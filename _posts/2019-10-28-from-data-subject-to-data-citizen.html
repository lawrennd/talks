---
title: "From Data Subject to Data Citizen"
venue: "Global Forum on AI for Humanity, Paris"
abstract: "Resolutely complementary to top-down regulation, bottom-up data trusts aim to ‘give a voice’ to data subjects whose choices when it comes to data governance are often reduced to binary, ill-informed consent. While the rights granted by instruments like the GDPR can be used as tools in a bit to shape possible data-reliant futures - such as better use of natural resources, medical care etc., their exercise is both demanding and unlikely to be as impactful when leveraged individually. The power that stems from aggregated data should be returned to individuals through the legal mechanism of trusts."
author:
- given: Neil D.
  family: Lawrence
  url: http://inverseprobability.com
  institute: University of Cambridge
  twitter: lawrennd
  gscholar: r3SJcvoAAAAJ
  orchid: 
date: 2019-10-28
published: 2019-10-28
youtube: "pWTQ1ZpyanM"
youtube_start: "972"
youtube_end: "1597"
layout: talk
categories:
- notes
---


<div style="display:none">
  $${% include talk-notation.tex %}$$
</div>

<script src="/talks/figure-magnify.js"></script>
<script src="/talks/figure-animate.js"></script>
    
<div id="modal-frame" class="modal">
  <span class="close" onclick="closeMagnify()">&times;</span>
  <div class="modal-figure">
    <div class="figure-frame">
      <div class="modal-content" id="modal01"></div>
      <!--<img class="modal-content" id="object01">-->
    </div>
    <div class="caption-frame" id="modal-caption"></div>
  </div>
</div>	  

<h2 id="context">Context</h2>
<p>This talk was given on a panel session organised by <a href="https://www.cs.mcgill.ca/~jpineau/">Joelle Pineau</a> and <a href="https://www.birmingham.ac.uk/staff/profiles/law/delacroix-sylvie.aspx">Sylvie Delacroix</a>.</p>
<p>Paul refers to <a href="https://twitter.com/PaulNemitz">Paul Nemitz</a> (who spoke before me), Sylvie refers to <a href="https://twitter.com/sylviedelacroix?lang=en">Sylvie Delacroix</a> (who introduced the panel), Stuart refers to <a href="https://people.eecs.berkeley.edu/~russell/">Stuart Russell</a> (who spoke in the previous session).</p>
<p>The talk was given unscripted and without slides, but below is a transcript of what I said taken from a personal recording I made.</p>
<p>Youtube video is now included above, transcript below.</p>
<h2 id="talk-transcript">Talk Transcript</h2>
<p>It’s a great pleasure to come after Paul.</p>
<p>So my talk’s going to be in three parts where I try and talk about motivation and then end up where Paul also ended up around Data Co-operatives. But I wanted to start by taking the title of this meeting “Global Forum on AI for Humanity”, it sounds great doesn’t it. All positive there. But the first question for me is “So what is Humanity?”. How many Africans are in the audience today? How many Chinese are in the audience today? Humanity is a diversity of opinion. And I was thinking about our hosts and I was thinking <em>liberté</em>, <em>egalité</em> and <em>fraternité</em>. Should probably be <em>solidarité</em>. But <em>diversité</em>. Diversité, my pronounciation isn’t that good. Diversité is the main thing we should be adding, I believe, to those sentiments which are after all 18th century sentiments developed by white men.</p>
<p>We heard earlier about trust. Now, one of the challenges we face is around this term AI. What is intelligence itself? It’s a very emotive term, because as soon as I say intelligence, we assume its something to do with who we are. Now the type of intelligence we can create is not who we are, it’s a combination of computers and statistics. Statistics that are computed on the basis of personal data, which is why legislation such as GDPR is so important in regulation. People in the public, when they hear the term intelligence, I believe they think of something more like anthropomorphic intelligence. But what we have created is nothing like an anthropomorphic intelligence, it would be closer to the type of intelligence you have in your immune system, which is something you are not aware of, but is one of the most important intelligences we have. What we talk about as AI today would therefore be better described as “computers and statistics”.</p>
<p>You cannot put trust in a machine in the way that the human being in the street understands the term trust. The idea that trust is verification or some other form of “I can prove that this computer is going to do this”, is wrong. Trust is naturally a human characteristic, I trust someone, I cannot trust a thing in the same way. Human rights are robust, and they should be the foundation of what we do, but they are robust because they are interpreted by humans.</p>
<p>There is a fundamental difference between the codification a computer scientist makes (I am a computer scientist) and a legal expert such as Paul makes. A computer scientist knows that they have to account for every situation that is going to be encountered when the system is deployed. This relates to some of what Stuart was talking about. But we cannot tolerate that, we cannot build machines that are so specified that they understand every circumstance that they will perceive today. The humans must be kept in the loop.</p>
<p>The reason legislative frameworks can work is because there is an understanding that they will be interpreted [by humans] in the future given the context. The AI we have created has no contextual understanding. That’s another way of saying what Stuart was saying earlier about the AI asking us questions. We have the contextual understanding and that’s the gap that he’s adressing there. But Stuart also talked the challenges of “Which contextual understanding?”. We need a diversity of understandings.</p>
<p>I was in Ghana last week at <a href="http://www.datascienceafrica.org/dsa2019accra/">this meeting</a> “Data Science Africa”, and we had a panel session on “What is Ethics?”. So to my mind I could see three parts to it. I think ethics are about <em>vulnerabilities</em>. People who are not empowered to control their own destinies, because of lack of knowledge, lack of power of some form. And very often those vulnerabilities are to do with <em>power asymmetries</em>. Some people have more power because they have more knowledge and they enact decisions that affect the people that are vulnerable. And, as was mentioned by Sylvie at the beginning, there’s a tension that is not reflected enough in our legal mechanisms of the <em>collective vs the individual</em>. I don’t understand very well Chinese ethical points of view but I believe them to be valid in some way, and my best understanding of them is that they value the collective more than the individual. Certainly, in the United States and in the UK the perspective is that the individual is primary. But I don’t think that we can continue to view it that way, as Sylvie mentioned, in the world of data.</p>
<p>So what are the challenges? Well we’re lucky because, I would say, that legislators are actually quite far-seeing. So GDPR is very far-seeing legislation in that it originates<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> in 1983 when people were worried about what they called significant<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> decision-making about whether you should be given insurance, or whether you should be allowed to go to a particular University or a decision about your sentencing in a court case. It gives us rights in those circumstances. But the new world that we face is that we’re getting algorithmic decisions being made about us, based on a series of insignificant decisions that when accumulated together have a significant effect. So the challenge is we will only investiage the decision … Stuart talked about we need to think about our objective funcitons, he’s absolutely right … but the challenge is if you’re building one small subsystem in an AI and the decision making is inconsequentional, not much thought is going into those decisions and what their objectives are. But once you’ve deployed the system it becomes part of a wider vitual environment that we’re all faced with that is changing our lives and that’s the gap we’re looking at.</p>
<p>So the GDPR gives us rights, it gives us rights to portability, erasability and explainability. But what we need to do is come together in the manner that Paul was suggesting and combine those rights. Because <a href="https://www.theguardian.com/media-network/2015/nov/16/information-barons-threaten-autonomy-privacy-online">we are in a medieval system of legislation</a> as far as data goes. There are two forms, there’s the commons where you put all your data out there for the whole world to see or the the Baron, the company that owns your data and makes decisions on your behalf. And we have no response … we have some legal rights, but those legal rights are ignored until the moment when we discover they’ve failed in their duty of care and we say “What were you doing?”. Equivalent to the Vikings turning up and stealing our children and so on so forth.</p>
<p>Now trust law provides an ecosystem for regulation, I’m aware that trust law is more developed perhaps in common law, in the Anglo Saxon countries, but the important part of trust law is the fiduciary responsibilities. So there are two parts to what I want to say in terms of <a href="https://academic.oup.com/idpl/advance-article/doi/10.1093/idpl/ipz014/5579842">the proposal that Sylvie and I have written about on data trusts</a> <span class="citation" data-cites="Delacroix:trusts19">(Delacroix and Lawrence 2019)</span>.</p>
<p>First of all, in trust law there is a duty of care which is fiduciary, a duty of undivided loyalty for those that lead the trust to act on behalf of the members<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a> of the trust. So the idea in a data trust is we pool our data rights within one organisation and we have data trustees who make decisions on our behalf. They are not regulated in the way that current professionals are regulated as directors of companies, they are are regulated in a stronger way they have to stand by those duties and provide undivided loyalty.</p>
<p>The really important thing is that you can have a diversity of trusts. You do not want one trust to rule them all, that would be equivalent to govermental legislation, and the reason for that is because we don’t understand the future decisions that people will want to make about their data. And we should give them an opportunity to express their preferences today. Unfortunately doing that individually, we know doesn’t work. So you place in this intermediary, this form of weak democracy of a data trust, with millions of members perhaps, that is representing a body of people with a particular opinion.</p>
<p>In that way you get over the need to break up platform companies, because the platform companies themselves rely on data to obtain their monopoly. If you remove the data, AI of today is entirely driven by data. The AI of tomorrow we cannot legislate for whatever that might be. The AI of today we can legislate for and it is driven by our personal data, and if we want to take back control of the decisions that are being made about us the place to intervene is on the data. So people who talk about competition law, I think they’re barking up the wrong tree. I think they need to look at data privacy law and data protection law.</p>
<p>I’ll just end by reading out a few corporate missions. You have to guess which companies they are.</p>
<p>“To give people the power to build community and bring the world closer together”</p>
<p>Sounds lovely</p>
<p>“To organise the world’s information and make it universally accessible and useful”</p>
<p>Also sounds lovely</p>
<p>“To make the world around you universally accessible and useful”</p>
<p>That’s related to the previous one.</p>
<p>“To be the earth’s most customer centric company”</p>
<p>Well these are all very lovely, but these are companies that are claiming they are mission driven but the reality is that [much of] their revenues are driven by advertising. [Much of] their revenues are driven by looking at our personal data and we have no come-back to say “You are not conforming to your mission” now trust law does that, and of course these missions are in some sense meaningless because no one can question the company on what it’s doing against its mission. If you force an organisation to have a mission that they have to stand beside, and you can do that through trust law, then you will find a more equitable approach to use and decisions that are made on the basis of our personal data. And I’ll end there.</p>
<div id="refs" class="references">
<div id="ref-Delacroix:trusts19">
<p>Delacroix, Sylvie, and Neil D. Lawrence. 2019. “Bottom-up Data Trusts: Disturbing the ‘One Size Fits All’ Approach to Data Governance.” <em>International Data Privacy Law</em>, October. <a href="https://doi.org/10.1093/idpl/ipz014" class="uri">https://doi.org/10.1093/idpl/ipz014</a>.</p>
</div>
</div>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>An error here, it actually <a href="https://www.coe.int/en/web/data-protection/convention108-and-protocol">goes back to 1981</a>.<a href="#fnref1" class="footnote-back">↩</a></p></li>
<li id="fn2"><p>Here I misspoke, I intended to say ‘consequential’.<a href="#fnref2" class="footnote-back">↩</a></p></li>
<li id="fn3"><p>It would have been more accurate to say ‘beneficiaries’ here.<a href="#fnref3" class="footnote-back">↩</a></p></li>
</ol>
</section>



---
title: "Artificial Intelligence: Reclaiming Control"
subtitle: “FIT Models must become FIT Systems”
abstract: |
  Though artificial intelligence is ubiquitous in our homes and
  workplaces, there is widespread misunderstanding of what it really
  is. Join us for this public lecture as Neil Lawrence, DeepMind
  Professor of Machine Learning encourages us to reframe our view of
  AI.
 
  He’ll discuss how the artificial systems we have developed operate
  in a fundamentally different way to our own intelligence. He’ll
  describe how this difference in operational capability leads us to
  misunderstand the influence that decisions made by machine
  intelligence are having on our lives. Without this understanding we
  cannot take back control of those decisions from the machine. Along
  the way, he’ll chat with fellow Cambridge University researchers
  about how we maximise the benefits of these technologies while
  minimising the harms.
author:
- family: Lawrence
  given: Neil D.
  gscholar: r3SJcvoAAAAJ
  institute: University of Cambridge
  twitter: lawrennd
  url: http://inverseprobability.com
date: 2022-04-09
venue: "William Gates Building"
transition: None
---
 

Beth Singler's work on AI as a creation narrative
https://bvsingler.com

Patrick Boyde's talks on Sistine Chapel
https://www.mmll.cam.ac.uk/pb127

David MacKay's work on information theory.
https://en.wikipedia.org/wiki/David_J._C._MacKay

Discussions with Rachel.

* Embodiment Factor

* AI Substantive Fairness vis PRocedural Fairness 

* Bring in Diana (working with professionals on understanding uncertainty)

* AI Fallacy

AI@Cam agenda: See the machine as a tool. Accelerate Programme bring in Sarah.

Data Trusts Initiative (Brixham ... deprivation) Chris WHitty

Finish on ... imaginary enemies (well aware of the big tech) need to worry about companies not on our radar.

Leave fifeteen minutes for questions. (Or 20 ... hour total)

t’s said that Henry Ford’s customers wanted a “a faster horse”. If Henry Ford was selling us artificial intelligence today, what would the customer call for, “a smarter human”? That’s certainly the picture of machine intelligence we find in science fiction narratives, but the reality of what we’ve developed is much more mundane. 
 
Car engines produce prodigious power from petrol. Machine intelligences deliver decisions derived from data. In both cases the scale of consumption enables a speed of operation that is far beyond the capabilities of their natural counterparts. Unfettered energy consumption has consequences in the form of climate change. Does unbridled data consumption also have consequences for us? 
 
If we devolve decision making to machines, we depend on those machines to accommodate our needs. If we don’t understand how those machines operate, we lose control over our destiny. Our mistake has been to see machine intelligence as a reflection of our intelligence. We cannot understand the smarter human without understanding the human. To understand the machine, we need to better understand ourselves.


From Rachel: 

I was going to say a bit about the data trusts work.
 
Perhaps that with Diana and Sarah is enough?
 
From: Rachel Gardner <rg580@cam.ac.uk>
Date: Monday, 14 March 2022 at 16:53
To: Neil Lawrence <ndl21@cam.ac.uk>
Subject: RE: Your Festival lecture on AI: RECLAIMING CONTROL

Hi Neil,
 
Just a quick update on your planned 9th April Festival lecture. I’ve approached Diane Coyle and sadly she can’t come and join in as she’ll be out of Cambridge that day. Both Sarah Morgan (Computer Says No) and Diane Robinson (‘working with doctors on the interpretation of uncertainty’) are happy to come and contribute. They’d like to know what in particular you’d like them to say so they can prepare.
 
I was just wondering, given we were talking about taking back control of our data, do you want someone from the Data Trusts Initiative to contribute a few words – maybe about what the new pilot projects will do to help give back groups control over the way their data is used?
 
My other thought was whether it might be worth asking Jat Singh to say a little bit about his ‘Internet of Stings’ project with the Information Commissioner’s Office? One of the topics you mentioned in our chat was data crimes being committed in the equivalent of international waters and that’s one of things he’s concerned about in his research, i.e. the occasions when data from our many smart devices is transmitted from one country to another where there may be different rules, rights and restrictions around data and its use.
 
Let me know what you think.
 
All the best, Rachel
 
Rachel Gardner
Digital Communications Coordinator
Department of Computer Science and Technology
University of Cambridge
 
Please note: I work part-time and my usual working hours are Monday, Tuesday and Wednesday.



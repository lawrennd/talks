---
title: Large Scale Learning in <span>G</span>aussian Processes
abstract: Gaussian process models view the kernel matrix as representing the covariance
  between data points. In a Gaussian process, the RKHS function is a mean of a posterior
  distribution over possible functions. Gaussian processes sustain uncertainty around
  this means and this leads to a posterior \*covariance\* function (or kernel) associated
  with the process. A complication for large scale Gaussian process models is the
  need to sustain the estimate for this covariance function. In this talk we’ll review
  how this can be done probabilistically through a variational approach we know as
  ’variational compression’.
venue: Large-Scale Kernel Learning Workshop @ICML2015
linkpdf: http://staffwww.dcs.shef.ac.uk/people/N.Lawrence/talks/parametric_icmllskw15.pdf
year: '2015'
month: 7
day: '11'
layout: talk
key: Lawrence:largeicml15
categories:
- Lawrence:largeicml15
authors:
- firstname: Neil D.
  lastname: Lawrence
published: 2015-07-11
---

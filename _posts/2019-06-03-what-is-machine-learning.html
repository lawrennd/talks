---
title: "What is Machine Learning?"
venue: "Data Science Africa Summer School, Addis Ababa, Ethiopia"
abstract: "In this talk we will introduce the fundamental ideas in machine learning. We’ll develop our exposition around the ideas of prediction function and the objective function. We don’t so much focus on the derivation of particular algorithms, but more the general principles involved to give an idea of the machine learning <em>landscape</em>."
author:
- given: Neil D.
  family: Lawrence
  url: http://inverseprobability.com
  institute: Amazon Cambridge and University of Sheffield
  twitter: lawrennd
  gscholar: r3SJcvoAAAAJ
  orchid: 
date: 2019-06-03
published: 2019-06-03
reveal: 2019-06-03-what-is-machine-learning.slides.html
ipynb: 2019-06-03-what-is-machine-learning.ipynb
layout: talk
categories:
- notes
---


<div style="display:none">
  $${% include talk-notation.tex %}$$
</div>

<script src="/talks/figure-magnify.js"></script>
<script src="/talks/figure-animate.js"></script>
    
<div id="modal-frame" class="modal">
  <span class="close" onclick="closeMagnify()">&times;</span>
  <div class="modal-figure">
    <div class="figure-frame">
      <div class="modal-content" id="modal01"></div>
      <!--<img class="modal-content" id="object01">-->
    </div>
    <div class="caption-frame" id="modal-caption"></div>
  </div>
</div>	  

<!-- Front matter -->
<!-- Front matter -->
<!-- Do not edit this file locally. -->
<p>.</p>
<!-- Do not edit this file locally. -->
<!---->
<!-- Do not edit this file locally. -->
<!--Back matter-->
<!-- Do not edit this file locally. -->
<!-- The last names to be defined. Should be defined entirely in terms of macros from above-->
<h1 id="introduction">Introduction</h1>
<h2 id="machine-learning">Machine Learning</h2>
<p>This talk is a general introduction to machine learning, we will highlight the technical challenges and the current solutions. We will give an overview of what is machine learning and why it is important.</p>
<h2 id="rise-of-machine-learning">Rise of Machine Learning</h2>
<p>Machine learning is the combination of data and models, through computation, to make predictions. <br /><span class="math display">$$
\text{data} + \text{model} + \xrightarrow{\text{compute}} \text{prediction}
$$</span><br /></p>
<h2 id="data-revolution">Data Revolution</h2>
Machine learning has risen in prominence due to the rise in data availability, and its interconnection with computers. The high bandwidth connection between data and computer leads to a new interaction between us and data via the computer. It is that channel that is being mediated by machine learning techniques.
<div class="figure">
<div id="data-science-information-flow-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/data-science/new-flow-of-information.svg" width="60%" style=" ">
</object>
</div>
<div id="data-science-information-flow-magnify" class="magnify" onclick="magnifyFigure(&#39;data-science-information-flow&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="data-science-information-flow-caption" class="caption-frame">
<p>Figure: Large amounts of data and high interconnection bandwidth mean that we receive much of our information about the world around us through computers.</p>
</div>
</div>
<div class="figure">
<div id="amazon-drone-delivery-figure" class="figure-frame">
<iframe width="800" height="600" src="https://www.youtube.com/embed/vNySOrI2Ny8?start=" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen>
</iframe>
</div>
<div id="amazon-drone-delivery-magnify" class="magnify" onclick="magnifyFigure(&#39;amazon-drone-delivery&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="amazon-drone-delivery-caption" class="caption-frame">
<p>Figure: Amazon’s proposed drone delivery system.</p>
</div>
</div>
<h2 id="olympic-marathon-data-edit">Olympic Marathon Data <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/olympic-marathon-data.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/olympic-marathon-data.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<table>
<tr>
<td width="70%">
<ul>
<li>Gold medal times for Olympic Marathon since 1896.</li>
<li>Marathons before 1924 didn’t have a standardised distance.</li>
<li>Present results using pace per km.</li>
<li>In 1904 Marathon was badly organised leading to very slow times.</li>
</ul>
</td>
<td width="30%">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/Stephen_Kiprotich.jpg" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
<small>Image from Wikimedia Commons <a href="http://bit.ly/16kMKHQ" class="uri">http://bit.ly/16kMKHQ</a></small>
</td>
</tr>
</table>
<p>The first thing we will do is load a standard data set for regression modelling. The data consists of the pace of Olympic Gold Medal Marathon winners for the Olympics from 1896 to present. First we load in the data and plot.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="im">import</span> numpy <span class="im">as</span> np</a>
<a class="sourceLine" id="cb1-2" data-line-number="2"><span class="im">import</span> pods</a></code></pre></div>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb2-1" data-line-number="1">data <span class="op">=</span> pods.datasets.olympic_marathon_men()</a>
<a class="sourceLine" id="cb2-2" data-line-number="2">x <span class="op">=</span> data[<span class="st">&#39;X&#39;</span>]</a>
<a class="sourceLine" id="cb2-3" data-line-number="3">y <span class="op">=</span> data[<span class="st">&#39;Y&#39;</span>]</a>
<a class="sourceLine" id="cb2-4" data-line-number="4"></a>
<a class="sourceLine" id="cb2-5" data-line-number="5">offset <span class="op">=</span> y.mean()</a>
<a class="sourceLine" id="cb2-6" data-line-number="6">scale <span class="op">=</span> np.sqrt(y.var())</a></code></pre></div>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb3-1" data-line-number="1"><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</a>
<a class="sourceLine" id="cb3-2" data-line-number="2"><span class="im">import</span> teaching_plots <span class="im">as</span> plot</a>
<a class="sourceLine" id="cb3-3" data-line-number="3"><span class="im">import</span> mlai</a></code></pre></div>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb4-1" data-line-number="1"></a>
<a class="sourceLine" id="cb4-2" data-line-number="2">xlim <span class="op">=</span> (<span class="dv">1875</span>,<span class="dv">2030</span>)</a>
<a class="sourceLine" id="cb4-3" data-line-number="3">ylim <span class="op">=</span> (<span class="fl">2.5</span>, <span class="fl">6.5</span>)</a>
<a class="sourceLine" id="cb4-4" data-line-number="4">yhat <span class="op">=</span> (y<span class="op">-</span>offset)<span class="op">/</span>scale</a>
<a class="sourceLine" id="cb4-5" data-line-number="5"></a>
<a class="sourceLine" id="cb4-6" data-line-number="6">fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>plot.big_wide_figsize)</a>
<a class="sourceLine" id="cb4-7" data-line-number="7">_ <span class="op">=</span> ax.plot(x, y, <span class="st">&#39;r.&#39;</span>,markersize<span class="op">=</span><span class="dv">10</span>)</a>
<a class="sourceLine" id="cb4-8" data-line-number="8">ax.set_xlabel(<span class="st">&#39;year&#39;</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</a>
<a class="sourceLine" id="cb4-9" data-line-number="9">ax.set_ylabel(<span class="st">&#39;pace min/km&#39;</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</a>
<a class="sourceLine" id="cb4-10" data-line-number="10">ax.set_xlim(xlim)</a>
<a class="sourceLine" id="cb4-11" data-line-number="11">ax.set_ylim(ylim)</a>
<a class="sourceLine" id="cb4-12" data-line-number="12"></a>
<a class="sourceLine" id="cb4-13" data-line-number="13">mlai.write_figure(figure<span class="op">=</span>fig, </a>
<a class="sourceLine" id="cb4-14" data-line-number="14">                  filename<span class="op">=</span><span class="st">&#39;../slides/diagrams/datasets/olympic-marathon.svg&#39;</span>, </a>
<a class="sourceLine" id="cb4-15" data-line-number="15">                  transparent<span class="op">=</span><span class="va">True</span>, </a>
<a class="sourceLine" id="cb4-16" data-line-number="16">                  frameon<span class="op">=</span><span class="va">True</span>)</a></code></pre></div>
<div class="figure">
<div id="olympic-marathon-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/datasets/olympic-marathon.svg" width style=" ">
</object>
</div>
<div id="olympic-marathon-magnify" class="magnify" onclick="magnifyFigure(&#39;olympic-marathon&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="olympic-marathon-caption" class="caption-frame">
<p>Figure: Olympic marathon pace times since 1892.</p>
</div>
</div>
<p>Things to notice about the data include the outlier in 1904, in this year, the olympics was in St Louis, USA. Organizational problems and challenges with dust kicked up by the cars following the race meant that participants got lost, and only very few participants completed.</p>
<p>More recent years see more consistently quick marathons.</p>
<h2 id="polynomial-fits-to-olympic-data-edit">Polynomial Fits to Olympic Data <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/olympic-polynomials.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/olympic-polynomials.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb5-1" data-line-number="1"><span class="im">import</span> numpy <span class="im">as</span> np</a>
<a class="sourceLine" id="cb5-2" data-line-number="2"><span class="im">from</span> matplotlib <span class="im">import</span> pyplot <span class="im">as</span> plt</a>
<a class="sourceLine" id="cb5-3" data-line-number="3"><span class="im">import</span> mlai</a>
<a class="sourceLine" id="cb5-4" data-line-number="4"><span class="im">import</span> pods</a></code></pre></div>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb6-1" data-line-number="1">basis <span class="op">=</span> mlai.polynomial</a>
<a class="sourceLine" id="cb6-2" data-line-number="2"></a>
<a class="sourceLine" id="cb6-3" data-line-number="3">data <span class="op">=</span> pods.datasets.olympic_marathon_men()</a>
<a class="sourceLine" id="cb6-4" data-line-number="4"></a>
<a class="sourceLine" id="cb6-5" data-line-number="5">x <span class="op">=</span> data[<span class="st">&#39;X&#39;</span>]</a>
<a class="sourceLine" id="cb6-6" data-line-number="6">y <span class="op">=</span> data[<span class="st">&#39;Y&#39;</span>]</a>
<a class="sourceLine" id="cb6-7" data-line-number="7"></a>
<a class="sourceLine" id="cb6-8" data-line-number="8">xlim <span class="op">=</span> [<span class="dv">1892</span>, <span class="dv">2020</span>]</a>
<a class="sourceLine" id="cb6-9" data-line-number="9"></a>
<a class="sourceLine" id="cb6-10" data-line-number="10"></a>
<a class="sourceLine" id="cb6-11" data-line-number="11">basis<span class="op">=</span>mlai.Basis(mlai.polynomial, number<span class="op">=</span><span class="dv">1</span>, data_limits<span class="op">=</span>xlim)</a></code></pre></div>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb7-1" data-line-number="1"><span class="im">from</span> ipywidgets <span class="im">import</span> IntSlider</a></code></pre></div>
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb8-1" data-line-number="1">pods.notebook.display_plots(<span class="st">&#39;olympic_LM_polynomial_num_basis</span><span class="sc">{num_basis:0&gt;3}</span><span class="st">.svg&#39;</span>,</a>
<a class="sourceLine" id="cb8-2" data-line-number="2">                            directory<span class="op">=</span><span class="st">&#39;../slides/diagrams/ml&#39;</span>, </a>
<a class="sourceLine" id="cb8-3" data-line-number="3">                            num_basis<span class="op">=</span>IntSlider(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">27</span>,<span class="dv">1</span>))</a></code></pre></div>
<div class="figure">
<div id="olympic-lm-polynomial-num-basis-02-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/ml/olympic_LM_polynomial_num_basis002.svg" width="80%" style=" ">
</object>
</div>
<div id="olympic-lm-polynomial-num-basis-02-magnify" class="magnify" onclick="magnifyFigure(&#39;olympic-lm-polynomial-num-basis-02&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="olympic-lm-polynomial-num-basis-02-caption" class="caption-frame">
<p>Figure: Fit of a 1 degree polynomial to the olympic marathon data.</p>
</div>
</div>
<div class="figure">
<div id="olympic-lm-polynomial-num-basis-03-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/ml/olympic_LM_polynomial_num_basis003.svg" width="80%" style=" ">
</object>
</div>
<div id="olympic-lm-polynomial-num-basis-03-magnify" class="magnify" onclick="magnifyFigure(&#39;olympic-lm-polynomial-num-basis-03&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="olympic-lm-polynomial-num-basis-03-caption" class="caption-frame">
<p>Figure: Fit of a 2 degree polynomial to the olympic marathon data.</p>
</div>
</div>
<p>Machine learning is the principal technology underlying the recent advances in artificial intelligence techniques. It is a fundamentally different approach to that developed in classical artificial intelligence (sometimes referred to as “good old fashioned AI” or GOFAI). GOFAI relied on symbolic logic as its mathematical engine.</p>
<p>Early AI used expert systems: a set of logical rules implemented to reconstruct expertise. For example, rules to decide whether or not someone has cancer. Rule based systems are very hard to specify for complex processes.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a></p>
<h2 id="data-science">Data Science</h2>
<p>Can split applications of machine learning broadly into <em>data science</em> and <em>artificial intelligence</em>. <em>Data science</em>: making sense of ‘new data’, the large volumes of data from sensors and increased interconnectivity (big data, IoT). Classical statistics: the question is formed first, and data is later.</p>
<p>In contrast to statistics, data science is <em>data first</em>, questions come later.</p>
<h2 id="artificial-intelligence">Artificial Intelligence</h2>
<p>In contrast, <em>Artificial intelligence</em> originates in <em>cybernetics</em>. It is the challenge of recreating ‘intelligent’ behaviour. In some cases it can mean <em>general intelligence</em> or emulation of <em>human</em> capabilities. Machine learning is important because of success of data-driven artificial intelligence. Data-driven artificial intelligence: instead of solving from first principles, collect data.</p>
<h2 id="machine-learning-1">Machine Learning</h2>
<p>The key idea in machine learning is to observe the system in practice, and then emulate its behavior with mathematics. That leads to a design challenge as to where to place the mathematical function. The placement of the mathematical function leads to the different domains of machine learning.</p>
<ol type="1">
<li>Supervised learning</li>
<li>Unsupervised learning</li>
<li>Reinforcement learning</li>
</ol>
<h1 id="supervised-learning-edit">Supervised Learning <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/supervised-learning.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/supervised-learning.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h1>
<p>Supervised learning is one of the most widely deployed machine learning technologies, and a particular domain of success has been <em>classification</em>. Classification is the process of taking an input (which might be an image) and categorizing it into one of a number of different classes (e.g. dog or cat). This simple idea underpins a lot of machine learning. By scanning across the image we can also determine where the animal is in the image.</p>
<div class="figure">
<div id="the-perceptron-algorithm-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/ml/perceptron001.svg" width="80%" style=" ">
</object>
<object class="svgplot " data="../slides/diagrams/ml/perceptron044.svg" width="80%" style=" ">
</object>
</div>
<div id="the-perceptron-algorithm-magnify" class="magnify" onclick="magnifyFigure(&#39;the-perceptron-algorithm&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="the-perceptron-algorithm-caption" class="caption-frame">
<p>Figure: The perceptron algorithm.</p>
</div>
</div>
<p>Classification is perhaps the technique most closely assocated with machine learning. In the speech based agents, on-device classifiers are used to determine when the wake word is used. A wake word is a word that wakes up the device. For the Amazon Echo it is “Alexa”, for Siri it is “Hey Siri”. Once the wake word detected with a classifier, the speech can be uploaded to the cloud for full processing, the speech recognition stages.</p>
<p>A major breakthrough in image classification came in 2012 with the ImageNet result of <a href="http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-">Alex Krizhevsky, Ilya Sutskever and Geoff Hinton</a> from the University of Toronto. ImageNet is a large data base of 14 million images with many thousands of classes. The data is used in a community-wide challenge for object categorization. Krizhevsky et al used convolutional neural networks to outperform all previous approaches on the challenge. They formed a company which was purchased shortly after by Google. This challenge, known as object categorisation, was a major obstacle for practical computer vision systems. Modern object categorization systems are close to human performance.</p>
<p>In supervised learning the inputs, <span class="math inline">$\inputVector$</span>, are mapped to a label, <span class="math inline">$\dataScalar$</span>, through a function <span class="math inline">$\mappingFunction(\cdot)$</span> that is dependent on a set of parameters, <span class="math inline">$\weightVector$</span>, <br /><span class="math display">$$
\dataScalar = \mappingFunction(\inputVector; \weightVector).
$$</span><br /> The function <span class="math inline">$\mappingFunction(\cdot)$</span> is known as the <em>prediction function</em>. The key challenges are (1) choosing which features, <span class="math inline">$\inputVector$</span>, are relevant in the prediction, (2) defining the appropriate <em>class of function</em>, <span class="math inline">$\mappingFunction(\cdot)$</span>, to use and (3) selecting the right parameters, <span class="math inline">$\weightVector$</span>.</p>
<h2 id="supervised-learning-challenges">Supervised Learning Challenges</h2>
<p>There are three principal challenges in constructing a problem for supervised learning.</p>
<ol type="1">
<li>choosing which features, <span class="math inline">$\inputVector$</span>, are relevant in the prediction</li>
<li>defining the appropriate <em>class of function</em>, <span class="math inline">$\mappingFunction(\cdot)$</span>.</li>
<li>selecting the right parameters, <span class="math inline">$\weightVector$</span>.</li>
</ol>
<h2 id="feature-selection">Feature Selection</h2>
<p>Feature selection is a critical stage in the algorithm design process. In the Olympic prediction example above we’re only using time to predict the the pace of the runners. In practice we might also want to use characteristics of the course: how hilly it is, what the temperature was when the race was run. In 1904 the runners actually got lost during the race. Should we include ‘lost’ as a feature? It would certainly help explain the particularly slow time in 1904. The features we select should be ones we expect to correlate with the prediction. In statistics, these features are even called <em>predictors</em> which highlights their role in developing the prediction function. For Facebook newsfeed, we might use features that include how close your friendship is with the poster, or how often you react to that poster, or whether a photo is included in the post.</p>
<p>Sometimes we use feature selection algorithms, algorithms that automate the process of finding the features that we need. Classification is often used to rank search results, to decide which adverts to serve or, at Facebook, to determine what appears at the top of your newsfeed. In the Facebook example features might include how many likes a post has had, whether it has an image in it, whether you regularly interact with the friend who has posted. A good newsfeed ranking algorithm is critical to Facebook’s success, just as good ad serving choice is critical to Google’s success. These algorithms are in turn highly dependent on the feature sets used. Facebook in particular has made heavy investments in machine learning pipelines for evaluation of the feature utility.</p>
<h2 id="class-of-function-mappingfunctioncdot">Class of Function, <span class="math inline">$\mappingFunction(\cdot)$</span></h2>
<p>By class of function we mean, what are the characteristics of the mapping between <span class="math inline"><strong>x</strong></span> and <span class="math inline"><em>y</em></span>. Often, we might choose it to be a smooth function. Sometimes we will choose it to be a linear function. If the prediction is a forecast, for example the demand of a particular product, then the function would need some periodic components to reflect seasonal or weekly effects.</p>
<p>In the ImageNet challenge the input, <span class="math inline"><strong>x</strong></span>, was in the form of an image. And the form of the prediction function was a <em>convolutional neural network</em> (more on this later). A convolutional neural network introduces <em>invariances</em> into the function that are particular to image classification. An invariance is a transformation of the input that we don’t want to affect the output. For example, a cat in an image is still a cat no matter where it’s located in the image (translation). The cat is also a cat regardless of how large it is (scale), or whether it’s upside-down (rotation). Convolutional neural networks encode these invariances: scale invariance, rotation invariance and translation invariance; in the mathematical function.</p>
<p>Encoding invariance in the prediction function is like encoding knowledge in the model. If we don’t specify these invariances, then the model must learn them. This will require a lot more data to achieve the same performance, making the model less data efficient. Note that one invariance that is <em>not</em> encoded in a convolutional network is invariance to camera type. As a result, practitioners need to be careful to ensure that their training data is representative of the type of cameras that will be used when the model is deployed.</p>
<p>In general the prediction function could be any set of parameterized functions. In the Olympic marathon data example above we used a polynomial fit,</p>
<p><br /><span class="math display">$$
\mappingFunction(\inputScalar) = \weightScalar_0 + \weightScalar_1 \inputScalar+ \weightScalar_2 \inputScalar^2 + \weightScalar_3 \inputScalar^3 + \weightScalar_4 \inputScalar^4.
$$</span><br /></p>
<p>The Olympic example is also a supervised learning challenge. But it is a <em>regression</em> problem. A regression problem is one where the output is a continuous value (such as the pace in the marathon). In classification the output is constrained to be discrete. For example, classifying whether or not an image contains a dog implies the output is binary. An early example of a regression problem used in machine learning was <a href="http://lib.stat.cmu.edu/datasets/tecator">the Tecator data</a>, where the fat, water and protein content of meat samples was predicted as a function of the absorption of infrared light.</p>
<h3 id="parameter-estimation">Parameter Estimation</h3>
<p>Once we have a set of features, and the class of functions we use is determined, we need to find the parameters of the model.</p>
<p>The parameters of the model, <span class="math inline"><strong>w</strong></span>, are estimated by specifying an <em>objective function</em>. The objective function specifies the quality of the match between the prediction function and the <em>training data</em>. In supervised learning the objective function incorporates both the input data (in the ImageNet data the image, in the Olympic marathon data the year of the marathon) and a <em>label</em>.</p>
<p>The label is where the term supervised learning comes from. The idea being that a supervisor, or annotator, has already looked at the data and given it labels. For regression problem, a typical objective function is the <em>squared error</em>, <br /><span class="math display">$$
E(\mathbf{w}) = \sum_{i=1}^n (y_i - f(\mathbf{x}_i))^2
$$</span><br /> where the data is provided to us as a set of <span class="math inline"><em>n</em></span> inputs, <span class="math inline"><strong>x</strong><sub>1</sub></span>, <span class="math inline"><strong>x</strong><sub>2</sub></span>, <span class="math inline"><strong>x</strong><sub>3</sub></span>, <span class="math inline">…</span>, <span class="math inline"><strong>x</strong><sub><em>n</em></sub></span> each one with an associated label, <span class="math inline"><em>y</em><sub>1</sub></span>, <span class="math inline"><em>y</em><sub>2</sub></span>, <span class="math inline"><em>y</em><sub>3</sub></span>, <span class="math inline">…</span>, <span class="math inline"><em>y</em><sub><em>n</em></sub></span>. Sometimes the label is cheap to acquire. For example, in Newsfeed ranking Facebook are acquiring a label each time a user clicks on a post in their Newsfeed. Similarly, in ad-click prediction labels are obtained whenever an advert is clicked. More generally though, we have to employ human annotators to label the data. For example, ImageNet, the breakthrough deep learning result was annotated using Amazon’s Mechanical Turk. Without such large scale human input, we would not have the breakthrough results on image categorization we have today.</p>
<p>Some tasks are easier to annotate than others. For example, in the Tecator data, to acquire the actual values of water, protein and fat content in the meat samples further experiments may be required. It is not simply a matter of human labelling. Even if the task is easy for humans to solve there can be problems. For example, humans will extrapolate the context of an image. A colleague mentioned once to me a challenge where humans were labelling images as containing swimming pools, even though none was visible, because they could infer there must be a pool nearby, perhaps because there are kids wearing bathing suits. But there is no swimming pool in the image for the computer to find. The quality of any machine learning solution is very sensitive to the quality of annotated data we have. Investing in processes and tools to improve annotation of data is therefore priority for improving the quality of machine learning solutions.</p>
<p>There can also be significant problems with misrepresentation in the data set. If data isn’t collected carefully, then it can reflect biases about the population that we don’t want our models to have. For example, if we design a face detector using Californians may not perform well when deployed in Kampala, Uganda.</p>
<h2 id="generalization-and-overfitting">Generalization and Overfitting</h2>
<p>Once a supervised learning system is trained it can be placed in a sequential pipeline to automate a process that used to be done manually.</p>
<p>Supervised learning is one of the dominant approaches to learning. But the cost and time associated with labeling data is a major bottleneck for deploying machine learning systems. The process for creating training data requires significant human intervention. For example, internationalization of a speech recognition system would require large speech corpora in new languages.</p>
<p>An important distinction in machine learning is the separation between training data and test data (or production data). Training data is the data that was used to find the model parameters. Test data (or production data) is the data that is used with the live system. The ability of a machine learning system to predict well on production systems given only its training data is known as its <em>generalization</em> ability. This is the system’s ability to predict in areas where it hasn’t previously seen data.</p>
<h2 id="overfitting">Overfitting</h2>
<div class="figure">
<div id="alex-ihler-overfitting-figure" class="figure-frame">
<iframe width="800" height="600" src="https://www.youtube.com/embed/py8QrZPT48s?start=4m0s" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen>
</iframe>
</div>
<div id="alex-ihler-overfitting-magnify" class="magnify" onclick="magnifyFigure(&#39;alex-ihler-overfitting&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="alex-ihler-overfitting-caption" class="caption-frame">
<p>Figure: Alex Ihler discusses polynomials and overfitting.</p>
</div>
</div>
<div class="figure">
<div id="olympic-lm-polynomial-num-basis-26-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/ml/olympic_LM_polynomial_num_basis026.svg" width="80%" style=" ">
</object>
</div>
<div id="olympic-lm-polynomial-num-basis-26-magnify" class="magnify" onclick="magnifyFigure(&#39;olympic-lm-polynomial-num-basis-26&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="olympic-lm-polynomial-num-basis-26-caption" class="caption-frame">
<p>Figure: Fit of a 26 degree polynomial to the olympic marathon data.</p>
</div>
</div>
<p>We can easily develop a simple prediction function that reconstructs the training data exactly, you can just use a look up table. But how would the lookup table predict between the training data, where examples haven’t been seen before? The choice of the class of prediction functions is critical in ensuring that the model generalizes well.</p>
<p>The generalization error is normally estimated by applying the objective function to a set of data that the model <em>wasn’t</em> trained on, the test data. To ensure good performance we normally want a model that gives us a low generalization error. If we weren’t sure of the right prediction function to use, then we could try 1,000 different prediction functions. Then we could use the one that gives us the lowest error on the test data. But you have to be careful. Selecting a model in this way is like a further stage of training where you are using the test data in the training.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> So when this is done, the data used for this is not known as test data, it is known as <em>validation data</em>. And the associated error is the <em>validation error</em>. Using the validation error for model selection is a standard machine learning technique, but it can be misleading about the final generalization error. Almost all machine learning practitioners know not to use the test data in your training procedure, but sometimes people forget that when validation data is used for model selection that validation error cannot be used as an unbiased estimate of the generalization performance.</p>
<h1 id="unsupervised-learning-edit">Unsupervised Learning <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/unsupervised-learning.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/unsupervised-learning.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h1>
<p>In unsupervised learning you have data, <span class="math inline">$\inputVector$</span>, but no labels <span class="math inline">$\dataScalar$</span>. The aim in unsupervised learning is to extract structure from data. The type of structure you are interested in is dependent on the broader context of the task. In supervised learning that context is very much driven by the labels. Supervised learning algorithms try and focus on the aspects of the data which are relevant to predicting the labels. But in unsupervised learning there are no labels.</p>
<h2 id="context">Context</h2>
<p>Humans can easily sort a number of objects into objects that share similar characteristics. We easily categorize animals or vehicles. But if the data is very large this is too slow. Even for smaller data, it may be that it is presented in a form that is unintelligible for humans. We are good at dealing with high dimensional data when it’s presented in images, but if it’s presented as a series of numbers, we find it hard to interpret. In unsupervised learning we want the computer to do the sorting for us. For example, an e-commerce company might need an algorithm that can go through its entire list of products and automatically sort them into groups such that similar products are located together.</p>
<h2 id="discrete-vs-continuous">Discrete vs Continuous</h2>
<p>Supervised learning is broadly divided into classification: i.e. wake word classification in the Amazon Echo, and regression, e.g. shelf life prediction for perishable goods. Similarly, unsupervised learning can be broadly split into methods that cluster the data (i.e. provide a discrete label) and methods that represent the data as a continuous value.</p>
<h2 id="clustering-edit">Clustering <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/clustering.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/clustering.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<p>Clustering methods associate each data point with a different label. Unlike in classification the label is not provided by a human annotator. It is allocated by the computer. Clustering is quite intuitive for humans, we do it naturally with our observations of the real world. For example, we cluster animals into different groups. If we encounter a new animal, we can immediately assign it to a group: bird, mammal, insect. These are certainly labels that can be provided by humans, but they were also originally invented by humans. With clustering we want the computer to recreate that process of inventing the label.</p>
<p>Unsupervised learning enables computers to form similar categorizations on data that is too large scale for us to process. When the Greek philosopher, Plato, was thinking about ideas, he considered the concept of the Platonic ideal. The Platonic ideal bird is the bird that is most bird-like or the chair that is most chair-like. In some sense, the task in clustering is to define different clusters, by finding their Platonic ideal (known as the cluster center) and allocate each data point to the relevant cluster center. So, allocate each animal to the class defined by its nearest cluster center.</p>
<p>To perform clustering on a computer we need to define a notion of either similarity or distance between the objects and their Platonic ideal, the cluster center. We normally assume that our objects are represented by vectors of data, <span class="math inline">$\inputVector_i$</span>. Similarly, we represent our cluster center for category <span class="math inline"><em>j</em></span> by a vector <span class="math inline">$\meanVector_j$</span>. This vector contains the ideal features of a bird, a chair, or whatever category <span class="math inline"><em>j</em></span> is. In clustering we can either think in terms of similarity of the objects, or distances. We want objects that are similar to each other to cluster together. We want objects that are distant from each other to cluster apart.</p>
<p>This requires us to formalize our notion of similarity or distance. Let’s focus on distances. A definition of distance between an object, <span class="math inline"><em>i</em></span>, and the cluster center of class <span class="math inline"><em>j</em></span> is a function of two vectors, the data point, <span class="math inline">$\inputVector_i$</span> and the cluster center, <span class="math inline">$\meanVector_j$</span>, <br /><span class="math display">$$
d_{ij} = f(\inputVector_i, \meanVector_j).
$$</span><br /> Our objective is then to find cluster centers that are close to as many data points as possible. For example, we might want to cluster customers into their different tastes. We could represent each customer by the products they’ve purchased in the past. This could be a binary vector <span class="math inline">$\inputVector_i$</span>. We can then define a distance between the cluster center and the customer.</p>
<h3 id="squared-distance">Squared Distance</h3>
<p>A commonly used distance is the squared distance, <br /><span class="math display">$$
\distanceScalar_{ij} = (\inputVector_i - \meanVector_j)^2.
$$</span><br /> The squared distance comes up a lot in machine learning. In unsupervised learning it was used to measure dissimilarity between predictions and observed data. Here its being used to measure the dissimilarity between a cluster center and the data.</p>
<p>Once we have decided on the distance or similarity function, we can decide a number of cluster centers, <span class="math inline"><em>K</em></span>. We find their location by allocating each center to a sub-set of the points and minimizing the sum of the squared errors, <br /><span class="math display">$$
\errorFunction(\meanMatrix) = \sum_{i \in \mathbf{i}_j} (\inputVector_i - \meanVector_j)^2
$$</span><br /> where the notation <span class="math inline"><strong>i</strong><sub><em>j</em></sub></span> represents all the indices of each data point which has been allocated to the <span class="math inline"><em>j</em></span>th cluster represented by the center <span class="math inline">$\meanVector_j$</span>.</p>
<h3 id="k-means-clustering"><span class="math inline"><em>k</em></span>-Means Clustering</h3>
<p>One approach to minimizing this objective function is known as <em><span class="math inline"><em>k</em></span>-means clustering</em>. It is simple and relatively quick to implement, but it is an initialization sensitive algorithm. Initialization is the process of choosing an initial set of parameters before optimization. For <span class="math inline"><em>k</em></span>-means clustering you need to choose an initial set of centers. In <span class="math inline"><em>k</em></span>-means clustering your final set of clusters is very sensitive to the initial choice of centers. For more technical details on <span class="math inline"><em>k</em></span>-means clustering you can watch a video of Alex Ihler introducing the algorithm here.</p>
<h3 id="k-means-clustering-1"><span class="math inline"><em>k</em></span>-Means Clustering</h3>
<div class="figure">
<div id="kmeans-clustering-13-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/ml/kmeans-clustering/kmeans_clustering_013.svg" width="\width" style=" ">
</object>
</div>
<div id="kmeans-clustering-13-magnify" class="magnify" onclick="magnifyFigure(&#39;kmeans-clustering-13&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="kmeans-clustering-13-caption" class="caption-frame">
<p>Figure: Clustering with the <span class="math inline"><em>k</em></span>-means clustering algorithm.</p>
</div>
</div>
<div class="figure">
<div id="k-means-clustering-figure" class="figure-frame">
<iframe width="800" height="600" src="https://www.youtube.com/embed/mfqmoUN-Cuw?start=" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen>
</iframe>
</div>
<div id="k-means-clustering-magnify" class="magnify" onclick="magnifyFigure(&#39;k-means-clustering&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="k-means-clustering-caption" class="caption-frame">
<p>Figure: <span class="math inline"><em>k</em></span>-means clustering by Alex Ihler.</p>
</div>
</div>
<h3 id="hierarchical-clustering">Hierarchical Clustering</h3>
<p>Other approaches to clustering involve forming taxonomies of the cluster centers, like humans apply to animals, to form trees. You can learn more about agglomerative clustering in this video from Alex Ihler.</p>
<div class="figure">
<div id="alex-ihler-hierarchical-clustering-figure" class="figure-frame">
<iframe width="800" height="600" src="https://www.youtube.com/embed/OcoE7JlbXvY?start=" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen>
</iframe>
</div>
<div id="alex-ihler-hierarchical-clustering-magnify" class="magnify" onclick="magnifyFigure(&#39;alex-ihler-hierarchical-clustering&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="alex-ihler-hierarchical-clustering-caption" class="caption-frame">
<p>Figure: Hierarchical Clustering by Alex Ihler.</p>
</div>
</div>
<h3 id="phylogenetic-trees">Phylogenetic Trees</h3>
<p>Indeed, one application of machine learning techniques is performing a hierarchical clustering based on genetic data, i.e. the actual contents of the genome. If we do this across a number of species then we can produce a <em>phylogeny</em>. The phylogeny aims to represent the actual evolution of the species and some phylogenies even estimate the timing of the common ancestor between two species<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a>. Similar methods are used to estimate the origin of viruses like AIDS or Bird flu which mutate very quickly. Determining the origin of viruses can be important in containing or treating outbreaks.</p>
<h3 id="product-clustering">Product Clustering</h3>
<p>An e-commerce company could apply hierarchical clustering to all its products. That would give a phylogeny of products. Each cluster of products would be split into sub-clusters of products until we got down to individual products. For example, we might expect a high level split to be Electronics/Clothing. Of course, a challenge with these tree-like structures is that many products belong in more than one parent cluster: for example running shoes should be in more than one group, they are ‘sporting goods’ and they are ‘apparel’. A tree structure doesn’t allow this allocation.</p>
<h3 id="hierarchical-clustering-challenge">Hierarchical Clustering Challenge</h3>
<p>Our own psychological grouping capabilities are studied as a domain of cognitive science. Researchers like Josh Tenenbaum have developed algorithms that decompose data in more complex ways, but they can normally only be applied to smaller data sets.</p>
<h2 id="dimensionality-reduction-edit">Dimensionality Reduction <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/dimensionality-reduction.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/dimensionality-reduction.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<p>Dimensionality reduction methods compress the data by replacing the original data with a reduced number of continuous variables. One way of thinking of these methods is to imagine a marionette.</p>
<div class="figure">
<div id="marionette-figure" class="figure-frame">
<object class width="40%" data="../slides/diagrams/ml/marionette.svg">
</object>
</div>
<div id="marionette-magnify" class="magnify" onclick="magnifyFigure(&#39;marionette&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="marionette-caption" class="caption-frame">
<p>Figure: Thinking of dimensionality reduction as a marionette. We observe the high dimensional pose of the puppet, <span class="math inline">$\inputVector$</span>, but the movement of the puppeteer’s hand, <span class="math inline">$\latentVector$</span> remains hidden to us. Dimensionality reduction aims to recover those hidden movements which generated the observations.</p>
</div>
</div>
<p>The position of each body part of a marionette could be thought of as our data, <span class="math inline">$\inputVector_i$</span>. So, each data point consists of the 3-D co-ordinates of all the different body parts of the marionette. Let’s say there are 13 different body parts (2 each of feet, knees, hips, hands, elbows, shoulders, one head). Each body part has an x, y, z position in Cartesian coordinates. So that’s 39 numbers associated with each observation.</p>
<p>The movement of these 39 parts is determined by the puppeteer via strings. Let’s assume it’s a very simple puppet, with just one stick to control it. The puppeteer can move the stick up and down, left and right. And they can twist it. This gives three parameters in the puppeteers control. This implies that the 39 variables we see moving are controlled by only 3 variables. These 3 variables are often called the hidden or <em>latent variables</em>.</p>
<p>Dimensionality reduction assumes something similar for real world data. It assumes that the data we observe is generated from some lower dimensional underlying process. It then seeks to recover the values associated with this low dimensional process.</p>
<h3 id="examples-in-social-sciences">Examples in Social Sciences</h3>
<p>Dimensionality reduction techniques underpin a lot of psychological scoring tests such as IQ tests or personality tests. An IQ test can involve several hundred questions, potentially giving a rich, high dimensional, characterization of some aspects of your intelligence. It is then summarized by a single number. Similarly, the Myers-Briggs personality test involves answering questions about preferences which are reduced to a set of numbers reflecting personality.</p>
<p>These tests are assuming that our intelligence is implicitly one-dimensional and that our personality is implicitly four dimensional. Other examples include political belief which is typically represented on a left to right scale. A one-dimensional distillation of an entire philosophy about how a country should be run. Our own leadership principles imply that our decisions have a fourteen-dimensional space underlying them. Each decision could be characterized by judging to what extent it embodies each of the principles.</p>
<p>Political belief, personality, intelligence, leadership. None of these exist as a directly measurable quantity in the real world, rather they are inferred based on measurables. Dimensionality reduction is the process of allowing the computer to automatically find such underlying dimensions. This automatically allowing us to characterize each data point according to those explanatory variables. Each of these characteristics can be scored, and individuals can then be turned into vectors.</p>
<p>This doesn’t only apply to individuals, in recent years work on language modeling has taken a similar approach to words. The <a href="https://arxiv.org/abs/1301.3781">word2vec</a> algorithm performed a dimensionality reduction on words, now you can take any word and map it to a latent space where similar words exhibit similar characteristics. A personality space for words.</p>
<h3 id="principal-component-analysis">Principal Component Analysis</h3>
<p>Principal component analysis (PCA) is arguably the queen of dimensionality reduction techniques. PCA was developed as an approach to dimensionality reduction in 1930s by Hotelling as a method for the social sciences. In Hotelling’s formulation of PCA it was assumed that any data point, <span class="math inline"><strong>x</strong></span> could be represented as a weighted sum of the latent factors of interest, so that Hotelling described prediction functions (like in regression and classification above), only the regression is now <em>multiple output</em>. And instead of predicting a label, <span class="math inline"><em>y</em><sub><em>i</em></sub></span>, we now try and force the regression to predict the observed feature vector, <span class="math inline">$\dataVector_i$</span>. So, for example, on an IQ test we would try and predict subject <span class="math inline"><em>i</em></span>’s answer to the <span class="math inline"><em>j</em></span>th question with the following function <br /><span class="math display">$$
\dataScalar_{ij} = \mappingFunction_j(\latentScalar_i; \weightVector).
$$</span><br /> Here <span class="math inline"><em>z</em><sub><em>i</em></sub></span> would be the IQ of subject <span class="math inline"><em>i</em></span> and <span class="math inline">$\mappingFunction_j(\cdot)$</span> would be a function representing the relationship between the subject’s IQ and their score on the answer to question <span class="math inline"><em>j</em></span>. This function is the same for all subjects, but the subject’s IQ is assumed to differ leading to different scores for each subject.</p>
<div class="figure">
<div id="dem-manifold-print-all-1-2-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/ml/demManifoldPrint_all_1_2.svg" width="60%" style=" ">
</object>
</div>
<div id="dem-manifold-print-all-1-2-magnify" class="magnify" onclick="magnifyFigure(&#39;dem-manifold-print-all-1-2&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="dem-manifold-print-all-1-2-caption" class="caption-frame">
<p>Figure: Visualization of the first two principal components of an artificial data set. The data was generated by taking an image of a handwritten digit, 6, and rotating it 360 times, one degree each time. The first two principal components have been extracted in the diagram. The underlying circular shape is derived from the rotation of the data. Each image in the data set is projected on to the location its projected to in the latent space.</p>
</div>
</div>
<h3 id="hotellings-pca">Hotelling’s PCA</h3>
<p>In Hotelling’s formulation he assumed that the function was a linear function. This idea is taken from a wider field known as <em>factor analysis</em>, so Hotelling described the challenge as <br /><span class="math display">$$
\mappingFunction_j(\latentScalar_i; \weightVector) = \weightScalar_j \latentScalar_i
$$</span><br /> so the answer to the <span class="math inline"><em>j</em></span>th question is predicted to be a scaling of the subject’s IQ. The scale factor is given by <span class="math inline">$\weightScalar_j$</span>. If there are more latent dimensions then a matrix of parameters, <span class="math inline">$\weightMatrix$</span> is used, for example if there were two latent dimensions, we’d have <br /><span class="math display">$$
\mappingFunction_j(\mathbf{\latentScalar}_i; \weightMatrix) = \weightScalar_{1j} \latentScalar_{1i} + \weightScalar_{2j} \latentScalar_{2i}
$$</span><br /> where, if this were a personality test, then <span class="math inline">$\latentScalar_{1i}$</span> might represent the spectrum over a subject’s extrovert/introvert and <span class="math inline">$\latentScalar_{2i}$</span> might represent where the subject was on the rational/perceptual scale. The function would make a prediction about the subjects answer to a particular question on the test (e.g. preference for office job vs preference for outdoor job). In factor analysis the parameters <span class="math inline">$\weightMatrix$</span> are known as the factor <em>loadings</em> and in PCA they are known as the principal components.</p>
<h3 id="parameters">Parameters</h3>
<p>Fitting the model involves finding estimates for the loadings, <span class="math inline">$\weightMatrix$</span>, and latent variables, <span class="math inline">$\latentMatrix$</span>. There are different approaches including least squares. The least squares approach is used, for example, in recommender systems. In recommender systems this method is called <em>matrix factorization</em>. The customer characteristics, <span class="math inline">$\dataVector_i$</span> is the customer rating for each different product (or item) and the latent variables can be seen as a space of customer preferences. In the recommender system case, the loadings matrix also has an interpretation as product similarities.<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a> Recommender systems have a particular characteristic in that most of the entries of the vector <span class="math inline">$\dataVector_i$</span> are missing most of the time.</p>
<p>In PCA and factor analysis the unknown latent factors are dealt with through a probability distribution. They are each assumed to be drawn from a zero mean, unit variance normal distribution. This leaves the factor loadings to be estimated. For PCA the maximum likelihood solution for the factor loadings can be shown to be given by the <em>eigenvalue decomposition</em> of the data covariance matrix. This is algorithmically simple and convenient, although slow to compute for very large data sets with many features and many subjects. The eigenvalue problem can also be derived from many other starting points: e.g. the directions of maximum variance in the data or finding a latent space that best preserves inter-point distances between the data, or the optimal linear compression of the data given a linear reconstruction. These many and varied justifications for the eigenvalue decomposition may account for the popularity of PCA. Indeed, there is even an interpretation for Google’s original PageRank algorithm (which computed the <em>smallest</em> eigenvector of the internet’s linkage matrix) as seeking the dominant principal component of the web.<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a></p>
<p>Characterizing users according to past buying behavior and combining this with characteristics about products, is key to making good recommendations and returning useful search results. Further advances can be made if we understand the context of a particular session. For example, if a user is buying Christmas presents and searches for a dress, then it could be the case that the user is willing to spend a little more on the dress than in normal circumstances. Characterizing these effects requires more data and more complex algorithms. However, in domains such a search we are normally constrained by the speed with which we need to return results. Accounting for each of these factors while returning results with acceptable latency is a particular challenge.</p>
<h1 id="reinforcement-learning-edit">Reinforcement Learning <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/reinforcement-learning.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/reinforcement-learning.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h1>
<p>The final domain of learning we will review is known as reinforcement learning. The domain of reinforcement learning is one that many researchers seem to believe is offering a route to <em>general intelligence</em>. The idea of general intelligence is to develop algorithms that are adaptable to many different circumstances. Supervised learning algorithms are designed to resolve particular challenges. Data is annotated with those challenges in mind. Unsupervised attempts to build representations without any context. But normally the algorithm designer has an understanding of what the broader objective is and designs the algorithms accordingly (for example, characterizing users). In reinforcement learning some context is given, in the form of a reward, but the reward is normally delayed. There may have been many actions that affected the outcome, but which actions had a positive effect and which a negative effect?</p>
<h2 id="reward">“Reward”</h2>
<ul>
<li><p>In reinforcement learning some context is given, in the form of a reward. But it is often <em>delayed</em></p></li>
<li><p>Credit allocation problem: many actions that affected the outcome, but which actions had a positive effect and which a negative effect?</p></li>
</ul>
<p>One issue for many companies is that the best way of testing the customer experience, A/B testing, prioritizes short term reward. The internet is currently being driven by short term rewards which make it distracting in the short term, but perhaps less useful in the long term. Click-bait is an example, but there are more subtle effects. The success of Facebook is driven by its ability to draw us in when likely we should be doing something else. This is driven by large scale A/B testing.</p>
<p>One open question is how to drive non-visual interfaces through equivalents to A/B testing. Speech interfaces, such as those used in intelligent agents, are less amenable to A/B testing when determining the quality of the interface. Improving interaction with them is therefore less exact science than the visual interface. Data efficient reinforcement learning methods are likely to be key to improving these agent’s ability to interact with the user and understand intent. However, they are not yet mature enough to be deployed in this application.</p>
<h2 id="game-play">Game Play</h2>
<p><br />
An area where reinforcement learning methods have been deployed with high profile success is game play. In game play the reward is delayed to the end of the game, and it comes in the form of victory or defeat. A significant advantage of game play as an application area is that, through simulation of the game, it is possible to generate as much data as is required to solve the problem. For this reason, many of the recent advances in reinforcement learning have occurred with methods that are not data efficient.</p>
<p>The company DeepMind is set up around reinforcement learning as an approach to general intelligence. All their most well-known achievements are centered around artificial intelligence in game play. In reinforcement learning a decision made at any given time have a downstream effect on the result. Whether the effect if beneficial or not is unknown until a future moment.</p>
<p>We can think of reinforcement learning as providing a label, but the label is associated with a series of data involving a number of decisions taken. Each decision was taken given the understanding of game play at any given moment. Understanding which of these decisions was important in victory or defeat is a hard problem.</p>
<p>In machine learning the process of understanding which decisions were beneficial and which were detrimental is known as the credit allocation problem. You wish to reward decisions that led to success to encourage them, but punish decisions that lead to failure.</p>
<p>Broadly speaking, DeepMind uses an approach to Machine Learning where there are two mathematical functions at work. One determines the action to be taken at any given moment, the other estimates the quality of the board position at any given time. These are respectively known as the <em>policy network</em> and the <em>value network</em>.<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a> DeepMind made use of convolutional neural networks for both these models.</p>
<h2 id="alphago">AlphaGo</h2>
<p>The ancient Chinese game of Go was considered a challenge for artificial intelligence for two reasons. Firstly, the game tree has a very high branching factor. The game tree is a discrete representation of the game. Every node in the game tree is associated with a board position. You can move through the game tree by making legal a move on the board to change the position. In Go, there are so many legal moves that the game tree increases exponentially. This challenge in Go was addressed by using stochastic game tree search. Rather than exploring the game tree exhaustively they explored it randomly.</p>
<p>Secondly, evaluating the quality of any given board position was deemed to be very hard.<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a> The value function determines for each player whether they are winning or losing. Skilled Go players can assess a board position, but they do it by instinct, by intuition. Just as early AI researchers struggled to give rules for detecting cancer, it is challenging to give rules to assess a Go board. The machine learning approach that AlphaGo took is to train a value function network to make this assessment.</p>
<p>The approach that DeepMind took to conquering Go is a <em>model-free</em> approach known as <em>Q-learning</em>.<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a> The model-free approach refers to the fact that they don’t directly include a model of how the world evolves in the reinforcement learning algorithm. They make extensive use of the game tree, but they don’t model how it evolves. They do model the expected reward of each position in the game tree (the value function) but that is not the same as modeling how the game will proceed.</p>
<p>Reinforcement Learning and Classical Control</p>
<p>An alternative approach to reinforcement learning is to use a prediction function to suggest how the world will evolve in response to your actions. To predict how the game tree will evolve. You can then use this prediction to indirectly infer the expected reward associated with any action. This is known as <em>model-based</em> reinforcement learning.</p>
<p>This model-based approach is also closer to a control system. A classical control system is one where you give the system a set point. For example, a thermostat in the house. You set the temperature and the boiler switches off when it reaches it. Optimal control is about getting the house to the right temperature as quickly as possible. Classical control is widely used in robotic control and flight control.</p>
<p>One interesting crossover between classical control and machine learning arises because classical optimal control can be seen as a form of model-based reinforcement learning. One where the reward is recovered when the set point is reached. In control engineering the prediction function is known as the <em>transfer function</em>. The process of fitting the transfer function in control is known as <em>system identification</em>.</p>
<p>There is some exciting work emerging at the interface between the areas of control and reinforcement learning. Results at this interface could be very important for improving the quality of robotic and drone control.</p>
<h2 id="optimization-methods">Optimization Methods</h2>
<p>As we implied above, reinforcement learning can also used to improve user experience. In that case the reward is gained when the user buys a product from us. This makes it closely allied to the area of optimization. Optimization of our user interfaces can be seen as a reinforcement learning task, but more commonly it is thought about separately in the domains of <em>Bayesian optimization</em> or <em>bandit learning</em>.</p>
<p>We use optimization in machine learning to find the parameters of our models. We can do that because we have a mathematical representation of our objective function as a direct function of the parameters.</p>
<p>Examples in this form of optimization include, what is the best user interface for presenting adverts? What is the best design for a front wing for an F1 racing car? Which product should I return top of the list in response to this user’s search?</p>
<p>Bayesian optimization arises when we can’t directly relate the parameters in the system of interest to our objective through a mathematical function. For example, what is the mathematical function that relates a user’s experience to the probability that they will buy a product?</p>
<h2 id="bayesian-optimization">Bayesian Optimization</h2>
<p>One approach to these problems is to use machine learning methods to develop a <em>surrogate model</em> for the optimization task. The surrogate model is a prediction function that attempts to recreate the process we are finding hard to model. We try to simultaneously fit the surrogate model and optimize the process.</p>
<h2 id="surrogate-models">Surrogate Models</h2>
<p>Bayesian optimization methods use a <em>surrogate model</em> (normally a specific form of regression model). They use this to predict how the real system will perform. The surrogate model makes a prediction (with an estimate of the uncertainty) of what the response will be to any given input. Parameters to test are chosen by considering this prediction. Similar to reinforcement learning, this can be viewed as a <em>model-based</em> approach because the surrogate model can be seen as a model of the real world. In bandit methods strategies are determined without turning to a model to motivate them. They are <em>model free</em> methods.</p>
<h2 id="model-based-and-model-free-performance">Model-Based and Model Free: Performance</h2>
<p>Because of their different philosophies, if a class of prediction functions is chosen, then a model-based approach might have better average case performance. At least in terms of <em>data efficiency</em>. A model free approach may well have better worst-case performance though, because it makes less assumptions about the nature of the data. To put it another way, making assumptions about the data is helpful if they are right: and if the model is sensible they’ll be right on average. However, it is unhelpful if the model is wrong. Indeed, it could be actively damaging. Since we can’t usually guarantee the model is absolutely right, the worst-case performance of a model-based approach would be poor.</p>
<p>We have introduced a range of machine learning approaches by focusing on their use of mathematical functions to replace manually coded systems of rules. The important characteristic of machine learning is that the form of these functions, as dictated by their parameters, is determined by acquiring data from the real world.</p>
<h2 id="deployment-edit">Deployment <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/deployment.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/deployment.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<p>The methods we have introduced are roughly speaking introduced in order of difficulty of deployment. While supervised learning is more involved in terms of collection of data, it is the most straightforward method to deploy once that data is recovered. For this reason, a major focus with supervised learning should always be on maintaining data quality, increasing the efficiency and accountability<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a> of the data collection pipeline and the quality of features used.</p>
<p>You can also check my blog post on <a href="http://inverseprobability.com/2017/01/12/data-readiness-levels">“Data Readiness Levels”</a> You can also check my blog post on <a href="http://inverseprobability.com/2018/11/05/the-3ds-of-machine-learning-systems-design">“The 3Ds of Machine Learning Systems Design”</a></p>
<h2 id="where-to-deploy">Where to Deploy?</h2>
<p>In relation to what AI can and can’t do today Andrew Ng is quoted as saying:</p>
<blockquote>
<p>If a typical person can do a mental task with less than one second of thought, we can probably automate it using AI either now or in the near future.<a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a> Andrew Ng</p>
</blockquote>
<h2 id="is-this-right">Is this Right?</h2>
<p>I would broadly agree with this quote but only in the context of supervised learning. If a human expert takes around that amount of time, then it’s also likely we can acquire the data necessary to build a supervised learning algorithm that can emulate that human’s response.</p>
<p>The picture with regard to unsupervised learning and reinforcement learning is more clouded.</p>
<p>One observation is that for <em>supervised</em> learning we seem to be moving beyond the era where very deep machine learning expertise is required to deploy methods. A solid understanding of machine learning (say to Masters level) is certainly required, but the quality of the final result is likely more dependent on domain expertise and the quality of the data and the information processing pipeline. This seems part of a wider trend where some of the big successes in machine learning are moving rapidly from the domain of science to that of engineering.<a href="#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a></p>
<p>You can also check my blog post on <a href="http://inverseprobability.com/2016/11/29/new-directions-in-kernels-and-gaussian-processes">“New Directions in Kernels and Gaussian Processes”</a></p>
<p>So if we can only emulate tasks that humans take around a second to do, how are we managing to deliver on self driving cars? The answer is that we are constructing engineered systems from sub-components, each of which is a machine learning subsystem. But they are tied together as a component based system in line with our traditional engineering approach. This has an advantage that each component in the system can be verified before its inclusion. This is important for debugging and safety. But in practice we can expect these systems to be very brittle. A human adapts the way in which they drive the car across their lifetime. A human can react to other road users. In extreme situations, such as a car jacking, a human can set to one side normal patterns of behavior, and purposely crash their car to draw attention to the situation.</p>
<p>Supervised machine learning solutions are normally trained offline. They do not adapt when deployed because this makes them less verifiable. But this compounds the brittleness of our solutions. By deploying our solutions we actually change the environment in which they operate. Therefore, it’s important that they can be quickly updated to reflect changing circumstances. This updating happens offline. For a complex mechanical system, such as a delivery drone, extensive testing of the system may be required when any component is updated. It is therefore imperative that these data processing pipelines are well documented so that they can be redeployed on demand.</p>
<p>In practice there can be challenges with the false dichotomy between reproducibility and performance. It is likely that most of our data scientists are caring less about their ability to redeploy their pipelines and only about their ability to produce an algorithm that achieves a particular performance. A key question is how reproducible is that process? There is a <em>false</em> dichotomy because ensuring reproducibility will typically improve performance as it will make it easier to run a rigorous set of explorative experiments. A worry is that, currently, we do not have a way to quantify the scale of this potential problem within companies.</p>
<h2 id="model-choice">Model Choice</h2>
<p>Common to all machine learning methods is the initial choice of useful classes of functions. The deep learning revolution is associated with a particular class of mathematical functions that is proving very successful in what were seen to be challenging domains: speech, vision, language. This has meant that significant advances in problems that have been seen as hard have occurred in artificial intelligence.</p>
<!-- Machine learning solutions When we deploy our solutions in the real world, we find that the situation is more complex. ThereAnother potential problem with our rush to supervised learning solutions is the false dichotomy between reproducibility and performance. Across Amazon we are using data science to design solutions which are deployed into production.  -->
<!-- It also requires more expertise on the machine learning side to develop and deploy solutions in un, and requires more expertise.  -->
<!-- such as avoiding a crash, to deliberately ram into another vehicle -->
<!-- To deliver complex solutions, like self driving cars, many sub-components from a  -->
<!-- Domain expertise becomWith regard to deIn particular, we are moving beyond the era where there is a short -->
<h1 id="references">References</h1>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>GOFAI has its origins in the birth of computer science so it is unsurprising that logic should be the dominant paradigm. There was also a sense in which pure logic felt like it mapped well on to human reasoning. In practice, for any complex real world situation, the number of logical rules required causes an explosion in the <em>state space</em> of the system. This makes logical systems intractable in many applications.<a href="#fnref1" class="footnote-back">↩</a></p></li>
<li id="fn2"><p>Using the test data in your training procedure is a major error in any machine learning procedure. It is extremely dangerous as it gives a misleading assessment of the model performance. The <a href="http://inverseprobability.com/2015/06/04/baidu-on-imagenet">Baidu ImageNet scandal</a> was an example of a team competing in the ImageNet challenge which did this. The team had announced via the publication pre-print server Arxiv that they had a world-leading performance on the ImageNet challenge. This was reported in the mainstream media. Two weeks later the challenge organizers revealed that the team had created multiple accounts for checking their test performance more times than was permitted by the challenge rules. This was then reported as “AI’s first doping scandal”. The team lead was fired by Baidu.<a href="#fnref2" class="footnote-back">↩</a></p></li>
<li id="fn3"><p>These models are quite a lot more complex than the simple clustering we describe here. They represent a common ancestor through a cluster center that is then allowed to evolve over time through a mutation rate. The time of separation between different species is estimated via these mutation rates.<a href="#fnref3" class="footnote-back">↩</a></p></li>
<li id="fn4"><p>One way of thinking about this is to flip the model on its side. Instead of thinking about the <span class="math inline"><em>i</em></span>th subject and the <span class="math inline"><em>j</em></span>th characteristic. Assume that each product is the subject. So, the <span class="math inline"><em>j</em></span>th item is thought of as the subject, and each item’s characteristic is given by the rating from a particular user. In this case symmetries in the model show that the matrix <span class="math inline">$\weightMatrix$</span> can now be seen as a matrix of <em>latent variables</em> and the matrix <span class="math inline">$\latentMatrix$</span> can be seen as <em>factor loadings</em>. So, you can think of the method as simultaneously doing a dimensionality reduction on the products and the users. Recommender systems also use other approaches, some of them based on similarity measures. In a similarity measure-based recommender system the rating prediction is given by looking for similar products in the user profile and scoring the new product with a score that is a weighted sum of those products.<a href="#fnref4" class="footnote-back">↩</a></p></li>
<li id="fn5"><p>The interpretation requires you to think of the web as a series of web pages in a high dimensional space where distances between web pages are computed by moving along the links (in either direction). The PageRank is the one-dimensional space that best preserves those distances in the sense of an L1 norm. The interpretation works because the smallest eigenvalue of the linkage matrix is the <em>largest</em> eigenvalue of the inverse of the linkage matrix. The inverse linkage matrix (which would be impossible to compute) embeds similarities between pages according to how far apart they are via a random walk along the linkage matrix.<a href="#fnref5" class="footnote-back">↩</a></p></li>
<li id="fn6"><p>The approach was described early on in the history of machine learning by Chris Watkins, during his PhD thesis in the 1980s. It is known as Q-learning. It’s recent success in the games domain is driven by the use of deep learning for the policy and value functions as well as the use of fast compute to generate and process very large quantities of data. In its standard form it is not seen as a very data-efficient approach.<a href="#fnref6" class="footnote-back">↩</a></p></li>
<li id="fn7"><p>The situation in chess is much easier, firstly the number of possible moves at any time is about an order of magnitude lower, meaning the game tree doesn’t grow as quickly. Secondly, in chess, there are well defined value functions. For example, a value function could be based on adding together the points that are associated with each piece.<a href="#fnref7" class="footnote-back">↩</a></p></li>
<li id="fn8"><p>The approach was described early on in the history of machine learning by Chris Watkins, during his PhD thesis in the 1980s. It is known as Q-learning. It’s recent success in the games domain is driven by the use of deep learning for the policy and value functions as well as the use of fast compute to generate and process very large quantities of data. In its standard form it is not seen as a very data-efficient approach.<a href="#fnref8" class="footnote-back">↩</a></p></li>
<li id="fn9"><p>To try and better embody the state of data readiness in organizations I’ve been proposing “Data Readiness Levels”. More needs to be done in this area to improve the efficiency of the data science pipeline.<a href="#fnref9" class="footnote-back">↩</a></p></li>
<li id="fn10"><p>The quote can be found in the Harvard Business Review Article <a href="https://hbr.org/2016/11/what-artificial-intelligence-can-and-cant-do-right-now">“What Artificial Intelligence Can and Can’t Do Right Now”</a>.<a href="#fnref10" class="footnote-back">↩</a></p></li>
<li id="fn11"><p>This trend was very clear at the moment, <a href="%7B%7Bsite.baseurl%20%7D%7D/">I spoke about it</a> at a recent Dagstuhl workshop on new directions for kernel methods and Gaussian processes.<a href="#fnref11" class="footnote-back">↩</a></p></li>
</ol>
</section>



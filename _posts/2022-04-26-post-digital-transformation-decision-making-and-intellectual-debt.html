---
title: "Post-Digital Transformation, Decision Making and Intellectual Debt"
venue: "Cambridge Senior Management Programme, Judge Business School, University of Cambridge"
abstract: "<p>Digital transformation has offered the promise of moving from a manual decision-making world to a world where decisions can be rational, data-driven and automated. The first step to digital transformation is mapping the world of atoms (material, customers, logistic networks) into the world of bits.</p>
<p>I’ll discuss how the artificial systems we have developed operate in a fundamentally different way to our own intelligence. I’ll describe how this difference in operational capability leads us to misunderstand the influence the nature of decisions made by machine intelligence.</p>
<p>Developing this understanding is important in integrating human decisions with those from the machine. These ideas are designed to help with the challenge of ‘post digital transformation’: doing business in a digital world.</p>"
author:
- given: Neil D.
  family: Lawrence
  url: http://inverseprobability.com
  institute: University of Cambridge
  twitter: lawrennd
  gscholar: r3SJcvoAAAAJ
  orcid: null
edit_url: https://github.com/lawrennd/talks/edit/gh-pages/_business/post-digital-transformation-decision-making-and-intellectual-debt.md
date: 2022-04-26
published: 2022-04-26
week: 0
reveal: 2022-04-26-post-digital-transformation-decision-making-and-intellectual-debt.slides.html
ipynb: 2022-04-26-post-digital-transformation-decision-making-and-intellectual-debt.ipynb
edit_url: https://github.com/lawrennd/talks/edit/gh-pages/_business/post-digital-transformation-decision-making-and-intellectual-debt.md
layout: talk
categories:
- notes
---



<!-- Do not edit this file locally. -->
<!---->
<!-- Do not edit this file locally. -->
<!-- Do not edit this file locally. -->
<!-- The last names to be defined. Should be defined entirely in terms of macros from above-->
<!--

-->
<h1 id="introduction">Introduction</h1>
<h2 id="pre-read-material">Pre-Read Material</h2>
<p>{Please watch <a href="https://www.youtube.com/watch?v=ubq3ayuG2EY">this excerpt</a> from the Lex Friedman podcast, interviewing with the roboticist Rodney Brooks. Please read this <a href="https://medium.com/berkman-klein-center/from-technical-debt-to-intellectual-debt-in-ai-e05ac56a502c">blog post by Jonathan Zittrain on Intellectual Debt</a>.</p>
<h2 id="setup">Setup</h2>
<!--setupplotcode{import seaborn as sns
sns.set_style('darkgrid')
sns.set_context('paper')
sns.set_palette('colorblind')}-->
<h2 id="notutils">notutils</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_software/includes/notutils-software.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_software/includes/notutils-software.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>This small package is a helper package for various notebook utilities used</p>
<p>The software can be installed using</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>pip install notutils</span></code></pre></div>
<p>from the command prompt where you can access your python installation.</p>
<p>The code is also available on GitHub: <a href="https://github.com/lawrennd/notutils" class="uri">https://github.com/lawrennd/notutils</a></p>
<p>Once <code>notutils</code> is installed, it can be imported in the usual manner.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> notutils</span></code></pre></div>
<h2 id="the-gartner-hype-cycle">The Gartner Hype Cycle</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_data-science/includes/gartner-hype-cycle.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_data-science/includes/gartner-hype-cycle.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<div class="figure">
<div id="gartner-hype-cycle-figure" class="figure-frame">
<object class="svgplot " data="https://inverseprobability.com/talks/./slides/diagrams//Gartner_Hype_Cycle.svg" width="80%" style=" ">
</object>
</div>
<div id="gartner-hype-cycle-magnify" class="magnify" onclick="magnifyFigure(&#39;gartner-hype-cycle&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="gartner-hype-cycle-caption" class="caption-frame">
<p>Figure: The Gartner Hype Cycle places technologies on a graph that relates to the expectations we have of a technology against its actual influence. Early hope for a new techology is often displaced by disillusionment due to the time it takes for a technology to be usefully deployed.</p>
</div>
</div>
<p>The <a href="https://en.wikipedia.org/wiki/Hype_cycle">Gartner Hype Cycle</a> tries to assess where an idea is in terms of maturity and adoption. It splits the evolution of technology into a technological trigger, a peak of expectations followed by a trough of disillusionment and a final ascension into a useful technology. It looks rather like a classical control response to a final set point.</p>
<h2 id="cycle-for-ml-terms">Cycle for ML Terms</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_data-science/includes/gartner-hype-cycle-ai-bd-dm-dl-ml.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_data-science/includes/gartner-hype-cycle-ai-bd-dm-dl-ml.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<h2 id="google-trends">Google Trends</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_data-science/includes/gartner-hype-cycle-base.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_data-science/includes/gartner-hype-cycle-base.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>pip install pytrends</span></code></pre></div>
<div class="figure">
<div id="ai-bd-dm-dl-ml-gartner-hype-cycle-google-trends-figure" class="figure-frame">
<object class="svgplot " data="https://inverseprobability.com/talks/./slides/diagrams//data-science/ai-bd-dm-dl-ml-google-trends.svg" width="80%" style=" ">
</object>
</div>
<div id="ai-bd-dm-dl-ml-gartner-hype-cycle-google-trends-magnify" class="magnify" onclick="magnifyFigure(&#39;ai-bd-dm-dl-ml-gartner-hype-cycle-google-trends&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="ai-bd-dm-dl-ml-gartner-hype-cycle-google-trends-caption" class="caption-frame">
<p>Figure: Google trends for ‘artificial intelligence,’ ‘big data,’ ‘data mining,’ ‘deep learning,’ ‘machine learning’ as different technological terms gives us insight into their popularity over time.</p>
</div>
</div>
<p>Google trends gives us insight into the interest for different terms over time.</p>
<p>Examining Google treds for ‘artificial intelligence,’ ‘big data,’ ‘data mining,’ ‘deep learning’ and ‘machine learning’ we can see that ‘artificial intelligence’ <em>may</em> be entering a plateau of productivity, ‘big data’ is entering the trough of disillusionment, and ‘data mining’ seems to be deeply within the trough. On the other hand, ‘deep learning’ and ‘machine learning’ appear to be ascending to the peak of inflated expectations having experienced a technology trigger.</p>
<p>For deep learning that technology trigger was the ImageNet result of 2012 <span class="citation" data-cites="Krizhevsky:imagenet12">(Krizhevsky et al., n.d.)</span>. This step change in performance on object detection in images was achieved through convolutional neural networks, popularly known as ‘deep learning.’</p>
<h1 id="what-is-machine-learning">What is Machine Learning?</h1>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/what-is-ml.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/what-is-ml.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>What is machine learning? At its most basic level machine learning is a combination of</p>
<p><span class="math display">\[\text{data} + \text{model} \stackrel{\text{compute}}{\rightarrow} \text{prediction}\]</span></p>
<p>where <em>data</em> is our observations. They can be actively or passively acquired (meta-data). The <em>model</em> contains our assumptions, based on previous experience. That experience can be other data, it can come from transfer learning, or it can merely be our beliefs about the regularities of the universe. In humans our models include our inductive biases. The <em>prediction</em> is an action to be taken or a categorization or a quality score. The reason that machine learning has become a mainstay of artificial intelligence is the importance of predictions in artificial intelligence. The data and the model are combined through computation.</p>
<p>In practice we normally perform machine learning using two functions. To combine data with a model we typically make use of:</p>
<p><strong>a prediction function</strong> a function which is used to make the predictions. It includes our beliefs about the regularities of the universe, our assumptions about how the world works, e.g., smoothness, spatial similarities, temporal similarities.</p>
<p><strong>an objective function</strong> a function which defines the cost of misprediction. Typically, it includes knowledge about the world’s generating processes (probabilistic objectives) or the costs we pay for mispredictions (empirical risk minimization).</p>
<p>The combination of data and model through the prediction function and the objective function leads to a <em>learning algorithm</em>. The class of prediction functions and objective functions we can make use of is restricted by the algorithms they lead to. If the prediction function or the objective function are too complex, then it can be difficult to find an appropriate learning algorithm. Much of the academic field of machine learning is the quest for new learning algorithms that allow us to bring different types of models and data together.</p>
<p>A useful reference for state of the art in machine learning is the UK Royal Society Report, <a href="https://royalsociety.org/~/media/policy/projects/machine-learning/publications/machine-learning-report.pdf">Machine Learning: Power and Promise of Computers that Learn by Example</a>.</p>
<p>You can also check my post blog post on <a href="http://inverseprobability.com/2017/07/17/what-is-machine-learning">What is Machine Learning?</a>.</p>
<h2 id="artificial-intelligence-and-data-science">Artificial Intelligence and Data Science</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ai/includes/ai-vs-data-science-2.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ai/includes/ai-vs-data-science-2.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>Artificial intelligence has the objective of endowing computers with human-like intelligent capabilities. For example, understanding an image (computer vision) or the contents of some speech (speech recognition), the meaning of a sentence (natural language processing) or the translation of a sentence (machine translation).</p>
<h3 id="supervised-learning-for-ai">Supervised Learning for AI</h3>
<p>The machine learning approach to artificial intelligence is to collect and annotate a large data set from humans. The problem is characterized by input data (e.g. a particular image) and a label (e.g. is there a car in the image yes/no). The machine learning algorithm fits a mathematical function (I call this the <em>prediction function</em>) to map from the input image to the label. The parameters of the prediction function are set by minimizing an error between the function’s predictions and the true data. This mathematical function that encapsulates this error is known as the <em>objective function</em>.</p>
<p>This approach to machine learning is known as <em>supervised learning</em>. Various approaches to supervised learning use different prediction functions, objective functions or different optimization algorithms to fit them.</p>
<p>For example, <em>deep learning</em> makes use of <em>neural networks</em> to form the predictions. A neural network is a particular type of mathematical function that allows the algorithm designer to introduce invariances into the function.</p>
<p>An invariance is an important way of including prior understanding in a machine learning model. For example, in an image, a car is still a car regardless of whether it’s in the upper left or lower right corner of the image. This is known as translation invariance. A neural network encodes translation invariance in <em>convolutional layers</em>. Convolutional neural networks are widely used in image recognition tasks.</p>
<p>An alternative structure is known as a recurrent neural network (RNN). RNNs neural networks encode temporal structure. They use auto regressive connections in their hidden layers, they can be seen as time series models which have non-linear auto-regressive basis functions. They are widely used in speech recognition and machine translation.</p>
<p>Machine learning has been deployed in Speech Recognition (e.g. Alexa, deep neural networks, convolutional neural networks for speech recognition), in computer vision (e.g. Amazon Go, convolutional neural networks for person recognition and pose detection).</p>
<p>The field of data science is related to AI, but philosophically different. It arises because we are increasingly creating large amounts of data through <em>happenstance</em> rather than active collection. In the modern era data is laid down by almost all our activities. The objective of data science is to extract insights from this data.</p>
<p>Classically, in the field of statistics, data analysis proceeds by assuming that the question (or scientific hypothesis) comes before the data is created. E.g., if I want to determine the effectiveness of a particular drug, I perform a <em>design</em> for my data collection. I use foundational approaches such as randomization to account for confounders. This made a lot of sense in an era where data had to be actively collected. The reduction in cost of data collection and storage now means that many data sets are available which weren’t collected with a particular question in mind. This is a challenge because bias in the way data was acquired can corrupt the insights we derive. We can perform randomized control trials (or A/B tests) to verify our conclusions, but the opportunity is to use data science techniques to better guide our question selection or even answer a question without the expense of a full randomized control trial (referred to as A/B testing in modern internet parlance).</p>
<h1 id="embodiment-and-intellectual-debt">Embodiment and Intellectual Debt</h1>
<div class="figure">
<div id="cappella-sistina-ceiling-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="https://inverseprobability.com/talks/./slides/diagrams//art/sistine-chapel-ceiling.jpg" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="cappella-sistina-ceiling-magnify" class="magnify" onclick="magnifyFigure(&#39;cappella-sistina-ceiling&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="cappella-sistina-ceiling-caption" class="caption-frame">
<p>Figure: The ceiling of the Sistine Chapel.</p>
</div>
</div>
<p><a href="https://www.mmll.cam.ac.uk/pb127">Patrick Boyde</a>’s talks on the Sistine Chapel focussed on both the structure of the chapel ceiling, describing the impression of height it was intended to give, as well as the significance and positioning of each of the panels and the meaning of the individual figures.</p>
<div class="figure">
<div id="the-creation-of-man-michelangelo-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="https://inverseprobability.com/talks/./slides/diagrams//art/the-creation-of-man-michelangelo.jpg" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="the-creation-of-man-michelangelo-magnify" class="magnify" onclick="magnifyFigure(&#39;the-creation-of-man-michelangelo&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="the-creation-of-man-michelangelo-caption" class="caption-frame">
<p>Figure: Photo of Detail of Creation of Man from the Sistine chapel ceiling.</p>
</div>
</div>
<p>One of the most famous panels is central in the ceiling, it’s the creation of man. Here, God in the guise of a pink-robed bearded man reaches out to a languid Adam.</p>
<p>The representation of God in this form seems typical of the time, because elsewhere in the Vatican Museums there are similar representations.</p>
<div class="figure">
<div id="the-creation-of-man-detail-god-michelangelo-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="https://inverseprobability.com/talks/./slides/diagrams//art/the-creation-of-man-detail-god-michelangelo.jpg" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="the-creation-of-man-detail-god-michelangelo-magnify" class="magnify" onclick="magnifyFigure(&#39;the-creation-of-man-detail-god-michelangelo&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="the-creation-of-man-detail-god-michelangelo-caption" class="caption-frame">
<p>Figure: Photo detail of God.</p>
</div>
</div>
<p><a href="https://commons.wikimedia.org/wiki/File:Michelangelo,_Creation_of_Adam_04.jpg" class="uri">https://commons.wikimedia.org/wiki/File:Michelangelo,_Creation_of_Adam_04.jpg</a></p>
<p>For a time at the head of all articles about AI, an <a href="https://www.flickr.com/photos/tom-margie/2144882415/sizes/o/">image of the terminator</a> was included.</p>
<div class="figure">
<div id="terminator-image-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="https://inverseprobability.com/talks/./slides/diagrams//ai/terminator-image.jpg" width="70%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="terminator-image-magnify" class="magnify" onclick="magnifyFigure(&#39;terminator-image&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="terminator-image-caption" class="caption-frame">
<p>Figure: Image of James Cameron’s terminator. Images like this have been used to illustrate articles about artificial intelligence.</p>
</div>
</div>
<p>Sometimes, this image is even combined with that of God to create what <a href="https://bvsingler.com">Beth Singler</a>, a digital anthropologist who is a JRF at Hmerton College, refers to as the creation meme <span class="citation" data-cites="Singler-aicreation20">(Singler, 2020)</span>.</p>
<div class="figure">
<div id="beth-singler-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="https://inverseprobability.com/talks/./slides/diagrams//people/beth-singler.jpg" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="beth-singler-magnify" class="magnify" onclick="magnifyFigure(&#39;beth-singler&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="beth-singler-caption" class="caption-frame">
<p>Figure: Beth Singler is a digital anthropologist who holds a JRF at Homerton College. She has explored parallels between the Michelangelo image of creation and our own notion of robotic creation</p>
</div>
</div>
<p>So in a very real sense, we can see that both God and AI are viewed by us as embodied intelligences, whether creator or created. We show these other-intelligences in a humanoid form.</p>
<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-Krizhevsky:imagenet12" class="csl-entry" role="doc-biblioentry">
Krizhevsky, A., Sutskever, I., Hinton, G.E., n.d. ImageNet classification with deep convolutional neural networks. pp. 1097–1105.
</div>
<div id="ref-Singler-aicreation20" class="csl-entry" role="doc-biblioentry">
Singler, B., 2020. The AI creation meme: A case study of the new visibility of religion in artificial intelligence discourse. Religions 11. <a href="https://doi.org/10.3390/rel11050253">https://doi.org/10.3390/rel11050253</a>
</div>
</div>


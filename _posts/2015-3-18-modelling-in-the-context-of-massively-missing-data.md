---
:bibtex_key: Lawrence:mpi15
:bibtex_type: :talk
:author: Lawrence, Neil D.
:title: Modelling in the Context of Massively Missing Data
:abstract: In the age of large streaming data it seems appropriate to revisit the
  foundations of what we think of as data modelling. In this talk I'll argue that
  traditional statistical approaches based on parametric models and i.i.d. assumptions
  are inappropriate for the type of large scale machine learning we need to do in
  the age of massive streaming data sets. Particularly when we realise that regardless
  of the size of data we have, it pales in comparison to the data we could have. This
  is the domain of \emph{massively missing data}. I'll be arguing for flexible non-parametric
  models as the answer. This presents a particular challenge, non parametric models
  require data storage of the entire data set, which presents problems for massive,
  streaming data. I will present a potential solution, but perhaps end with more questions
  than we started with.
:venue: Max Planck Institute, T\"ubingen
:linkpdf: '"http://staffwww.dcs.shef.ac.uk/people/N.Lawrence/talks/" # "missingdata_tuebingen15.pdf"'
:ipynb: '"github.com/SheffieldML/notebook/blob/master/" # "lab_classes/gprs/Low%20Rank%20Gaussian%20Processes.ipynb"'
:year: '2015'
:month: mar
:day: '18'
:month_numeric: '3'
---

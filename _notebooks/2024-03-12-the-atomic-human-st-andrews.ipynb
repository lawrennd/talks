{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Atomic Human\n",
    "\n",
    "### [Neil D. Lawrence](http://inverseprobability.com), University of\n",
    "\n",
    "Cambridge\n",
    "\n",
    "### 2024-03-12"
   ],
   "id": "c424bff0-2c1a-4d09-a8d9-6b1d5297ff5b"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Abstract**: A vital perspective is missing from the discussions we’re\n",
    "having about Artificial Intelligence: what does it mean for our\n",
    "identity?\n",
    "\n",
    "Our fascination with AI stems from the perceived uniqueness of human\n",
    "intelligence. We believe it’s what differentiates us. Fears of AI not\n",
    "only concern how it invades our digital lives, but also the implied\n",
    "threat of an intelligence that displaces us from our position at the\n",
    "centre of the world.\n",
    "\n",
    "Atomism, proposed by Democritus, suggested it was impossible to continue\n",
    "dividing matter down into ever smaller components: eventually we reach a\n",
    "point where a cut cannot be made (the Greek for uncuttable is ‘atom’).\n",
    "In the same way, by slicing away at the facets of human intelligence\n",
    "that can be replaced by machines, AI uncovers what is left: an\n",
    "indivisible core that is the essence of humanity.\n",
    "\n",
    "By contrasting our own (evolved, locked-in, embodied) intelligence with\n",
    "the capabilities of machine intelligence through history, The Atomic\n",
    "Human reveals the technical origins, capabilities and limitations of AI\n",
    "systems, and how they should be wielded. Not just by the experts, but\n",
    "ordinary people. Either AI is a tool for us, or we become a tool of AI.\n",
    "Understanding this will enable us to choose the future we want.\n",
    "\n",
    "This talk is based on Neil’s forthcoming book to be published with Allen\n",
    "Lane in June 2024. Machine learning solutions, in particular those based\n",
    "on deep learning methods, form an underpinning of the current revolution\n",
    "in “artificial intelligence” that has dominated popular press headlines\n",
    "and is having a significant influence on the wider tech agenda.\n",
    "\n",
    "In this talk I will give an overview of where we are now with machine\n",
    "learning solutions, and what challenges we face both in the near and far\n",
    "future. These include practical application of existing algorithms in\n",
    "the face of the need to explain decision making, mechanisms for\n",
    "improving the quality and availability of data, dealing with large\n",
    "unstructured datasets."
   ],
   "id": "709f30a7-1dfe-4e99-9ab0-11192f20db51"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "$$"
   ],
   "id": "080ffcbd-cf00-4e21-b6b1-6576902e816e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.cell .markdown}\n",
    "\n",
    "<!-- Do not edit this file locally. -->\n",
    "<!-- Do not edit this file locally. -->\n",
    "<!---->\n",
    "<!-- Do not edit this file locally. -->\n",
    "<!-- Do not edit this file locally. -->\n",
    "<!-- The last names to be defined. Should be defined entirely in terms of macros from above-->\n",
    "<!--\n",
    "\n",
    "-->"
   ],
   "id": "67690ca3-e481-479b-a4eb-e3c010b85e29"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Henry Ford’s Faster Horse\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_ai/includes/henry-ford-intro.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/henry-ford-intro.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//ai/1925_Ford_Model_T_touring.jpg\" style=\"width:70%\">\n",
    "\n",
    "Figure: <i>A 1925 Ford Model T built at Henry Ford’s Highland Park Plant\n",
    "in Dearborn, Michigan. This example now resides in Australia, owned by\n",
    "the founder of FordModelT.net. From\n",
    "<https://commons.wikimedia.org/wiki/File:1925_Ford_Model_T_touring.jpg></i>\n",
    "\n",
    "It’s said that Henry Ford’s customers wanted a “a faster horse”. If\n",
    "Henry Ford was selling us artificial intelligence today, what would the\n",
    "customer call for, “a smarter human”? That’s certainly the picture of\n",
    "machine intelligence we find in science fiction narratives, but the\n",
    "reality of what we’ve developed is much more mundane.\n",
    "\n",
    "Car engines produce prodigious power from petrol. Machine intelligences\n",
    "deliver decisions derived from data. In both cases the scale of\n",
    "consumption enables a speed of operation that is far beyond the\n",
    "capabilities of their natural counterparts. Unfettered energy\n",
    "consumption has consequences in the form of climate change. Does\n",
    "unbridled data consumption also have consequences for us?\n",
    "\n",
    "If we devolve decision making to machines, we depend on those machines\n",
    "to accommodate our needs. If we don’t understand how those machines\n",
    "operate, we lose control over our destiny. Our mistake has been to see\n",
    "machine intelligence as a reflection of our intelligence. We cannot\n",
    "understand the smarter human without understanding the human. To\n",
    "understand the machine, we need to better understand ourselves."
   ],
   "id": "500cf0c6-ac59-4a20-87a8-5815d13d3caf"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Diving Bell and the Butterfly\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_books/includes/the-diving-bell-and-the-butterfly.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_books/includes/the-diving-bell-and-the-butterfly.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//ai/the-diving-bell-and-the-butterfly.jpg\" style=\"width:40%\">\n",
    "\n",
    "Figure: <i>The Diving Bell and the Buttefly is the autobiography of Jean\n",
    "Dominique Bauby.</i>\n",
    "\n",
    "[The Diving Bell and the\n",
    "Butterfly](https://www.penguinrandomhouse.com/books/9616/the-diving-bell-and-the-butterfly-by-jean-dominique-bauby/)\n",
    "is the autobiography of Jean Dominique Bauby. Jean Dominique, the editor\n",
    "of French Elle magazine, suffered a major stroke at the age of 43 in\n",
    "1995. The stroke paralyzed him and rendered him speechless. He was only\n",
    "able to blink his left eyelid, he became a sufferer of locked in\n",
    "syndrome.\n",
    "\n",
    "E S A R I N T U L <br> O M D P C F B V <br> H G J Q Z Y X K W\n",
    "\n",
    "Figure: <i>The ordering of the letters that Bauby used for writing his\n",
    "autobiography.</i>\n",
    "\n",
    "How could he do that? Well, first, they set up a mechanism where he\n",
    "could scan across letters and blink at the letter he wanted to use. In\n",
    "this way, he was able to write each letter.\n",
    "\n",
    "It took him 10 months of four hours a day to write the book. Each word\n",
    "took two minutes to write.\n",
    "\n",
    "Imagine doing all that thinking, but so little speaking, having all\n",
    "those thoughts and so little ability to communicate.\n",
    "\n",
    "The idea behind this talk is that we are all in that situation. While\n",
    "not as extreme as for Bauby, we all have somewhat of a locked in\n",
    "intelligence.\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//ai/Jean-Dominique_Bauby.jpg\" style=\"width:70%\">\n",
    "\n",
    "Figure: <i>Jean Dominique Bauby was the Editor in Chief of the French\n",
    "Elle Magazine, he suffered a stroke that destroyed his brainstem,\n",
    "leaving him only capable of moving one eye. Jean Dominique became a\n",
    "victim of locked in syndrome.</i>\n",
    "\n",
    "Incredibly, Jean Dominique wrote his book after he became locked in. It\n",
    "took him 10 months of four hours a day to write the book. Each word took\n",
    "two minutes to write.\n",
    "\n",
    "The idea behind embodiment factors is that we are all in that situation.\n",
    "While not as extreme as for Bauby, we all have somewhat of a locked in\n",
    "intelligence.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td width>\n",
    "<center>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//ai/Jean-Dominique_Bauby.jpg\" style=\"width:100%\">\n",
    "\n",
    "</center>\n",
    "</td>\n",
    "<td width>\n",
    "<center>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//ClaudeShannon_MFO3807.jpg\" style=\"width:70%\">\n",
    "\n",
    "</center>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Figure: <i>Claude Shannon developed information theory which allows us\n",
    "to quantify how much Bauby can communicate. This allows us to compare\n",
    "how locked in he is to us.</i>"
   ],
   "id": "c23c51a9-9a58-4b87-80f9-b89085577dfa"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Atomic Human\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_ai/includes/the-atomic-eye.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/the-atomic-eye.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//ai/atomic-eye.png\" style=\"width:80%\">\n",
    "\n",
    "Figure: <i>The Atomic Eye, by slicing away aspects of the human that we\n",
    "used to believe to be unique to us, but are now the preserve of the\n",
    "machine, we learn something about what it means to be human.</i>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//computing/Colossus.jpg\" style=\"width:70%\">\n",
    "\n",
    "Figure: <i>A Colossus Mark 2 codebreaking computer being operated by\n",
    "Dorothy Du Boisson (left) and Elsie Booker (right). Colossus was\n",
    "designed by Tommy Flowers, but programmed and operated by groups of\n",
    "Wrens based at Bletchley Park.</i>"
   ],
   "id": "734c0f5b-a396-4813-b760-f9059b7e0f14"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embodiment Factors\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_ai/includes/embodiment-factors-short.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/embodiment-factors-short.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td>\n",
    "</td>\n",
    "<td align=\"center\">\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//ai/processor.svg\" class=\"\" width=\"15%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "</td>\n",
    "<td align=\"center\">\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//human.svg\" class=\"\" width=\"60%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "\n",
    "bits/min\n",
    "\n",
    "</td>\n",
    "<td align=\"center\">\n",
    "\n",
    "billions\n",
    "\n",
    "</td>\n",
    "<td align=\"center\">\n",
    "\n",
    "2,000\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "\n",
    "billion <br>calculations/s\n",
    "\n",
    "</td>\n",
    "<td align=\"center\">\n",
    "\n",
    "~100\n",
    "\n",
    "</td>\n",
    "<td align=\"center\">\n",
    "\n",
    "a billion\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>\n",
    "\n",
    "embodiment\n",
    "\n",
    "</td>\n",
    "<td align=\"center\">\n",
    "\n",
    "20 minutes\n",
    "\n",
    "</td>\n",
    "<td align=\"center\">\n",
    "\n",
    "5 billion years\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Figure: <i>Embodiment factors are the ratio between our ability to\n",
    "compute and our ability to communicate. Relative to the machine we are\n",
    "also locked in. In the table we represent embodiment as the length of\n",
    "time it would take to communicate one second’s worth of computation. For\n",
    "computers it is a matter of minutes, but for a human, it is a matter of\n",
    "thousands of millions of years. See also “Living Together: Mind and\n",
    "Machine Intelligence” Lawrence (2017)</i>\n",
    "\n",
    "There is a fundamental limit placed on our intelligence based on our\n",
    "ability to communicate. Claude Shannon founded the field of information\n",
    "theory. The clever part of this theory is it allows us to separate our\n",
    "measurement of information from what the information pertains to.[1]\n",
    "\n",
    "Shannon measured information in bits. One bit of information is the\n",
    "amount of information I pass to you when I give you the result of a coin\n",
    "toss. Shannon was also interested in the amount of information in the\n",
    "English language. He estimated that on average a word in the English\n",
    "language contains 12 bits of information.\n",
    "\n",
    "Given typical speaking rates, that gives us an estimate of our ability\n",
    "to communicate of around 100 bits per second (Reed and Durlach, 1998).\n",
    "Computers on the other hand can communicate much more rapidly. Current\n",
    "wired network speeds are around a billion bits per second, ten million\n",
    "times faster.\n",
    "\n",
    "When it comes to compute though, our best estimates indicate our\n",
    "computers are slower. A typical modern computer can process make around\n",
    "100 billion floating-point operations per second, each floating-point\n",
    "operation involves a 64 bit number. So the computer is processing around\n",
    "6,400 billion bits per second.\n",
    "\n",
    "It’s difficult to get similar estimates for humans, but by some\n",
    "estimates the amount of compute we would require to *simulate* a human\n",
    "brain is equivalent to that in the UK’s fastest computer\n",
    "(Ananthanarayanan et al., 2009), the MET office machine in Exeter, which\n",
    "in 2018 ranked as the 11th fastest computer in the world. That machine\n",
    "simulates the world’s weather each morning, and then simulates the\n",
    "world’s climate in the afternoon. It is a 16-petaflop machine,\n",
    "processing around 1,000 *trillion* bits per second.\n",
    "\n",
    "[1] the challenge of understanding what information pertains to is known\n",
    "as knowledge representation."
   ],
   "id": "b7f68d2c-54f0-4da2-bee6-7396f195eef0"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Flow of Information\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_data-science/includes/new-flow-of-information.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_data-science/includes/new-flow-of-information.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "Classically the field of statistics focused on mediating the\n",
    "relationship between the machine and the human. Our limited bandwidth of\n",
    "communication means we tend to over-interpret the limited information\n",
    "that we are given, in the extreme we assign motives and desires to\n",
    "inanimate objects (a process known as anthropomorphizing). Much of\n",
    "mathematical statistics was developed to help temper this tendency and\n",
    "understand when we are valid in drawing conclusions from data.\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//data-science/new-flow-of-information003.svg\" class=\"\" width=\"70%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>The trinity of human, data, and computer, and highlights the\n",
    "modern phenomenon. The communication channel between computer and data\n",
    "now has an extremely high bandwidth. The channel between human and\n",
    "computer and the channel between data and human is narrow. New direction\n",
    "of information flow, information is reaching us mediated by the\n",
    "computer. The focus on classical statistics reflected the importance of\n",
    "the direct communication between human and data. The modern challenges\n",
    "of data science emerge when that relationship is being mediated by the\n",
    "machine.</i>\n",
    "\n",
    "Data science brings new challenges. In particular, there is a very large\n",
    "bandwidth connection between the machine and data. This means that our\n",
    "relationship with data is now commonly being mediated by the machine.\n",
    "Whether this is in the acquisition of new data, which now happens by\n",
    "happenstance rather than with purpose, or the interpretation of that\n",
    "data where we are increasingly relying on machines to summarize what the\n",
    "data contains. This is leading to the emerging field of data science,\n",
    "which must not only deal with the same challenges that mathematical\n",
    "statistics faced in tempering our tendency to over interpret data but\n",
    "must also deal with the possibility that the machine has either\n",
    "inadvertently or maliciously misrepresented the underlying data."
   ],
   "id": "36015822-5683-4922-a1a1-932c9fc1f60c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bandwidth Constrained Conversations\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_ai/includes/anne-bob-talk.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/anne-bob-talk.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
   ],
   "id": "02419f6d-6511-4a7d-9749-9f95b89281a1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import notutils as nu\n",
    "from ipywidgets import IntSlider"
   ],
   "id": "b12acf35-8639-4e83-8caf-93fbe5546e66"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import notutils as nu"
   ],
   "id": "0a500e2f-4881-4843-a609-402a18253c24"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nu.display_plots('anne-bob-conversation{sample:0>3}.svg', \n",
    "                            'https://inverseprobability.com/talks/../slides/diagrams/',  sample=IntSlider(0, 0, 7, 1))"
   ],
   "id": "ffc7dcf4-fc78-4bfa-bd5b-011de2029ee9"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//anne-bob-conversation006.svg\" class=\"\" width=\"70%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Conversation relies on internal models of other\n",
    "individuals.</i>\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//anne-bob-conversation007.svg\" class=\"\" width=\"70%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Misunderstanding of context and who we are talking to leads\n",
    "to arguments.</i>\n",
    "\n",
    "Embodiment factors imply that, in our communication between humans, what\n",
    "is *not* said is, perhaps, more important than what is said. To\n",
    "communicate with each other we need to have a model of who each of us\n",
    "are.\n",
    "\n",
    "To aid this, in society, we are required to perform roles. Whether as a\n",
    "parent, a teacher, an employee or a boss. Each of these roles requires\n",
    "that we conform to certain standards of behaviour to facilitate\n",
    "communication between ourselves.\n",
    "\n",
    "Control of self is vitally important to these communications.\n",
    "\n",
    "The high availability of data available to humans undermines\n",
    "human-to-human communication channels by providing new routes to\n",
    "undermining our control of self.\n",
    "\n",
    "The consequences between this mismatch of power and delivery are to be\n",
    "seen all around us. Because, just as driving an F1 car with bicycle\n",
    "wheels would be a fine art, so is the process of communication between\n",
    "humans.\n",
    "\n",
    "If I have a thought and I wish to communicate it, I first need to have a\n",
    "model of what you think. I should think before I speak. When I speak,\n",
    "you may react. You have a model of who I am and what I was trying to\n",
    "say, and why I chose to say what I said. Now we begin this dance, where\n",
    "we are each trying to better understand each other and what we are\n",
    "saying. When it works, it is beautiful, but when mis-deployed, just like\n",
    "a badly driven F1 car, there is a horrible crash, an argument."
   ],
   "id": "af234096-b12f-4948-b004-112cdd8c9889"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sistine Chapel Ceiling\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_art/includes/michelangelo-sistine-chapel-ceiling.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_art/includes/michelangelo-sistine-chapel-ceiling.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//art/michelangelo-sistine-chapel-ceiling.jpg\" style=\"width:100%\">\n",
    "\n",
    "Figure: <i>The ceiling of the Sistine Chapel.</i>\n",
    "\n",
    "[Patrick Boyde](https://www.mmll.cam.ac.uk/pb127)’s talks on the Sistine\n",
    "Chapel focussed on both the structure of the chapel ceiling, describing\n",
    "the impression of height it was intended to give, as well as the\n",
    "significance and positioning of each of the panels and the meaning of\n",
    "the individual figures."
   ],
   "id": "d066c810-f5cf-45d8-81b1-3d97fcb3cd09"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Creation of Man\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_art/includes/michelangelo-the-creation-of-man.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_art/includes/michelangelo-the-creation-of-man.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//art/michelangelo-the-creation-of-man.jpg\" style=\"width:80%\">\n",
    "\n",
    "Figure: <i>Photo of Detail of Creation of Man from the Sistine chapel\n",
    "ceiling.</i>\n",
    "\n",
    "One of the most famous panels is central in the ceiling, it’s the\n",
    "creation of man. Here, God in the guise of a pink-robed bearded man\n",
    "reaches out to a languid Adam.\n",
    "\n",
    "The representation of God in this form seems typical of the time,\n",
    "because elsewhere in the Vatican Museums there are similar\n",
    "representations.\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//art/michelangelo-the-creation-of-man-detail-god.jpg\" style=\"width:80%\">\n",
    "\n",
    "Figure: <i>Photo detail of God.</i>\n",
    "\n",
    "<https://commons.wikimedia.org/wiki/File:Michelangelo,_Creation_of_Adam_04.jpg>"
   ],
   "id": "92452777-7e62-48b8-bd41-abc87ce7fa98"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Six Word Novel\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_ai/includes/baby-shoes.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/baby-shoes.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//Classic_baby_shoes.jpg\" style=\"width:60%\">\n",
    "\n",
    "Figure: <i>Consider the six-word novel, apocryphally credited to Ernest\n",
    "Hemingway, “For sale: baby shoes, never worn”. To understand what that\n",
    "means to a human, you need a great deal of additional context. Context\n",
    "that is not directly accessible to a machine that has not got both the\n",
    "evolved and contextual understanding of our own condition to realize\n",
    "both the implication of the advert and what that implication means\n",
    "emotionally to the previous owner.</i>\n",
    "\n",
    "But this is a very different kind of intelligence than ours. A computer\n",
    "cannot understand the depth of the Ernest Hemingway’s apocryphal\n",
    "six-word novel: “For Sale, Baby Shoes, Never worn”, because it isn’t\n",
    "equipped with that ability to model the complexity of humanity that\n",
    "underlies that statement."
   ],
   "id": "b58977d2-b58e-4f15-ae27-9d2549ae6569"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revolution\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_ai/includes/cuneiform.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/cuneiform.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "Arguably the information revolution we are experiencing is unprecedented\n",
    "in history. But changes in the way we share information have a long\n",
    "history. Over 5,000 years ago in the city of Uruk, on the banks of the\n",
    "Euphrates, communities which relied on the water to irrigate their corps\n",
    "developed an approach to recording transactions in clay. Eventually the\n",
    "system of recording system became sophisticated enough that their oral\n",
    "histories could be recorded in the form of the first epic: Gilgamesh.\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//cuneiform/chicago-cuneiform-stone.jpg\" style=\"width:40%\">\n",
    "\n",
    "Figure: <i>Chicago Stone, side 2, recording sale of a number of fields,\n",
    "probably from Isin, Early Dynastic Period, c. 2600 BC, black basalt</i>\n",
    "\n",
    "It was initially develoepd for people as a recordd of who owed what to\n",
    "whom, expanding individuals’ capacity to remember. But over a five\n",
    "hundred year period writing evolved to become a tool for literature as\n",
    "well. More pithily put, writing was invented by accountants not poets\n",
    "(see e.g. [this piece by Tim\n",
    "Harford](https://www.bbc.co.uk/news/business-39870485)).\n",
    "\n",
    "In some respects today’s revolution is different, because it involves\n",
    "also the creation of stories as well as their curation. But in some\n",
    "fundamental ways we can see what we have produced as another tool for us\n",
    "in the information revolution."
   ],
   "id": "a7a9d24f-cdcc-4aa2-9ed1-a413e2e58ef5"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Future of Professions\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_books/includes/the-future-of-professions.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_books/includes/the-future-of-professions.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//books/the-future-of-professions.jpg\" style=\"width:40%\">\n",
    "\n",
    "Figure: <i>[The Future of\n",
    "Professions](https://www.amazon.co.uk/Future-Professions-Technology-Transform-Experts/dp/0198713398)\n",
    "(Susskind and Susskind, 2015) is a 2015 book focussed on how the next\n",
    "wave of technology revolution is going to effect the professions.</i>"
   ],
   "id": "111efdf1-918c-4295-91bc-bff1ac3669ad"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coin Pusher\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_policy/includes/coin-pusher.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_policy/includes/coin-pusher.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "Disruption of society is like a coin pusher, it’s those who are already\n",
    "on the edge who are most likely to be effected by disruption.\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//policy/Coin_pusher_2.jpg\" style=\"width:70%\">\n",
    "\n",
    "Figure: <i>A coin pusher is a game where coins are dropped into th etop\n",
    "of the machine, and they disrupt those on the existing steps. With any\n",
    "coin drop, many coins move, but it is those on the edge, who are often\n",
    "only indirectly effected, but also most traumatically effected by the\n",
    "change.</i>\n",
    "\n",
    "One danger of the current hype around ChatGPT is that we are overly\n",
    "focussing on the fact that it seems to have significant effect on\n",
    "professional jobs, people are naturally asking the question “what does\n",
    "it do for my role?”. No doubt, there will be disruption, but the coin\n",
    "pusher hypothesis suggests that that disruption will likely involve\n",
    "movement on the same step. However it is those on the edge already, who\n",
    "are often not working directly in the information economy, who often\n",
    "have less of a voice in the policy conversation who are likely to be\n",
    "most disrupted.\n",
    "\n",
    "<!-- AI Fallacy -->"
   ],
   "id": "764f648b-43fc-483d-96fe-d0270b26e101"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Great AI Fallacy\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_ai/includes/the-great-ai-fallacy.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/the-great-ai-fallacy.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "There is a lot of variation in the use of the term artificial\n",
    "intelligence. I’m sometimes asked to define it, but depending on whether\n",
    "you’re speaking to a member of the public, a fellow machine learning\n",
    "researcher, or someone from the business community, the sense of the\n",
    "term differs.\n",
    "\n",
    "However, underlying its use I’ve detected one disturbing trend. A trend\n",
    "I’m beginining to think of as “The Great AI Fallacy”.\n",
    "\n",
    "The fallacy is associated with an implicit promise that is embedded in\n",
    "many statements about Artificial Intelligence. Artificial Intelligence,\n",
    "as it currently exists, is merely a form of automated decision making.\n",
    "The implicit promise of Artificial Intelligence is that it will be the\n",
    "first wave of automation where the machine adapts to the human, rather\n",
    "than the human adapting to the machine.\n",
    "\n",
    "How else can we explain the suspension of sensible business judgment\n",
    "that is accompanying the hype surrounding AI?\n",
    "\n",
    "This fallacy is particularly pernicious because there are serious\n",
    "benefits to society in deploying this new wave of data-driven automated\n",
    "decision making. But the AI Fallacy is causing us to suspend our\n",
    "calibrated skepticism that is needed to deploy these systems safely and\n",
    "efficiently.\n",
    "\n",
    "The problem is compounded because many of the techniques that we’re\n",
    "speaking of were originally developed in academic laboratories in\n",
    "isolation from real-world deployment.\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//ai/Jeeves_in_the_Springtime_01.jpg\" style=\"width:50%\">\n",
    "\n",
    "Figure: <i>We seem to have fallen for a perspective on AI that suggests\n",
    "it will adapt to our schedule, rather in the manner of a 1930s\n",
    "manservant.</i>\n",
    "\n",
    "In Greek mythology, Panacea was the goddess of the universal remedy. One\n",
    "consequence of the pervasive potential of AI is that it is positioned,\n",
    "like Panacea, as the purveyor of a universal solution. Whether it is\n",
    "overcoming industry’s productivity challenges, or as a salve for\n",
    "strained public sector services, or a remedy for pressing global\n",
    "challenges in sustainable development, AI is presented as an elixir to\n",
    "resolve society’s problems.\n",
    "\n",
    "In practice, translation of AI technology into practical benefit is not\n",
    "simple. Moreover, a growing body of evidence shows that risks and\n",
    "benefits from AI innovations are unevenly distributed across society.\n",
    "\n",
    "When carelessly deployed, AI risks exacerbating existing social and\n",
    "economic inequalities.\n",
    "\n",
    "<!-- Mathematical Statistics -->"
   ],
   "id": "97c62931-cfc6-432d-b034-7d8449fc8be8"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lies and Damned Lies\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_data-science/includes/lies-damned-lies.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_data-science/includes/lies-damned-lies.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "> There are three types of lies: lies, damned lies and statistics\n",
    ">\n",
    "> Arthur Balfour 1848-1930\n",
    "\n",
    "Arthur Balfour was quoting the lawyer James Munro[1] when he said that\n",
    "there three types of lies: lies, damned lies and statistics in 1892.\n",
    "This is 20 years before the first academic department of applied\n",
    "statistics was founded at UCL. If Balfour were alive today, it is likely\n",
    "that he’d rephrase his quote:\n",
    "\n",
    "> There are three types of lies, lies damned lies and *big data*.\n",
    "\n",
    "Why? Because the challenges of understanding and interpreting big data\n",
    "today are similar to those that Balfour (who was a Conservative\n",
    "politician and statesman and would later become Prime Minister) faced in\n",
    "governing an empire through statistics in the latter part of the 19th\n",
    "century.\n",
    "\n",
    "The quote lies, damned lies and statistics was also credited to Benjamin\n",
    "Disraeli by Mark Twain in Twain’s autobiography.[2] It characterizes the\n",
    "idea that statistic can be made to prove anything. But Disraeli died in\n",
    "1881 and Mark Twain died in 1910. The important breakthrough in\n",
    "overcoming our tendency to over-interpet data came with the\n",
    "formalization of the field through the development of *mathematical\n",
    "statistics*.\n",
    "\n",
    "Data has an elusive quality, it promises so much but can deliver little,\n",
    "it can mislead and misrepresent. To harness it, it must be tamed. In\n",
    "Balfour and Disraeli’s time during the second half of the 19th century,\n",
    "numbers and data were being accumulated, the social sciences were being\n",
    "developed. There was a large-scale collection of data for the purposes\n",
    "of government.\n",
    "\n",
    "The modern ‘big data era’ is on the verge of delivering the same sense\n",
    "of frustration that Balfour experienced, the early promise of big data\n",
    "as a panacea is evolving to demands for delivery. For me, personally,\n",
    "peak-hype coincided with an email I received inviting collaboration on a\n",
    "project to deploy “*Big Data* and *Internet of Things* in an *Industry\n",
    "4.0* environment”. Further questioning revealed that the actual project\n",
    "was optimization of the efficiency of a manufacturing production line, a\n",
    "far more tangible and *realizable* goal.\n",
    "\n",
    "The antidote to this verbiage is found in increasing awareness. When\n",
    "dealing with data the first trap to avoid is the games of buzzword bingo\n",
    "that we are wont to play. The first goal is to quantify what challenges\n",
    "can be addressed and what techniques are required. Behind the hype\n",
    "fundamentals are changing. The phenomenon is about the increasing access\n",
    "we have to data. The way customers’ information is recorded and\n",
    "processes are codified and digitized with little overhead. Internet of\n",
    "things is about the increasing number of cheap sensors that can be\n",
    "easily interconnected through our modern network structures. But\n",
    "businesses are about making money, and these phenomena need to be recast\n",
    "in those terms before their value can be realized.\n",
    "\n",
    "For more thoughts on the challenges that statistics brings see Chapter 8\n",
    "of Lawrence (2024).\n",
    "\n",
    "[1] The quote is reported in the *Manchester Guardian* on 29th June\n",
    "1892. See also <https://www.york.ac.uk/depts/maths/histstat/lies.htm>.\n",
    "\n",
    "[2] Although Twain attributes Disraeli in this way there’s [no record of\n",
    "him having said\n",
    "this.](https://en.wikipedia.org/wiki/Lies,_damned_lies,_and_statistics)."
   ],
   "id": "17022e19-a3f9-40ee-aade-9cfc1b829e36"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Mathematical* Statistics\n",
    "\n",
    "[Karl Pearson](https://en.wikipedia.org/wiki/Karl_Pearson) (1857-1936),\n",
    "[Ronald Fisher](https://en.wikipedia.org/wiki/Ronald_Fisher) (1890-1962)\n",
    "and others considered the question of what conclusions can truly be\n",
    "drawn from data. Their mathematical studies act as a restraint on our\n",
    "tendency to over-interpret and see patterns where there are none. They\n",
    "introduced concepts such as randomized control trials that form a\n",
    "mainstay of our decision making today, from government, to clinicians to\n",
    "large scale A/B testing that determines the nature of the web interfaces\n",
    "we interact with on social media and shopping.\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//Portrait_of_Karl_Pearson.jpg\" style=\"width:30%\">\n",
    "\n",
    "Figure: <i>Karl Pearson (1857-1936), one of the founders of Mathematical\n",
    "Statistics.</i>\n",
    "\n",
    "Their movement did the most to put statistics to rights, to eradicate\n",
    "the ‘damned lies’. It was known as [‘mathematical\n",
    "statistics’](https://en.wikipedia.org/wiki/Mathematical_statistics).\n",
    "Today I believe we should look to the emerging field of *data science*\n",
    "to provide the same role. Data science is an amalgam of statistics, data\n",
    "mining, computer systems, databases, computation, machine learning and\n",
    "artificial intelligence. Spread across these fields are the tools we\n",
    "need to realize data’s potential. For many businesses this might be\n",
    "thought of as the challenge of ‘converting bits into atoms’. Bits: the\n",
    "data stored on computer, atoms: the physical manifestation of what we\n",
    "do; the transfer of goods, the delivery of service. From fungible to\n",
    "tangible. When solving a challenge through data there are a series of\n",
    "obstacles that need to be addressed.\n",
    "\n",
    "Firstly, data awareness: what data you have and where its stored.\n",
    "Sometimes this includes changing your conception of what data is and how\n",
    "it can be obtained. From automated production lines to apps on employee\n",
    "smart phones. Often data is locked away: manual logbooks, confidential\n",
    "data, personal data. For increasing awareness an internal audit can\n",
    "help. The website [data.gov.uk](https://data.gov.uk/) hosts data made\n",
    "available by the UK government. To create this website the government’s\n",
    "departments went through an audit of what data they each hold and what\n",
    "data they could make available. Similarly, within private businesses\n",
    "this type of audit could be useful for understanding their internal\n",
    "digital landscape: after all the key to any successful campaign is a\n",
    "good map.\n",
    "\n",
    "Secondly, availability. How well are the data sources interconnected?\n",
    "How well curated are they? The curse of Disraeli was associated with\n",
    "unreliable data and *unreliable statistics*. The misrepresentations this\n",
    "leads to are worse than the absence of data as they give a false sense\n",
    "of confidence to decision making. Understanding how to avoid these\n",
    "pitfalls involves an improved sense of data and its value, one that\n",
    "needs to permeate the organization.\n",
    "\n",
    "The final challenge is analysis, the accumulation of the necessary\n",
    "expertise to digest what the data tells us. Data requires\n",
    "interpretation, and interpretation requires experience. Analysis is\n",
    "providing a bottleneck due to a skill shortage, a skill shortage made\n",
    "more acute by the fact that, ideally, analysis should be carried out by\n",
    "individuals not only skilled in data science but also equipped with the\n",
    "domain knowledge to understand the implications in a given application,\n",
    "and to see opportunities for improvements in efficiency."
   ],
   "id": "63103a20-434d-487c-98e0-5b31b2925b8f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‘Mathematical Data Science’\n",
    "\n",
    "As a term ‘big data’ promises much and delivers little, to get true\n",
    "value from data, it needs to be curated and evaluated. The three stages\n",
    "of awareness, availability and analysis provide a broad framework\n",
    "through which organizations should be assessing the potential in the\n",
    "data they hold. Hand waving about big data solutions will not do, it\n",
    "will only lead to self-deception. The castles we build on our data\n",
    "landscapes must be based on firm foundations, process and scientific\n",
    "analysis. If we do things right, those are the foundations that will be\n",
    "provided by the new field of data science.\n",
    "\n",
    "Today the statement “There are three types of lies: lies, damned lies\n",
    "and ‘big data’” may be more apt. We are revisiting many of the mistakes\n",
    "made in interpreting data from the 19th century. Big data is laid down\n",
    "by happenstance, rather than actively collected with a particular\n",
    "question in mind. That means it needs to be treated with care when\n",
    "conclusions are being drawn. For data science to succeed it needs the\n",
    "same form of rigor that Pearson and Fisher brought to statistics, a\n",
    "“mathematical data science” is needed.\n",
    "\n",
    "You can also check my blog post on [Lies, Damned Lies and Big\n",
    "Data](http://inverseprobability.com/2016/11/19/lies-damned-lies-big-data).\n",
    "\n",
    "I’m reminded of this because from 2015 to 2017 I was on the Working\n",
    "Group that compiled the Royal Society’s machine learning report. The\n",
    "process of constructing the report went across the UK Referendum, and\n",
    "the 2016 US election. I remember vividly a meeting we convened at the\n",
    "Society in London which had experts alongside MPs from all parties,\n",
    "policy advisors and civil servants. One of the MPs (likely correctly)\n",
    "pointed out “I suspect no one around this table voted for Brexit” to\n",
    "which I replied “But isn’t that the problem? There are a large number of\n",
    "people who aren’t empowered who are experiencing quite a different\n",
    "reality than us. And they aren’t reprented in these forums.” So it’s no\n",
    "surprise that so much of the press conversation around AI is still\n",
    "focussed on how it is likely to effect middle class jobs. We shouldn’t\n",
    "underestimate these effects, but it’s often the case that better\n",
    "educated people are better placed to deal with such challenges. For\n",
    "example, when stock brokers’ roles disappeared they simply moved on to\n",
    "other roles in banks and related industries."
   ],
   "id": "77322551-b39d-4b3f-9946-c44ffd26f093"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Royal Society Report\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_ml/includes/rs-report-machine-learning.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ml/includes/rs-report-machine-learning.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//ml/ml-report-cover-page.png\" style=\"width:\">\n",
    "\n",
    "Figure: <i>The Royal Society report on Machine Learning was released on\n",
    "25th April 2017</i>\n",
    "\n",
    "A useful reference for state of the art in machine learning is the UK\n",
    "Royal Society Report, [Machine Learning: Power and Promise of Computers\n",
    "that Learn by\n",
    "Example](https://royalsociety.org/~/media/policy/projects/machine-learning/publications/machine-learning-report.pdf)."
   ],
   "id": "d65f8123-ad5f-4eb1-bb58-0461ce78456e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Public Research\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_ml/includes/rs-report-mori-poll-art.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ml/includes/rs-report-mori-poll-art.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//ml/rs-report-mori-poll-cover.png\" style=\"width:\">\n",
    "\n",
    "Figure: <i>The Royal Society comissioned [public research from\n",
    "Mori](https://royalsociety.org/-/media/policy/projects/machine-learning/publications/public-views-of-machine-learning-ipsos-mori.pdf)\n",
    "as part of the machine learning review.</i>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//ml/rs-mori-views-of-specific-ml-applications-1.png\" style=\"width:\">\n",
    "\n",
    "Figure: <i>One of the questions focussed on machine learning\n",
    "applications.</i>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//ml/rs-mori-views-of-specific-ml-applications-2.png\" style=\"width:\">\n",
    "\n",
    "Figure: <i>The public were broadly supportive of a range of application\n",
    "areas.</i>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//ml/rs-mori-views-of-specific-ml-applications-3.png\" style=\"width:\">\n",
    "\n",
    "Figure: <i>But they failed to see the point in AI’s that could produce\n",
    "poetry.</i>\n",
    "\n",
    "<!-- Fritz Heider -->"
   ],
   "id": "dec56861-65b9-4075-a35d-6a659856fd84"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heider and Simmel (1944)\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_ai/includes/heider-simmel.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/heider-simmel.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
   ],
   "id": "f4c4a64b-5a89-479d-9dbe-546028d940e3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.lib.display import YouTubeVideo\n",
    "YouTubeVideo('8FIEZXMUM2I')"
   ],
   "id": "10cc37a7-3723-4aca-9bda-f60200206860"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure: <i>Fritz Heider and Marianne Simmel’s video of shapes from\n",
    "Heider and Simmel (1944).</i>\n",
    "\n",
    "[Fritz Heider](https://en.wikipedia.org/wiki/Fritz_Heider) and [Marianne\n",
    "Simmel](https://en.wikipedia.org/wiki/Marianne_Simmel)’s experiments\n",
    "with animated shapes from 1944 (Heider and Simmel, 1944). Our\n",
    "interpretation of these objects as showing motives and even emotion is a\n",
    "combination of our desire for narrative, a need for understanding of\n",
    "each other, and our ability to empathize. At one level, these are\n",
    "crudely drawn objects, but in another way, the animator has communicated\n",
    "a story through simple facets such as their relative motions, their\n",
    "sizes and their actions. We apply our psychological representations to\n",
    "these faceless shapes to interpret their actions.\n",
    "\n",
    "See also a recent review paper on Human Cooperation by Henrich and\n",
    "Muthukrishna (2021).\n",
    "\n",
    "<!-- Conversation LLM -->"
   ],
   "id": "90b74d5e-7db6-4662-95c8-eacf73ad8149"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer Conversations\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_ai/includes/conversation-computer.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/conversation-computer.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
   ],
   "id": "882cb170-915c-4eac-ad39-f30c90e5dc11"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import notutils as nu\n",
    "from ipywidgets import IntSlider"
   ],
   "id": "a660bca9-df53-46d6-87ef-6e4f8a49193a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import notutils as nu"
   ],
   "id": "75f4097a-7d09-4b82-a4f4-9d25a576be47"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nu.display_plots('anne-bob-conversation{sample:0>3}.svg', \n",
    "                            'https://inverseprobability.com/talks/../slides/diagrams/',  sample=IntSlider(0, 0, 7, 1))"
   ],
   "id": "500b0f73-7993-4e80-b99a-c7ff0e073e44"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//anne-computer-conversation006.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Conversation relies on internal models of other\n",
    "individuals.</i>\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//anne-computer-conversation007.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Misunderstanding of context and who we are talking to leads\n",
    "to arguments.</i>\n",
    "\n",
    "Similarly, we find it difficult to comprehend how computers are making\n",
    "decisions. Because they do so with more data than we can possibly\n",
    "imagine.\n",
    "\n",
    "In many respects, this is not a problem, it’s a good thing. Computers\n",
    "and us are good at different things. But when we interact with a\n",
    "computer, when it acts in a different way to us, we need to remember\n",
    "why.\n",
    "\n",
    "Just as the first step to getting along with other humans is\n",
    "understanding other humans, so it needs to be with getting along with\n",
    "our computers.\n",
    "\n",
    "Embodiment factors explain why, at the same time, computers are so\n",
    "impressive in simulating our weather, but so poor at predicting our\n",
    "moods. Our complexity is greater than that of our weather, and each of\n",
    "us is tuned to read and respond to one another.\n",
    "\n",
    "Their intelligence is different. It is based on very large quantities of\n",
    "data that we cannot absorb. Our computers don’t have a complex internal\n",
    "model of who we are. They don’t understand the human condition. They are\n",
    "not tuned to respond to us as we are to each other.\n",
    "\n",
    "Embodiment factors encapsulate a profound thing about the nature of\n",
    "humans. Our locked in intelligence means that we are striving to\n",
    "communicate, so we put a lot of thought into what we’re communicating\n",
    "with. And if we’re communicating with something complex, we naturally\n",
    "anthropomorphize them.\n",
    "\n",
    "We give our dogs, our cats, and our cars human motivations. We do the\n",
    "same with our computers. We anthropomorphize them. We assume that they\n",
    "have the same objectives as us and the same constraints. They don’t.\n",
    "\n",
    "This means, that when we worry about artificial intelligence, we worry\n",
    "about the wrong things. We fear computers that behave like more powerful\n",
    "versions of ourselves that will struggle to outcompete us.\n",
    "\n",
    "In reality, the challenge is that our computers cannot be human enough.\n",
    "They cannot understand us with the depth we understand one another. They\n",
    "drop below our cognitive radar and operate outside our mental models.\n",
    "\n",
    "The real danger is that computers don’t anthropomorphize. They’ll make\n",
    "decisions in isolation from us without our supervision because they\n",
    "can’t communicate truly and deeply with us."
   ],
   "id": "db5ca960-00ef-4f98-8608-ace9491599c8"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Conversations\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_ai/includes/conversation-probability.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/conversation-probability.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//ai/anne-probability-conversation.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>The focus so far has been on reducing uncertainty to a few\n",
    "representative values and sharing numbers with human beings. We forget\n",
    "that most people can be confused by basic probabilities for example the\n",
    "prosecutor’s fallacy.</i>\n",
    "\n",
    "In practice we know that probabilities can be very unintuitive, for\n",
    "example in court there is a fallacy known as the “prosecutor’s fallacy”\n",
    "that confuses conditional probabilities. This can cause problems in jury\n",
    "trials (Thompson, 1989)."
   ],
   "id": "e0173cce-fc98-4d36-9bda-89657cfb642d"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Networked Interactions\n",
    "\n",
    "Our modern society intertwines the machine with human interactions. The\n",
    "key question is who has control over these interfaces between humans and\n",
    "machines.\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//ai/human-computers-interacting.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Humans and computers interacting should be a major focus of\n",
    "our research and engineering efforts.</i>\n",
    "\n",
    "So the real challenge that we face for society is understanding which\n",
    "systemic interventions will encourage the right interactions between the\n",
    "humans and the machine at all of these interfaces.\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//ai/human-culture-interacting.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Humans use culture, facts and ‘artefacts’ to communicate.</i>"
   ],
   "id": "cad99ad7-dedb-483a-9f2e-8515b784f496"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Blue Marble\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_physics/includes/the-earth-seen-from-apollo-17.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_physics/includes/the-earth-seen-from-apollo-17.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//physics/the-earth-seen-from-apollo-17.jpg\" style=\"width:80%\">\n",
    "\n",
    "Figure: <i>The Blue Marble, a photo of Earth taken from Apollo 17.</i>"
   ],
   "id": "9a40357f-a0c7-44f2-af5e-718aa329dca6"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eagle from Columbia\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_physics/includes/eagle-from-columbia.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_physics/includes/eagle-from-columbia.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//physics/2131px-Earth,_Moon_and_Lunar_Module,_AS11-44-6643.jpg\" style=\"width:80%\">\n",
    "\n",
    "Figure: <i>Eagle photographed from Columbia on its return from the Lunar\n",
    "surface.</i>"
   ],
   "id": "9564b4bc-a206-4bfd-af93-3acb0429ebac"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amelia Earhart\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_physics/includes/little-red-bus.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_physics/includes/little-red-bus.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//physics/the-little-red-bus.jpg\" style=\"width:60%\">\n",
    "\n",
    "Figure: <i>The Little Red Bus, Amelia Earhart’s plane in Derry after\n",
    "landing.</i>"
   ],
   "id": "62617d9b-e560-4288-83da-837fedeb4a11"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NACA Langley\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_ai/includes/naca-proving.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/naca-proving.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//ai/NACA-LMAL-42612.jpg\" style=\"width:60%\">\n",
    "\n",
    "Figure: <i>1945 photo of the NACA test pilots, from left Mel Gough, Herb\n",
    "Hoover, Jack Reeder, Stefan Cavallo and Bill Gray (photo NASA, NACA LMAL\n",
    "42612)</i>\n",
    "\n",
    "The NACA Langley Field proving ground tested US aircraft. Bob Gilruth\n",
    "worked on the [flying qualities of\n",
    "aircraft](https://ntrs.nasa.gov/search.jsp?R=19930091834). One of his\n",
    "collaborators suggested that\n",
    "\n",
    "> Hawker Hurricane airplane. A heavily armed fighter airplane noted for\n",
    "> its role in the Battle of Britain, the Hurricane’s flying qualities\n",
    "> were found to be generally satisfactory. The most notable deficiencies\n",
    "> were heavy aileron forces at high speeds and large friction in the\n",
    "> controls.\n",
    ">\n",
    "> W. Hewitt Phillips[1]\n",
    "\n",
    "and\n",
    "\n",
    "> Supermarine Spitfire airplane. A high-performance fighter noted for\n",
    "> its role in the Battle of Britain and throughout WW II, the Spitfire\n",
    "> had desirably light elevator control forces in maneuvers and near\n",
    "> neutral longitudinal stability. Its greatest deficiency from the\n",
    "> combat standpoint was heavy aileron forces and sluggish roll response\n",
    "> at high speeds.\n",
    ">\n",
    "> W. Hewitt Phillips[2]\n",
    "\n",
    "Gilruth went beyond the reports of feel to characterise how the plane\n",
    "should respond to different inputs on the control stick. In other words\n",
    "he quantified that feel of the plane.\n",
    "\n",
    "[1] monographs\n",
    "\n",
    "[2] monographs"
   ],
   "id": "f42f66b3-88a2-491a-99d9-ff23e53a9229"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MONIAC\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_simulation/includes/the-moniac.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_simulation/includes/the-moniac.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "[The MONIAC](https://en.wikipedia.org/wiki/MONIAC) was an analogue\n",
    "computer designed to simulate the UK economy. Analogue comptuers work\n",
    "through analogy, the analogy in the MONIAC is that both money and water\n",
    "flow. The MONIAC exploits this through a system of tanks, pipes, valves\n",
    "and floats that represent the flow of money through the UK economy.\n",
    "Water flowed from the treasury tank at the top of the model to other\n",
    "tanks representing government spending, such as health and education.\n",
    "The machine was initially designed for teaching support but was also\n",
    "found to be a useful economic simulator. Several were built and today\n",
    "you can see the original at Leeds Business School, there is also one in\n",
    "the London Science Museum and one [in the Unisversity of Cambridge’s\n",
    "economics\n",
    "faculty](https://www.econ.cam.ac.uk/economics-alumni/drip-down-economics-phillips-machine).\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//simulation/Phillips_and_MONIAC_LSE.jpg\" style=\"width:40%\">\n",
    "\n",
    "Figure: <i>Bill Phillips and his MONIAC (completed in 1949). The machine\n",
    "is an analogue computer designed to simulate the workings of the UK\n",
    "economy.</i>"
   ],
   "id": "1996c8af-9de5-4175-bce6-08324e90986f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Donald MacKay\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_ai/includes/donald-mackay-brain.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/donald-mackay-brain.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//people/DonaldMacKay1952.jpg\" style=\"width:40%\">\n",
    "\n",
    "Figure: <i>Donald M. MacKay (1922-1987), a physicist who was an early\n",
    "member of the cybernetics community and member of the Ratio Club.</i>\n",
    "\n",
    "Donald MacKay was a physicist who worked on naval gun targetting during\n",
    "the second world war. The challenge with gun targetting for ships is\n",
    "that both the target and the gun platform are moving. The challenge was\n",
    "tackled using analogue computers, for example in the US the [Mark I fire\n",
    "control\n",
    "computer](https://en.wikipedia.org/wiki/Mark_I_Fire_Control_Computer)\n",
    "which was a mechanical computer. MacKay worked on radar systems for gun\n",
    "laying, here the velocity and distance of the target could be assessed\n",
    "through radar and an mechanical electrical analogue computer."
   ],
   "id": "cdaced48-65e6-4b63-bb03-a053260129a5"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fire Control Systems\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_ai/includes/fire-control-systems.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/fire-control-systems.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "Naval gunnery systems deal with targeting guns while taking into account\n",
    "movement of ships. The Royal Navy’s Gunnery Pocket Book (The Admiralty,\n",
    "1945) gives details of one system for gun laying.\n",
    "\n",
    "Like many challenges we face today, in the second world war, fire\n",
    "control was handled by a hybrid system of humans and computers. This\n",
    "means deploying human beings for the tasks that they can manage, and\n",
    "machines for the tasks that are better performed by a machine. This\n",
    "leads to a division of labour between the machine and the human that can\n",
    "still be found in our modern digital ecosystems.\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//ai/low-angle-fire-control-team.jpg\" style=\"width:80%\">\n",
    "\n",
    "Figure: <i>The fire control computer set at the centre of a system of\n",
    "observation and tracking (The Admiralty, 1945).</i>\n",
    "\n",
    "As analogue computers, fire control computers from the second world war\n",
    "would contain components that directly represented the different\n",
    "variables that were important in the problem to be solved, such as the\n",
    "inclination between two ships.\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//ai/the-measurement-of-inclination.jpg\" style=\"width:80%\">\n",
    "\n",
    "Figure: <i>Measuring inclination between two ships (The Admiralty,\n",
    "1945). Sophisticated fire control computers allowed the ship to continue\n",
    "to fire while under maneuvers.</i>\n",
    "\n",
    "The fire control systems were electro-mechanical analogue computers that\n",
    "represented the “state variables” of interest, such as inclination and\n",
    "ship speed with gears and cams within the machine.\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//ai/typical-modern-fire-control-table.jpg\" style=\"width:80%\">\n",
    "\n",
    "Figure: <i>A second world war gun computer’s control table (The\n",
    "Admiralty, 1945).</i>\n",
    "\n",
    "For more details on fire control computers, you can watch a 1953 film on\n",
    "the the US the [Mark IA fire control\n",
    "computer](https://en.wikipedia.org/wiki/Mark_I_Fire_Control_Computer)\n",
    "from Periscope Film."
   ],
   "id": "5751e654-578e-4f55-bb49-a4b9169bb59e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.lib.display import YouTubeVideo\n",
    "YouTubeVideo('gwf5mAlI7Ug')"
   ],
   "id": "c0ecd6ef-b25c-4d11-b85e-ff6529587e6c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure: <i>U.S. Navy training film MN-6783a. Basic Mechanisms of Fire\n",
    "Control Computers. Mechanical Computer Instructional Film 27794 (1953)\n",
    "for the Mk 1A Fire Control Computer.</i>"
   ],
   "id": "e4976116-8d07-4115-b410-e535505fb4c0"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behind the Eye\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_books/includes/behind-the-eye.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_books/includes/behind-the-eye.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//books/behind-the-eye.jpg\" style=\"width:40%\">\n",
    "\n",
    "Figure: <i>[Behind the\n",
    "Eye](https://www.amazon.co.uk/Behind-Eye-Gifford-Lectures-MACKAY/dp/0631173323)\n",
    "(MacKay, 1991) summarises MacKay’s Gifford Lectures, where MacKay uses\n",
    "the operation of the eye as a window on the operation of the brain.</i>\n",
    "\n",
    "Donald MacKay was at King’s College for his PhD. He was just down the\n",
    "road from Bill Phillips at LSE who was building the MONIAC. He was part\n",
    "of the Ratio Club. A group of early career scientists who were\n",
    "interested in communication and control in animals and humans, or more\n",
    "specifically they were interested in computers and brains. The were part\n",
    "of an international movement known as cybernetics.\n",
    "\n",
    "Donald MacKay wrote of the influence that his own work on radar had on\n",
    "his interest in the brain.\n",
    "\n",
    "> … during the war I had worked on the theory of automated and\n",
    "> electronic computing and on the theory of information, all of which\n",
    "> are highly relevant to such things as automatic pilots and automatic\n",
    "> gun direction. I found myself grappling with problems in the design of\n",
    "> artificial sense organs for naval gun-directors and with the\n",
    "> principles on which electronic circuits could be used to simulate\n",
    "> situations in the external world so as to provide goal-directed\n",
    "> guidance for ships, aircraft, missiles and the like.\n",
    "\n",
    "> Later in the 1940’s, when I was doing my Ph.D. work, there was much\n",
    "> talk of the brain as a computer and of the early digital computers\n",
    "> that were just making the headlines as “electronic brains.” As an\n",
    "> analogue computer man I felt strongly convinced that the brain,\n",
    "> whatever it was, was not a digital computer. I didn’t think it was an\n",
    "> analogue computer either in the conventional sense.\n",
    "\n",
    "> But this naturally rubbed under my skin the question: well, if it is\n",
    "> not either of these, what kind of system is it? Is there any way of\n",
    "> following through the kind of analysis that is appropriate to their\n",
    "> artificial automata so as to understand better the kind of system the\n",
    "> human brain is? That was the beginning of my slippery slope into brain\n",
    "> research.\n",
    ">\n",
    "> *Behind the Eye* pg 40. Edited version of the 1986 Gifford Lectures\n",
    "> given by Donald M. MacKay and edited by Valerie MacKay\n",
    "\n",
    "Importantly, MacKay distinguishes between the *analogue* computer and\n",
    "the *digital* computer. As he mentions, his experience was with analogue\n",
    "machines. An analogue machine is *literally* an analogue. The radar\n",
    "systems that Wiener and MacKay both worked on were made up of electronic\n",
    "components such as resistors, capacitors, inductors and/or mechanical\n",
    "components such as cams and gears. Together these components could\n",
    "represent a physical system, such as an anti-aircraft gun and a plane.\n",
    "The design of the analogue computer required the engineer to simulate\n",
    "the real world in analogue electronics, using dualities that exist\n",
    "between e.g. mechanical circuits (mass, spring, damper) and electronic\n",
    "circuits (inductor, resistor, capacitor). The analogy between mass and a\n",
    "damper, between spring and a resistor and between capacitor and a damper\n",
    "works because the underlying mathematics is approximated with the same\n",
    "linear system: a second order differential equation. This mathematical\n",
    "analogy allowed the designer to map from the real world, through\n",
    "mathematics, to a virtual world where the components reflected the real\n",
    "world through analogy."
   ],
   "id": "d53330de-0244-4aef-bec8-14c5e95b42ea"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human Analogue Machine\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_ai/includes/human-analogue-machines-short.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/human-analogue-machines-short.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "The machine learning systems we have built today that can reconstruct\n",
    "human text, or human classification of images, necessarily must have\n",
    "some aspects to them that are analagous to our understanding. As MacKay\n",
    "suggests the brain is neither a digital or an analogue computer, and the\n",
    "same can be said of the modern neural network systems that are being\n",
    "tagged as “artificial intelligence”.\n",
    "\n",
    "I believe a better term for them is “human-analogue machines”, because\n",
    "what we have built is not a system that can make intelligent decisions\n",
    "from first principles (a rational approach) but one that observes how\n",
    "humans have made decisions through our data and reconstructs that\n",
    "process. Machine learning is more empiricist than rational, but now we n\n",
    "empirical approach that distils our evolved intelligence.\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//ai/human-analogue-machine.png\" style=\"width:60%\">\n",
    "\n",
    "Figure: <i>The human analogue machine creates a feature space which is\n",
    "analagous to that we use to reason, one way of doing this is to have a\n",
    "machine attempt to compress all human generated text in an\n",
    "auto-regressive manner.</i>\n",
    "\n",
    "The perils of developing this capability include counterfeit people, a\n",
    "notion that the philosopher [Daniel Dennett has described in *The\n",
    "Atlantic*](https://www.theatlantic.com/technology/archive/2023/05/problem-counterfeit-people/674075/).\n",
    "This is where computers can represent themselves as human and fool\n",
    "people into doing things on that basis."
   ],
   "id": "6abb5bc5-68fc-4340-8c08-cbbff91fcf82"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Conversations\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_ai/includes/conversation-llm.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/conversation-llm.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//ai/anne-llm-conversation.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>The focus so far has been on reducing uncertainty to a few\n",
    "representative values and sharing numbers with human beings. We forget\n",
    "that most people can be confused by basic probabilities for example the\n",
    "prosecutor’s fallacy.</i>"
   ],
   "id": "a1653cdd-cdca-41e6-bea9-362f0c0aab70"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.lib.display import YouTubeVideo\n",
    "YouTubeVideo('0sJjdxn5kcI')"
   ],
   "id": "8f20d57b-57aa-47b7-8079-9530c3639ee8"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure: <i>The Inner Monologue paper suggests using LLMs for robotic\n",
    "planning (Huang et al., 2023).</i>\n",
    "\n",
    "By interacting directly with machines that have an understanding of\n",
    "human cultural context, it should be possible to share the nature of\n",
    "uncertainty in the same way humans do. See for example the paper [Inner\n",
    "Monologue: Embodied Reasoning through\n",
    "Planning](https://innermonologue.github.io/) Huang et al. (2023)."
   ],
   "id": "0b94fee6-5e3f-4b85-9389-531fd85477b4"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intellectual Debt\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_ai/includes/intellectual-debt-blog-post.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ai/includes/intellectual-debt-blog-post.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//ai/2020-02-12-intellectual-debt.png\" style=\"width:70%\">\n",
    "\n",
    "Figure: <i>Jonathan Zittrain’s term to describe the challenges of\n",
    "explanation that come with AI is Intellectual Debt.</i>\n",
    "\n",
    "In the context of machine learning and complex systems, Jonathan\n",
    "Zittrain has coined the term [“Intellectual\n",
    "Debt”](https://medium.com/berkman-klein-center/from-technical-debt-to-intellectual-debt-in-ai-e05ac56a502c)\n",
    "to describe the challenge of understanding what you’ve created. In [the\n",
    "ML@CL group we’ve been foucssing on developing the notion of a\n",
    "*data-oriented\n",
    "architecture*](https://mlatcl.github.io/projects/data-oriented-architectures-for-ai-based-systems.html)\n",
    "to deal with intellectual debt (Cabrera et al., 2023).\n",
    "\n",
    "Zittrain points out the challenge around the lack of interpretability of\n",
    "individual ML models as the origin of intellectual debt. In machine\n",
    "learning I refer to work in this area as fairness, interpretability and\n",
    "transparency or FIT models. To an extent I agree with Zittrain, but if\n",
    "we understand the context and purpose of the decision making, I believe\n",
    "this is readily put right by the correct monitoring and retraining\n",
    "regime around the model. A concept I refer to as “progression testing”.\n",
    "Indeed, the best teams do this at the moment, and their failure to do it\n",
    "feels more of a matter of technical debt rather than intellectual,\n",
    "because arguably it is a maintenance task rather than an explanation\n",
    "task. After all, we have good statistical tools for interpreting\n",
    "individual models and decisions when we have the context. We can\n",
    "linearise around the operating point, we can perform counterfactual\n",
    "tests on the model. We can build empirical validation sets that explore\n",
    "fairness or accuracy of the model.\n",
    "\n",
    "But if we can avoid the pitfalls of counterfeit people, this also offers\n",
    "us an opportunity to *psychologically represent* (Heider, 1958) the\n",
    "machine in a manner where humans can communicate without special\n",
    "training. This in turn offers the opportunity to overcome the challenge\n",
    "of *intellectual debt*.\n",
    "\n",
    "Despite the lack of interpretability of machine learning models, they\n",
    "allow us access to what the machine is doing in a way that bypasses many\n",
    "of the traditional techniques developed in statistics. But understanding\n",
    "this new route for access is a major new challenge."
   ],
   "id": "79bb6919-b39e-4b8d-8a0c-3e8305b16e34"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HAM\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_data-science/includes/new-flow-of-information-ham.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_data-science/includes/new-flow-of-information-ham.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//data-science/new-flow-of-information004.svg\" class=\"\" width=\"70%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>The trinity of human, data, and computer, and highlights the\n",
    "modern phenomenon. The communication channel between computer and data\n",
    "now has an extremely high bandwidth. The channel between human and\n",
    "computer and the channel between data and human is narrow. New direction\n",
    "of information flow, information is reaching us mediated by the\n",
    "computer. The focus on classical statistics reflected the importance of\n",
    "the direct communication between human and data. The modern challenges\n",
    "of data science emerge when that relationship is being mediated by the\n",
    "machine.</i>\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//data-science/new-flow-of-information-ham.svg\" class=\"\" width=\"70%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>The HAM now sits between us and the traditional digital\n",
    "computer.</i>\n",
    "\n",
    "<!--include{_ai/includes/p-n-fairness.md}-->"
   ],
   "id": "536ee02e-b7e9-4eb1-b773-c02a5cbfe702"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Question of Trust\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_books/includes/a-question-of-trust.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_books/includes/a-question-of-trust.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "In Baroness Onora O’Neill’s Reeith Lectures from 2002, she raises the\n",
    "challenge of trust. There are many aspects to her arcuments, but one of\n",
    "the key points she makes is that we cannot trust without the notion of\n",
    "duty. O’Neill is bemoaning the substitution of duty with process. The\n",
    "idea is that processes and transparency are supposed to hold us to\n",
    "account by measuring outcomes. But these processes themselves overwhelm\n",
    "decision makers and undermine their professional duty to deliver the\n",
    "right outcome.\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//books/a-question-of-trust.jpg\" style=\"width:40%\">\n",
    "\n",
    "Figure: <i>[A Question of Trust by Onora\n",
    "O’Neil](https://www.bbc.co.uk/programmes/p00gpzfq) which examines the\n",
    "nature of trust and its role in society.</i>\n",
    "\n",
    "> Again Univesities are to treat each applicant fairly on the basis of\n",
    "> ability and promise, but they are supposed also to admit a socially\n",
    "> more representative intake.\n",
    ">\n",
    "> There’s no guarantee that the process meets the target.\n",
    ">\n",
    "> Onora O’Neill *A Question of Trust: Called to Account* Reith Lectures\n",
    "> 2002 O’Neill (2002)\\]\n",
    "\n",
    "O’Neill is speaking in 2002, in the early days of the internet and\n",
    "before social media. Much of her thoughts are even more relevant for\n",
    "today than they were when she spoke. This is because the increased\n",
    "availability of information and machine driven decision-making makes the\n",
    "mistaken premise, that process is an adequate substitute for duty, more\n",
    "apparently plausible. But this undermines what O’Neill calls\n",
    "“intelligent accountability”, which is not accounting by the numbers,\n",
    "but through professional education and institutional safeguards.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td width=\"50%\">\n",
    "<center>\n",
    "<svg viewBox=\"0 0 200 200\" width=\"55%\">\n",
    "\n",
    "<defs>\n",
    "<linearGradient id=\"gradient-0\" x1=\"0%\" y1=\"0%\" x2=\"100%\" y2=\"0%\">\n",
    "<stop offset=\"0%\" style=\"stop-color:rgb(80,80,80);stop-opacity:1\" />\n",
    "<stop offset=\"100%\" style=\"stop-color:rgb(163,193,173);stop-opacity:1\" />\n",
    "</linearGradient> </defs>\n",
    "<circle cx=\"100\" cy=\"100\" r=\"100\" fill=\"url(#gradient-0)\" />\n",
    "<text fill=\"#ffffff\" x=\"100\" y=\"100\" text-anchor=\"middle\" alignment-baseline=\"middle\">policy</text>\n",
    "\n",
    "</svg>\n",
    "</center>\n",
    "</td>\n",
    "<td width=\"50%\">\n",
    "<center>\n",
    "<svg viewBox=\"0 0 200 200\" width=\"55%\">\n",
    "\n",
    "<defs>\n",
    "<linearGradient id=\"gradient-1\" x1=\"0%\" y1=\"0%\" x2=\"100%\" y2=\"0%\">\n",
    "<stop offset=\"0%\" style=\"stop-color:rgb(80,80,80);stop-opacity:1\" />\n",
    "<stop offset=\"100%\" style=\"stop-color:rgb(163,193,173);stop-opacity:1\" />\n",
    "</linearGradient> </defs>\n",
    "<circle cx=\"100\" cy=\"100\" r=\"100\" fill=\"url(#gradient-1)\" />\n",
    "<text fill=\"#ffffff\" x=\"100\" y=\"100\" text-anchor=\"middle\" alignment-baseline=\"middle\"><tspan x=\"100\" y=\"90\">data</tspan><tspan x=\"100\" y=\"130\">governance</tspan></text>\n",
    "\n",
    "</svg>\n",
    "</center>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "<table>\n",
    "<tr>\n",
    "<td width=\"50%\">\n",
    "<center>\n",
    "<svg viewBox=\"0 0 200 200\" width=\"55%\">\n",
    "\n",
    "<defs>\n",
    "<linearGradient id=\"gradient-2\" x1=\"0%\" y1=\"0%\" x2=\"100%\" y2=\"0%\">\n",
    "<stop offset=\"0%\" style=\"stop-color:rgb(80,80,80);stop-opacity:1\" />\n",
    "<stop offset=\"100%\" style=\"stop-color:rgb(163,193,173);stop-opacity:1\" />\n",
    "</linearGradient> </defs>\n",
    "<circle cx=\"100\" cy=\"100\" r=\"100\" fill=\"url(#gradient-2)\" />\n",
    "<text fill=\"#ffffff\" x=\"100\" y=\"100\" text-anchor=\"middle\" alignment-baseline=\"middle\"><tspan x=\"100\" y=\"90\">accelerate</tspan><tspan x=\"100\" y=\"130\">science</tspan></text>\n",
    "\n",
    "</svg>\n",
    "</center>\n",
    "</td>\n",
    "<td width=\"50%\">\n",
    "<center>\n",
    "<svg viewBox=\"0 0 200 200\" width=\"55%\">\n",
    "\n",
    "<defs>\n",
    "<linearGradient id=\"gradient-3\" x1=\"0%\" y1=\"0%\" x2=\"100%\" y2=\"0%\">\n",
    "<stop offset=\"0%\" style=\"stop-color:rgb(80,80,80);stop-opacity:1\" />\n",
    "<stop offset=\"100%\" style=\"stop-color:rgb(163,193,173);stop-opacity:1\" />\n",
    "</linearGradient> </defs>\n",
    "<circle cx=\"100\" cy=\"100\" r=\"100\" fill=\"url(#gradient-3)\" />\n",
    "<text fill=\"#ffffff\" x=\"100\" y=\"100\" text-anchor=\"middle\" alignment-baseline=\"middle\">AutoAI</text>\n",
    "\n",
    "</svg>\n",
    "</center>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Innovating to serve science and society requires a pipeline of\n",
    "interventions. As well as advances in the technical capabilities of AI\n",
    "technologies, engineering knowhow is required to safely deploy and\n",
    "monitor those solutions in practice. Regulatory frameworks need to adapt\n",
    "to ensure trustworthy use of these technologies. Aligning technology\n",
    "development with public interests demands effective stakeholder\n",
    "engagement to bring diverse voices and expertise into technology design.\n",
    "\n",
    "Building this pipeline will take coordination across research,\n",
    "engineering, policy and practice. It also requires action to address the\n",
    "digital divides that influence who benefits from AI advances. These\n",
    "include digital divides within the socioeconomic strata that need to be\n",
    "overcome – AI must not exacerbate existing equalities or create new\n",
    "ones. In addressing these challenges, we can be hindered by divides that\n",
    "exist between traditional academic disciplines. We need to develop\n",
    "common understanding of the problems and a shared knowledge of possible\n",
    "solutions."
   ],
   "id": "b795f129-1baf-472b-999e-af786df39a5d"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making AI equitable\n",
    "\n",
    "AI@Cam is a new flagship University mission that seeks to address these\n",
    "challenges. It recognises that development of safe and effective\n",
    "AI-enabled innovations requires this mix of expertise from across\n",
    "research domains, businesses, policy-makers, civill society, and from\n",
    "affected communities. AI@Cam is setting out a vision for AI-enabled\n",
    "innovation that benefits science, citizens and society.\n",
    "\n",
    "This vision will be achieved through leveraging the University’s vibrant\n",
    "interdisciplinary research community. AI@Cam will form partnerships\n",
    "between researchers, practitioners, and affected communities that embed\n",
    "equity and inclusion. It will develop new platforms for innovation and\n",
    "knowledge transfer. It will deliver innovative interdisciplinary\n",
    "teaching and learning for students, researchers, and professionals. It\n",
    "will build strong connections between the University and national AI\n",
    "priorities.\n",
    "\n",
    "The University operates as both an engine of AI-enabled innovation and\n",
    "steward of those innovations.\n",
    "\n",
    "AI is not a universal remedy. It is a set of tools, techniques and\n",
    "practices that correctly deployed can be leveraged to deliver societal\n",
    "benefit and mitigate social harm.\n",
    "\n",
    "In that sense AI@Cam’s mission is close in spirit to that of Panacea’s\n",
    "elder sister Hygeia. It is focussed on building and maintaining the\n",
    "hygiene of a robust and equitable AI research ecosystem."
   ],
   "id": "30e1c3c4-51f2-4ea3-b3be-cb713db73e5e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Richard Feynmann on Doubt\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_physics/includes/richard-feynmann-doubt.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_physics/includes/richard-feynmann-doubt.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "> One thing is I can live with is doubt, and uncertainty and not\n",
    "> knowing. I think it’s much more interesting to live with not knowing\n",
    "> than to have an answer that might be wrong.\n",
    ">\n",
    "> Richard P. Feynmann in the *The Pleasure of Finding Things Out* 1981."
   ],
   "id": "f16a3d1d-7ba0-4d0d-a900-f0591c197870"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Intelligence\n",
    "\n",
    "One of the struggles of artificial intelligence is that the term means\n",
    "different things to different people. Our intelligence is precious to\n",
    "us, and the notion that it can be easily recreated is disturbing to us.\n",
    "This leads to some dystopian notions of artificial intelligence, such as\n",
    "the singularity.\n",
    "\n",
    "Depending on whether this powerful technology is viewed as beneficent or\n",
    "maleficent, it can be viewed either as a helpful assistant, in the\n",
    "manner of Jeeves, or a tyrannical dictator.\n",
    "\n",
    "<!-- AI Fallacy -->\n",
    "\n",
    "The history of automation and technology is a history of us adapting to\n",
    "technological change. The invention of the railways, and the need for\n",
    "consistent national times to timetable our movements. The development of\n",
    "the factory system in the mills of Derbyshire required workers to\n",
    "operate and maintain the machines that replaced them.\n",
    "\n",
    "Listening to modern to conversations about artificial intelligence, I\n",
    "think the use of the term *intelligence* has given rise to an idea that\n",
    "this technology will be the But amoung these different assessments of\n",
    "artificial intelligence is buried an idea, one that will be the first\n",
    "technology to adapt to us."
   ],
   "id": "1347e1cd-4adf-4209-b101-b8e8e0bad570"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Structure of Scientific Revolutions\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_books/includes/the-structure-of-scientific-revolutions.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_books/includes/the-structure-of-scientific-revolutions.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//books/structure-of-scientific-revolutions.png\" style=\"width:40%\">\n",
    "\n",
    "Figure: <i>[The Structure of Scientific Revolutions by Thomas S.\n",
    "Kuhn](https://en.wikipedia.org/wiki/The_Structure_of_Scientific_Revolutions)\n",
    "suggests scientific paradigms are recorded in books.</i>"
   ],
   "id": "05f896cf-7216-418e-ae3f-89150739146e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blake’s Newton\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_art/includes/blake-newton.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_art/includes/blake-newton.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//art/blake-newton.jpg\" style=\"width:80%\">\n",
    "\n",
    "Figure: <i>William Blake’s *Newton*.</i>"
   ],
   "id": "55ae9472-c45f-4944-84eb-2244d55917f0"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lunette Rehoboam Abijah\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_art/includes/michelangelo-lunette-rehoboam-abijah.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_art/includes/michelangelo-lunette-rehoboam-abijah.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//art/michelangelo-lunette-rehoboam-abijah.jpg\" style=\"width:80%\">\n",
    "\n",
    "Figure: <i>Lunette containing Rehoboam and Abijah.</i>\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//ai/people-culture.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>People communicate through artifacts and culture.</i>\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//ai/processor-ham.svg\" class=\"\" width=\"40%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i></i>"
   ],
   "id": "902b7ac0-4c73-47a3-9616-d78db27993ce"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elohim Creating Adam\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_art/includes/blake-elohim-creating-adam.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_art/includes/blake-elohim-creating-adam.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//art/blake-elohim-creating-adam.jpg\" style=\"width:60%\">\n",
    "\n",
    "Figure: <i>William Blake’s *Elohim Creating Adam*.</i>"
   ],
   "id": "38bff8d0-de25-417a-ae23-55ad5d31c109"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fall and Expulsion from Garden of Eden\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_art/includes/michelangelo-fall-and-expulsion-from-garden-of-eden.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_art/includes/michelangelo-fall-and-expulsion-from-garden-of-eden.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//art/michelangelo-fall-and-expulsion-from-the-garden-of-eden.jpg\" style=\"width:80%\">\n",
    "\n",
    "Figure: <i>Photo of detail of the fall and expulsion from the Garden of\n",
    "Eden.</i>\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//ai/bandwidth-vs-complexity.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Bandwidth vs Complexity.</i>\n",
    "\n",
    "<!-- Conversation LLM -->\n",
    "<!--\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ":::\n",
    "\n",
    "\n",
    "\n",
    "::: {.cell .markdown}\n",
    "\n",
    "## Complexity in Action \n",
    "\n",
    "<div style=\"text-align:right\"><span class=\"editsection-bracket\" style=\"\">[</span><span class=\"editsection\" style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_psychology/includes/selective-attention-bias.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_psychology/includes/selective-attention-bias.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">]</span></div>\n",
    "\n",
    "As an exercise in understanding complexity, watch the following video. You will see the basketball being bounced around, and the players moving. Your job is to count the passes of those dressed in white and ignore those of the individuals dressed in black.\n",
    "\n",
    "\n",
    ":::\n",
    "\n",
    "::: {.cell .code}\n",
    "\n",
    "```{.python}\n",
    "from IPython.lib.display import YouTubeVideo\n",
    "YouTubeVideo('vJG698U2Mvo')"
   ],
   "id": "fc156609-a5db-4bb0-82ac-c0da5719ab0a"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure: <i>Daniel Simon’s famous illusion “monkey business”. Focus on\n",
    "the movement of the ball distracts the viewer from seeing other aspects\n",
    "of the image.</i>\n",
    "\n",
    "In a classic study Simons and Chabris (1999) ask subjects to count the\n",
    "number of passes of the basketball between players on the team wearing\n",
    "white shirts. Fifty percent of the time, these subjects don’t notice the\n",
    "gorilla moving across the scene.\n",
    "\n",
    "The phenomenon of inattentional blindness is well known, e.g in their\n",
    "paper Simons and Charbris quote the Hungarian neurologist, Rezsö Bálint,\n",
    "\n",
    "> It is a well-known phenomenon that we do not notice anything happening\n",
    "> in our surroundings while being absorbed in the inspection of\n",
    "> something; focusing our attention on a certain object may happen to\n",
    "> such an extent that we cannot perceive other objects placed in the\n",
    "> peripheral parts of our visual field, although the light rays they\n",
    "> emit arrive completely at the visual sphere of the cerebral cortex.\n",
    ">\n",
    "> Rezsö Bálint 1907 (translated in Husain and Stein 1988, page 91)\n",
    "\n",
    "When we combine the complexity of the world with our relatively low\n",
    "bandwidth for information, problems can arise. Our focus on what we\n",
    "perceive to be the most important problem can cause us to miss other\n",
    "(potentially vital) contextual information.\n",
    "\n",
    "This phenomenon is known as selective attention or ‘inattentional\n",
    "blindness’."
   ],
   "id": "c34fe300-9dd6-4766-831b-34aac3d606f2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.lib.display import YouTubeVideo\n",
    "YouTubeVideo('_oGAzq5wM_Q')"
   ],
   "id": "4af97e0f-c300-4327-8c93-117df68a907a"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure: <i>For a longer talk on inattentional bias from Daniel Simons\n",
    "see this video.</i>\n",
    "\n",
    "–\\>\n",
    "\n",
    "    ```{=html}\n",
    "    <!--include{_data-science/includes/data-selection-attention-bias.md}-->\n",
    "\n",
    "<!-- Interfaces AI for Science -->\n",
    "<!--include{_ai/includes/interfaces-ai-for-science.md}-->\n",
    "<!-- Lecture 2 -->\n",
    "<!--\n",
    "Time scales, how when you expand or contract time signal becomes noise and noise becomes signal illustrate with Dirac delta and and stochastic processes in Fourier space, ito calculus. Latent force models.\n",
    "\n",
    "Practical examples of what happens understochasticity:\n",
    "\n",
    "0) Derive U = W + TS?? Go from microscopic to macroscopic. \n",
    "\n",
    "1) Kappenball --- world in between where interesting things happen,\n",
    "\n",
    "2) Queue efficiency (M/M/1  1/(1-\\rho))\n",
    "\n",
    "3) Input to the system being in the form of bias and variance (or perhaps Brownian motion, wiener process)\n",
    "\n",
    "(Latent force models being driven by this???? Latent force as high frequency information processing? Environment as slow?-->"
   ],
   "id": "cce66872-f9ee-4d41-81c6-e5663f4cf2b3"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laplace’s Demon\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_physics/includes/laplaces-demon.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_physics/includes/laplaces-demon.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
   ],
   "id": "409812bd-90b6-4faa-8f36-7f897b7558d1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import notutils as nu\n",
    "nu.display_google_book(id='1YQPAAAAQAAJ', page='PR17-IA2')"
   ],
   "id": "3614f86e-a25e-40cb-b42a-98e4a4268c99"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//physics/philosophicaless00lapliala_16_cropped.png\" style=\"width:60%\">\n",
    "\n",
    "Figure: <i>English translation of Laplace’s demon, taken from the\n",
    "Philosophical Essay on probabilities Laplace (1814) pg 3.</i>\n",
    "\n",
    "One way of viewing what Laplace is saying is that we can take “the\n",
    "forces by which nature is animated” or our best\n",
    "mathematical/computational abstraction of that which we would call the\n",
    "*model* and combine it with the “respective situation of the beings who\n",
    "compose it” which I would refer to as the *data* and if we have an\n",
    "“intelligence sufficiently vast enough to submit these data to\n",
    "analysis”, or sufficient *compute* then we would have a system for which\n",
    "“nothing would be uncertain and the future, as the past, would be\n",
    "present in its eyes”, or in other words we can make a *prediction*. Or\n",
    "more succinctly put we have\n",
    "\n",
    "<center>\n",
    "\n",
    "$$\n",
    "\\text{model} + \\text{data} \\stackrel{\\text{compute}}{\\rightarrow} \\text{prediction}.$$\n",
    "\n",
    "</center>\n",
    "\n",
    "Laplace’s demon has been a recurring theme in science, we can also find\n",
    "it in Stephen Hawking’s book *A Brief History of Time* (*A brief history\n",
    "of time*, 1988).\n",
    "\n",
    "> If we do discover a theory of everything … it would be the ultimate\n",
    "> triumph of human reason-for then we would truly know the mind of God\n",
    ">\n",
    "> Stephen Hawking in *A Brief History of Time* 1988\n",
    "\n",
    "But is it really that simple? Do we just need more and more accurate\n",
    "models and more and more data?"
   ],
   "id": "3387882e-7b9b-4e32-849e-02f26dbbea5f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Game of Life\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_simulation/includes/game-of-life.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_simulation/includes/game-of-life.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "[John Horton Conway](https://en.wikipedia.org/wiki/John_Horton_Conway)\n",
    "was a mathematician who developed a game known as the Game of Life. He\n",
    "died in April 2020, but since he invented the game, he was in effect\n",
    "‘god’ for this game. But as we will see, just inventing the rules\n",
    "doesn’t give you omniscience in the game.\n",
    "\n",
    "The Game of Life is played on a grid of squares, or pixels. Each pixel\n",
    "is either on or off. The game has no players, but a set of simple rules\n",
    "that are followed at each turn the rules are."
   ],
   "id": "a3b3268d-4846-4104-aeed-6bfd338d9d7a"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Life Rules\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_simulation/includes/life-rules.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_simulation/includes/life-rules.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "John Conway’s game of life is a cellular automaton where the cells obey\n",
    "three very simple rules. The cells live on a rectangular grid, so that\n",
    "each cell has 8 possible neighbors.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td width=\"70%\">\n",
    "<table>\n",
    "<tr>\n",
    "<td width=\"30%\">\n",
    "<center>\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//simulation/life-rules-1-0.svg\" class=\"\" width=\"100%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "</center>\n",
    "</td>\n",
    "<td width=\"39%\">\n",
    "<center>\n",
    "\n",
    "*loneliness*\n",
    "\n",
    "</center>\n",
    "<center>\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//util/right-arrow.svg\" class=\"\" width=\"60%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "</center>\n",
    "</td>\n",
    "<td width=\"30%\">\n",
    "<center>\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//simulation/life-rules-1-1.svg\" class=\"\" width=\"100%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "</center>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "</td>\n",
    "<td width=\"30%\">\n",
    "<center>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//maths/John-Conway.jpg\" style=\"width:100%\">\n",
    "\n",
    "</center>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Figure: <i>‘Death’ through loneliness in Conway’s game of life. If a\n",
    "cell is surrounded by less than three cells, it ‘dies’ through\n",
    "loneliness.</i>\n",
    "\n",
    "The game proceeds in turns, and at each location in the grid is either\n",
    "alive or dead. Each turn, a cell counts its neighbors. If there are two\n",
    "or fewer neighbors, the cell ‘dies’ of ‘loneliness’.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td width=\"70%\">\n",
    "<table>\n",
    "<tr>\n",
    "<td width=\"30%\">\n",
    "<center>\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//simulation/life-rules-2-0.svg\" class=\"\" width=\"100%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "</center>\n",
    "</td>\n",
    "<td width=\"39%\">\n",
    "<center>\n",
    "\n",
    "*overcrowding*\n",
    "\n",
    "</center>\n",
    "<center>\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//util/right-arrow.svg\" class=\"\" width=\"60%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "</center>\n",
    "</td>\n",
    "<td width=\"30%\">\n",
    "<center>\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//simulation/life-rules-2-1.svg\" class=\"\" width=\"100%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "</center>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "</td>\n",
    "<td width=\"30%\">\n",
    "<center>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//maths/John-Conway.jpg\" style=\"width:100%\">\n",
    "\n",
    "</center>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Figure: <i>‘Death’ through overpopulation in Conway’s game of life. If a\n",
    "cell is surrounded by more than three cells, it ‘dies’ through\n",
    "loneliness.</i>\n",
    "\n",
    "If there are four or more neighbors, the cell ‘dies’ from\n",
    "‘overcrowding’. If there are three neighbors, the cell persists, or if\n",
    "it is currently dead, a new cell is born.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td width=\"70%\">\n",
    "<table>\n",
    "<tr>\n",
    "<td width=\"30%\">\n",
    "<center>\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//simulation/life-rules-3-0.svg\" class=\"\" width=\"100%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "</center>\n",
    "</td>\n",
    "<td width=\"39%\">\n",
    "<center>\n",
    "\n",
    "*birth*\n",
    "\n",
    "</center>\n",
    "<center>\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//util/right-arrow.svg\" class=\"\" width=\"60%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "</center>\n",
    "</td>\n",
    "<td width=\"30%\">\n",
    "<center>\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//simulation/life-rules-3-1.svg\" class=\"\" width=\"100%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "</center>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "</td>\n",
    "<td width=\"30%\">\n",
    "<center>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//maths/John-Conway.jpg\" style=\"width:100%\">\n",
    "\n",
    "</center>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Figure: <i>Birth in Conway’s life. Any position surrounded by precisely\n",
    "three live cells will give birth to a new cell at the next turn.</i>\n",
    "\n",
    "And that’s it. Those are the simple ‘physical laws’ for Conway’s game.\n",
    "\n",
    "The game leads to patterns emerging, some of these patterns are static,\n",
    "but some oscillate in place, with varying periods. Others oscillate, but\n",
    "when they complete their cycle they’ve translated to a new location, in\n",
    "other words they move. In Life the former are known as\n",
    "[oscillators](https://conwaylife.com/wiki/Oscillator) and the latter as\n",
    "[spaceships](https://conwaylife.com/wiki/Spaceship)."
   ],
   "id": "e69d265e-970d-43df-982f-3b7135243767"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loafers and Gliders\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_simulation/includes/life-glider-loafer-conway.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_simulation/includes/life-glider-loafer-conway.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "John Horton Conway, as the creator of the game of life, could be seen\n",
    "somehow as the god of this small universe. He created the rules. The\n",
    "rules are so simple that in many senses he, and we, are all-knowing in\n",
    "this space. But despite our knowledge, this world can still ‘surprise’\n",
    "us. From the simple rules, emergent patterns of behaviour arise. These\n",
    "include static patterns that don’t change from one turn to the next.\n",
    "They also include, oscillators, that pulse between different forms\n",
    "across different periods of time. A particular form of oscillator is\n",
    "known as a ‘spaceship’, this is one that moves across the board as the\n",
    "game evolves. One of the simplest and earliest spaceships to be\n",
    "discovered is known as the glider.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td width=\"45%\">\n",
    "<center>\n",
    "\n",
    "*Glider (1969)*\n",
    "\n",
    "</center>\n",
    "<center>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//simulation/Glider.gif\" style=\"width:80%\">\n",
    "\n",
    "</center>\n",
    "</td>\n",
    "<td width=\"45%\">\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//maths/John-Conway.jpg\" style=\"width:80%\">\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Figure: <i>*Left* A Glider pattern discovered 1969 by Richard K. Guy.\n",
    "*Right*. John Horton Conway, creator of *Life* (1937-2020). The glider\n",
    "is an oscillator that moves diagonally after creation. From the simple\n",
    "rules of Life it’s not obvious that such an object does exist, until you\n",
    "do the necessary computation.</i>\n",
    "\n",
    "The glider was ‘discovered’ in 1969 by Richard K. Guy. What do we mean\n",
    "by discovered in this context? Well, as soon as the game of life is\n",
    "defined, objects such as the glider do somehow exist, but the many\n",
    "configurations of the game mean that it takes some time for us to see\n",
    "one and know it exists. This means, that despite being the creator,\n",
    "Conway, and despite the rules of the game being simple, and despite the\n",
    "rules being deterministic, we are not ‘omniscient’ in any simplistic\n",
    "sense. It requires computation to ‘discover’ what can exist in this\n",
    "universe once it’s been defined.\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//simulation/Gosperglidergun.gif\" style=\"width:80%\">\n",
    "\n",
    "Figure: <i>The Gosper glider gun is a configuration that creates\n",
    "gliders. A new glider is released after every 30 turns.</i>\n",
    "\n",
    "These patterns had to be discovered, in the same way that a scientist\n",
    "might discover a disease, or an explorer a new land. For example, the\n",
    "Gosper glider gun was [discovered by Bill Gosper in\n",
    "1970](https://conwaylife.com/wiki/Bill_Gosper). It is a pattern that\n",
    "creates a new glider every 30 turns of the game.\n",
    "\n",
    "Despite widespread interest in Life, some of its patterns were only very\n",
    "recently discovered like the Loafer, discovered in 2013 by Josh Ball.\n",
    "So, despite the game having existed for over forty years, and the rules\n",
    "of the game being simple, there are emergent behaviors that are unknown.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td width=\"45%\">\n",
    "<center>\n",
    "\n",
    "*Loafer (2013)*\n",
    "\n",
    "</center>\n",
    "<center>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//simulation/Loafer.gif\" style=\"width:80%\">\n",
    "\n",
    "</center>\n",
    "</td>\n",
    "<td width=\"45%\">\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//maths/John-Conway.jpg\" style=\"width:80%\">\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Figure: <i>*Left* A Loafer pattern discovered by Josh Ball in 2013.\n",
    "*Right*. John Horton Conway, creator of *Life* (1937-2020).</i>\n",
    "\n",
    "Once these patterns are discovered, they are combined (or engineered) to\n",
    "create new Life patterns that do some remarkable things. For example,\n",
    "there’s a life pattern that runs a Turing machine, or more remarkably\n",
    "there’s a Life pattern that runs Life itself.\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//simulation/life-in-life.gif\" style=\"width:80%\">\n",
    "\n",
    "Figure: <i>The Game of Life running in Life. The video is drawing out\n",
    "recursively showing pixels that are being formed by filling cells with\n",
    "moving spaceships. Each individual pixel in this game of life is made up\n",
    "of $2048 \\times 2048$ pixels called an [OTCA\n",
    "metapixel](https://www.conwaylife.com/wiki/OTCA_metapixel).</i>\n",
    "\n",
    "To find out more about the Game of Life you can watch this video by Alan\n",
    "Zucconi or read his [associated blog\n",
    "post](https://www.alanzucconi.com/2020/10/13/conways-game-of-life/)."
   ],
   "id": "ddad8800-4ea5-47a2-8874-eb920ac33d70"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.lib.display import YouTubeVideo\n",
    "YouTubeVideo('Kk2MH9O4pXY')"
   ],
   "id": "7b062522-4ab9-4174-be55-6df247daf36e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure: <i>An introduction to the Game of Life by Alan Zucconi.</i>\n",
    "\n",
    "Contrast this with our situation where in ‘real life’ we don’t know the\n",
    "simple rules of the game, the state space is larger, and emergent\n",
    "behaviors (hurricanes, earthquakes, volcanos, climate change) have\n",
    "direct consequences for our daily lives, and we understand why the\n",
    "process of ‘understanding’ the physical world is so difficult. We also\n",
    "see immediately how much easier we might expect the physical sciences to\n",
    "be than the social sciences, where the emergent behaviors are contingent\n",
    "on highly complex human interactions."
   ],
   "id": "483ea903-9c86-49b2-bd1d-05022d15b5ba"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emergent Behaviour\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_physics/includes/emergent-behaviour.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_physics/includes/emergent-behaviour.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
   ],
   "id": "e2fad986-a60d-435c-9dd5-ed75e61bc377"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laplace’s Gremlin\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_physics/includes/laplaces-gremlin.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_physics/includes/laplaces-gremlin.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "> The curve described by a simple molecule of air or vapor is regulated\n",
    "> in a manner just as certain as the planetary orbits; the only\n",
    "> difference between them is that which comes from our ignorance.\n",
    "> Probability is relative, in part to this ignorance, in part to our\n",
    "> knowledge. We know that of three or greater number of events a single\n",
    "> one ought to occur; but nothing induces us to believe that one of them\n",
    "> will occur rather than the others. In this state of indecision it is\n",
    "> impossible for us to announce their occurrence with certainty. It is,\n",
    "> however, probable that one of these events, chosen at will, will not\n",
    "> occur because we see several cases equally possible which exclude its\n",
    "> occurrence, while only a single one favors it.\n",
    ">\n",
    "> — Pierre-Simon Laplace (Laplace, 1814), pg 5\n",
    "\n",
    "The representation of ignorance through probability is the true message\n",
    "of Laplace, I refer to this message as “Laplace’s gremlin”, because it\n",
    "is the gremlin of uncertainty that interferes with the demon of\n",
    "determinism to mean that our predictions are not deterministic.\n",
    "\n",
    "Our separation of the uncertainty into the data, the model and the\n",
    "computation give us three domains in which our doubts can creep into our\n",
    "ability to predict. Over the last three lectures we’ve introduced some\n",
    "of the basic tools we can use to unpick this uncertainty. You’ve been\n",
    "introduced to, (or have yow reviewed) *Bayes’ rule*. The rule, which is\n",
    "a simple consequence of the product rule of probability, is the\n",
    "foundation of how we update our beliefs in the presence of new\n",
    "information.\n",
    "\n",
    "The real point of Laplace’s essay was that we don’t have access to all\n",
    "the data, we don’t have access to a complete physical understanding, and\n",
    "as the example of the Game of Life shows, even if we did have access to\n",
    "both (as we do for “Conway’s universe”) we still don’t have access to\n",
    "all the compute that we need to make deterministic predictions. There is\n",
    "uncertainty in the system which means we can’t make precise predictions.\n",
    "\n",
    "Gremlins are imaginary creatures used as an explanation of failure in\n",
    "aircraft, causing crashes. In that sense the Gremlin represents the\n",
    "uncertainty that a pilot felt about what might go wrong in a plane which\n",
    "might be “theoretically sound” but in practice is poorly maintained or\n",
    "exposed to conditions that take it beyond its design criteria. Laplace’s\n",
    "gremlin is all the things that your model, data and ability to compute\n",
    "don’t account for bringing about failures in your ability to predict.\n",
    "Laplace’s gremlin is the uncertainty in the system.\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//ai/gremlins-think-its-fun-to-hurt-you.jpg\" style=\"width:40%\">\n",
    "\n",
    "Figure: <i>Gremlins are seen as the cause of a number of challenges in\n",
    "this World War II poster.</i>"
   ],
   "id": "27e36217-4b86-49d5-bbe1-208cdbe354e4"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lenox Globe\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//ai/lenox-globe.png\" style=\"width:50%\">\n",
    "\n",
    "Figure: <i>[The Lenox\n",
    "globe](http://www.myoldmaps.com/renaissance-maps-1490-1800/314-the-lenox-globe/314-lenox.pdf),\n",
    "which dates from early 16th century, one of the earliest known\n",
    "globes.</i>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//ai/lenox-globe-by-b-f-da-costa.png\" style=\"width:100%\">\n",
    "\n",
    "Figure: <i>Drawing of the Lenox Globe by the historian for the Magazine\n",
    "of American History in September 1879.</i>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//ai/lenox-globe-hic-sunt-dracones.png\" style=\"width:60%\">\n",
    "\n",
    "Figure: <i>Detail from the Lenox globe located in the region of China,\n",
    "“hic sunt dracones”</i>"
   ],
   "id": "b2d042b2-9d33-4468-93a7-bd9c1b2d45ca"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_physics/includes/d-day-weather.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_physics/includes/d-day-weather.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "So what’s going on here? One analogy I like to use is with weather\n",
    "forecasting. Historically, before the use of computer driven weather\n",
    "forecasting, we used a process of interpolation to measure the pressure.\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//physics/1944-06-05_met-office-weather.png\" style=\"width:80%\">\n",
    "\n",
    "Figure: <i>Forecast from UK Met Office on 5th June 1944. (detail from\n",
    "<https://www.metoffice.gov.uk/research/library-and-archive/archive-hidden-treasures/d-day>)</i>\n",
    "\n",
    "This was problematic for German forces in the Second World War because\n",
    "they had no ability to predict the weather when it was coming in from\n",
    "across the UK. Conversely, the UK had a number of weather stations in\n",
    "the UK, and some information (perhaps from spies or Enigma decrypts)\n",
    "about weather on the mainland.\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//physics/1944-06-05_dwd-weather.png\" style=\"width:80%\">\n",
    "\n",
    "Figure: <i>Forecast from Deutscher Wetterdienst on 5th June 1944.\n",
    "(detail from\n",
    "<https://www.metoffice.gov.uk/research/library-and-archive/archive-hidden-treasures/d-day>).\n",
    "Note the lack of measurements within the UK. THis is the direction that\n",
    "weather was coming from so the locaiton of weather fronts (and\n",
    "associated storms) was harder for the Deutscher Wetterdienst to predict\n",
    "than the Met Office.</i>\n",
    "\n",
    "This meant that more accurate forecasts were possible for D-Day for the\n",
    "Allies than for the defending forces. As a result, on the morning that\n",
    "Eisenhower invated, Rommel was back in Germany attending his wife’s 50th\n",
    "birthday party.\n",
    "\n",
    "Modern artificial intelligence solutions are using very large amounts of\n",
    "data to build a landscape in which this interpolation can take place.\n",
    "Tools like ChatGPT are allowing us to interpolate between different\n",
    "human concepts. This is an amazing achievement, but it is also a\n",
    "challenge.\n",
    "\n",
    "<!-- thermodynamics -->"
   ],
   "id": "090a3c3d-d735-4ae3-a909-dd19616296e2"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boulton and Watt’s Lap Engine\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_physics/includes/lap-engine.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_physics/includes/lap-engine.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td width=\"60%\">\n",
    "<center>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//physics/lap-engine.jpg\" style=\"width:100%\">\n",
    "\n",
    "</center>\n",
    "<center>\n",
    "\n",
    "*Lap Engine (1788)*\n",
    "\n",
    "</center>\n",
    "</td>\n",
    "<td width=\"40%\">\n",
    "<center>\n",
    "\n",
    "total energy <br> = <br> available energy <br> + <br> temperature <br>\n",
    "$\\times$ <br>entropy\n",
    "\n",
    "</center>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Figure: <i>James Watt’s Lap Engine which incorporates many of his\n",
    "innovations to the steam engine, making it more efficient.</i>\n",
    "\n",
    "<!--THEORY of IGNORANCE-->"
   ],
   "id": "92114135-cca2-4e08-a747-ef9ec6bf3a52"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory of Ignorance\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_physics/includes/theory-of-ignorance.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_physics/includes/theory-of-ignorance.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td width=\"30%\">\n",
    "<center>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//philosophy/Bertrand_Russell_1957.jpg\" style=\"width:100%\">\n",
    "\n",
    "</center>\n",
    "</td>\n",
    "<td width=\"30%\">\n",
    "<center>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//physics/Albert_Einstein_photo_1921.jpg\" style=\"width:50%\">\n",
    "\n",
    "</center>\n",
    "</td>\n",
    "<td width=\"30%\">\n",
    "<center>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//physics/Norbert_wiener.jpg\" style=\"width:100%\">\n",
    "\n",
    "</center>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Figure: <i>Bertrand Russell (1872-1970), Albert Einstein (1879-1955),\n",
    "Norbert Wiener, (1894-1964)</i>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//physics/brownian-motion.gif\" style=\"width:40%\">\n",
    "\n",
    "Figure: <i>Brownian motion of a large particle in a group of smaller\n",
    "particles. The movement is known as a *Wiener process* after Norbert\n",
    "Wiener.</i>\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td width=\"30%\">\n",
    "<center>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//physics/james-clerk-maxwell.png\" style=\"width:100%\">\n",
    "\n",
    "</center>\n",
    "<center>\n",
    "\n",
    "*James Clerk Maxwell*\n",
    "\n",
    "</center>\n",
    "</td>\n",
    "<td width=\"30%\">\n",
    "<center>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//physics/boltzmann2.jpg\" style=\"width:100%\">\n",
    "\n",
    "</center>\n",
    "<center>\n",
    "\n",
    "*Ludwig Boltzmann*\n",
    "\n",
    "</center>\n",
    "</td>\n",
    "<td width=\"30%\">\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//physics/j-w-gibbs.jpg\" style=\"width:100%\">\n",
    "\n",
    "<center>\n",
    "\n",
    "*Josiah Willard Gibbs*\n",
    "\n",
    "</center>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Figure: <i>James Clerk Maxwell (1831-1879), Ludwig Boltzmann (1844-1906)\n",
    "Josiah Willard Gibbs (1839-1903)</i>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//ml/E.-H.-Shepard_Two-ink-drawings-from-The-House-at-Pooh-Corner-I_.jpg\" style=\"width:80%\">\n",
    "\n",
    "Figure: <i>Rabbit and Pooh watch the result of Pooh’s hooshing idea to\n",
    "move Eeyore towards the shore.</i>\n",
    "\n",
    "> When you are a Bear of Very Little Brain, and you Think of Things, you\n",
    "> find sometimes that a Thing which seemed very Thingish inside you is\n",
    "> quite different when it gets out into the open and has other people\n",
    "> looking at it.\n",
    ">\n",
    "> A.A. Milne as Winnie-the-Pooh in *The House at Pooh Corner*, 1928\n",
    "\n",
    "This comment from Pooh bear comes just as he’s tried to rescue his\n",
    "donkey friend, Eeyore, from a river by dropping a large stone on him\n",
    "from a bridge. Pooh’s idea had been to create a wave to push the donkey\n",
    "to the shore, a process that Pooh’s rabbit friend calls “hooshing”.\n",
    "\n",
    "Hooshing is a technique many children will have tried to retrieve a ball\n",
    "from a river. It can work, so Pooh’s idea wasn’t a bad one, but the\n",
    "challenge he faced was in its execution. Pooh aimed to the side of\n",
    "Eeyore, unfortunately the stone fell directly on the stuffed donkey. But\n",
    "where is Laplace’s demon in hooshing? Just as we can talk about Gliders\n",
    "and Loafers in Conway’s Game of Life, we talk about stones and donkeys\n",
    "in our Universe. Pooh’s prediction that he can hoosh the donkey with the\n",
    "stone is not based on the Theory, it comes from observing the way\n",
    "objects interact in the actual Universe. Pooh is like the mice in\n",
    "Douglas Adams’s Earth. He is observing his environment. He looks for\n",
    "patterns in that environment. Pooh then borrows the computation that the\n",
    "Universe has already done for us. He has seen similar situations before,\n",
    "perhaps he once used a stone to hoosh a ball. He is then generalising\n",
    "from these previous circumstances to suggest that he can also hoosh the\n",
    "donkey. Despite being a bear of little brain, like the mice on Adams’s\n",
    "Earth, Pooh can answer questions about his universe by observing the\n",
    "results of the Theory of Everything playing out around him."
   ],
   "id": "e1d1269d-e027-4368-a56a-2c032e83d19e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hydrodynamica\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_physics/includes/daniel-bernoulli-hydrodynamica.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_physics/includes/daniel-bernoulli-hydrodynamica.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "When Laplace spoke of the curve of a simple molecule of air, he may well\n",
    "have been thinking of Daniel Bernoulli (1700-1782). Daniel Bernoulli was\n",
    "one name in a prodigious family. His father and brother were both\n",
    "mathematicians. Daniel’s main work was known as *Hydrodynamica*."
   ],
   "id": "fb4f41d3-8d69-4484-9e61-9be755900d3d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import notutils as nu\n",
    "nu.display_google_book(id='3yRVAAAAcAAJ', page='PP7')"
   ],
   "id": "071968ff-4929-45d8-a2d2-84a178028050"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure: <i>Daniel Bernoulli’s *Hydrodynamica* published in 1738. It was\n",
    "one of the first works to use the idea of conservation of energy. It\n",
    "used Newton’s laws to predict the behaviour of gases.</i>\n",
    "\n",
    "Daniel Bernoulli described a kinetic theory of gases, but it wasn’t\n",
    "until 170 years later when these ideas were verified after Einstein had\n",
    "proposed a model of Brownian motion which was experimentally verified by\n",
    "Jean Baptiste Perrin."
   ],
   "id": "6a5c32cd-f208-45df-b14d-f09d96ccf6d0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import notutils as nu\n",
    "nu.display_google_book(id='3yRVAAAAcAAJ', page='PA200')"
   ],
   "id": "0e859cd6-753d-4c57-91b1-1116606eb740"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure: <i>Daniel Bernoulli’s chapter on the kinetic theory of gases,\n",
    "for a review on the context of this chapter see Mikhailov (n.d.). For\n",
    "1738 this is extraordinary thinking. The notion of kinetic theory of\n",
    "gases wouldn’t become fully accepted in Physics until 1908 when a model\n",
    "of Einstein’s was verified by Jean Baptiste Perrin.</i>"
   ],
   "id": "138c5242-95ca-454c-bddc-2cbd59aeb584"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy Billiards\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_physics/includes/entropy-billiards.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_physics/includes/entropy-billiards.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<canvas id=\"multiball-canvas\" width=\"700\" height=\"500\" style=\"border:1px solid black;display:inline;text-align:left \">\n",
    "</canvas>\n",
    "\n",
    "Entropy:\n",
    "\n",
    "<output id=\"multiball-entropy\">\n",
    "</output>\n",
    "\n",
    "<button id=\"multiball-newball\" style=\"text-align:right\">\n",
    "\n",
    "New Ball\n",
    "\n",
    "</button>\n",
    "<button id=\"multiball-pause\" style=\"text-align:right\">\n",
    "\n",
    "Pause\n",
    "\n",
    "</button>\n",
    "<button id=\"multiball-skip\" style=\"text-align:right\">\n",
    "\n",
    "Skip 1000s\n",
    "\n",
    "</button>\n",
    "<button id=\"multiball-histogram\" style=\"text-align:right\">\n",
    "\n",
    "Histogram\n",
    "\n",
    "</button>\n",
    "\n",
    "<script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>\n",
    "<script src=\"https://inverseprobability.com/talks/scripts//ballworld/ballworld.js\"></script>\n",
    "<script src=\"https://inverseprobability.com/talks/scripts//ballworld/multiball.js\"></script>\n",
    "\n",
    "Figure: <i>Bernoulli’s simple kinetic models of gases assume that the\n",
    "molecules of air operate like billiard balls.</i>"
   ],
   "id": "c823cac4-47b5-490b-bad1-3001845cf67b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "id": "4221598f-9dce-48ec-9e6e-64f4b97e3e85"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.random.randn(10000, 1)\n",
    "xlim = [-4, 4]\n",
    "x = np.linspace(xlim[0], xlim[1], 200)\n",
    "y = 1/np.sqrt(2*np.pi)*np.exp(-0.5*x*x)"
   ],
   "id": "e8e5aa2b-def0-4214-8812-44f834babf2f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mlai.plot as plot\n",
    "import mlai"
   ],
   "id": "42d1b9da-e740-4410-8c26-b04b3c4fbc51"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=plot.big_wide_figsize)\n",
    "ax.plot(x, y, 'r', linewidth=3)\n",
    "ax.hist(p, 100, density=True)\n",
    "ax.set_xlim(xlim)\n",
    "\n",
    "mlai.write_figure('gaussian-histogram.svg', directory='./ml')"
   ],
   "id": "fb7093bb-f484-44ed-985b-26f245a9b718"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important figure for Cambridge was the first to derive the\n",
    "probability distribution that results from small balls banging together\n",
    "in this manner. In doing so, James Clerk Maxwell founded the field of\n",
    "statistical physics.\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//ml/gaussian-histogram.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>James Clerk Maxwell 1831-1879 Derived distribution of\n",
    "velocities of particles in an ideal gas (elastic fluid).</i>\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td width=\"30%\">\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//physics/james-clerk-maxwell.png\" style=\"width:100%\">\n",
    "\n",
    "</td>\n",
    "<td width=\"30%\">\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//physics/boltzmann2.jpg\" style=\"width:100%\">\n",
    "\n",
    "</td>\n",
    "<td width=\"30%\">\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//physics/j-w-gibbs.jpg\" style=\"width:100%\">\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Figure: <i>James Clerk Maxwell (1831-1879), Ludwig Boltzmann (1844-1906)\n",
    "Josiah Willard Gibbs (1839-1903)</i>\n",
    "\n",
    "Many of the ideas of early statistical physicists were rejected by a\n",
    "cadre of physicists who didn’t believe in the notion of a molecule. The\n",
    "stress of trying to have his ideas established caused Boltzmann to\n",
    "commit suicide in 1906, only two years before the same ideas became\n",
    "widely accepted."
   ],
   "id": "5f6d5165-a3ac-4b10-a630-cd30488ae428"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import notutils as nu\n",
    "nu.display_google_book(id='Vuk5AQAAMAAJ', page='PA373')"
   ],
   "id": "2a286321-5dd2-48ce-b046-8db52bc31cf1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure: <i>Boltzmann’s paper Boltzmann (n.d.) which introduced the\n",
    "relationship between entropy and probability. A translation with notes\n",
    "is available in Sharp and Matschinsky (2015).</i>\n",
    "\n",
    "The important point about the uncertainty being represented here is that\n",
    "it is not genuine stochasticity, it is a lack of knowledge about the\n",
    "system. The techniques proposed by Maxwell, Boltzmann and Gibbs allow us\n",
    "to exactly represent the state of the system through a set of parameters\n",
    "that represent the sufficient statistics of the physical system. We know\n",
    "these values as the volume, temperature, and pressure. The challenge for\n",
    "us, when approximating the physical world with the techniques we will\n",
    "use is that we will have to sit somewhere between the deterministic and\n",
    "purely stochastic worlds that these different scientists described.\n",
    "\n",
    "One ongoing characteristic of people who study probability and\n",
    "uncertainty is the confidence with which they hold opinions about it.\n",
    "Another leader of the Cavendish laboratory expressed his support of the\n",
    "second law of thermodynamics (which can be proven through the work of\n",
    "Gibbs/Boltzmann) with an emphatic statement at the beginning of his\n",
    "book.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td width=\"49%\">\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//physics/arthur-stanley-eddington.jpg\" style=\"width:100%\">\n",
    "\n",
    "</td>\n",
    "<td width=\"49%\">\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//physics/natureofphysical00eddi_7.png\" style=\"width:80%\">\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Figure: <i>Eddington’s book on the Nature of the Physical World\n",
    "(Eddington, 1929)</i>\n",
    "\n",
    "The same Eddington is also famous for dismissing the ideas of a young\n",
    "Chandrasekhar who had come to Cambridge to study in the Cavendish lab.\n",
    "Chandrasekhar demonstrated the limit at which a star would collapse\n",
    "under its own weight to a singularity, but when he presented the work to\n",
    "Eddington, he was dismissive suggesting that there “must be some natural\n",
    "law that prevents this abomination from happening”.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td width=\"49%\">\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//physics/natureofphysical00eddi_100.png\" style=\"width:80%\">\n",
    "\n",
    "</td>\n",
    "<td width=\"49%\">\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//physics/ChandraNobel.png\" style=\"width:100%\">\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Figure: <i>Chandrasekhar (1910-1995) derived the limit at which a star\n",
    "collapses in on itself. Eddington’s confidence in the 2nd law may have\n",
    "been what drove him to dismiss Chandrasekhar’s ideas, humiliating a\n",
    "young scientist who would later receive a Nobel prize for the work.</i>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//physics/natureofphysical00eddi_100_cropped.png\" style=\"width:60%\">\n",
    "\n",
    "Figure: <i>Eddington makes his feelings about the primacy of the second\n",
    "law clear. This primacy is perhaps because the second law can be\n",
    "demonstrated mathematically, building on the work of Maxwell, Gibbs and\n",
    "Boltzmann. Eddington (1929)</i>\n",
    "\n",
    "Presumably he meant that the creation of a black hole seemed to\n",
    "transgress the second law of thermodynamics, although later Hawking was\n",
    "able to show that blackholes do evaporate, but the time scales at which\n",
    "this evaporation occurs is many orders of magnitude slower than other\n",
    "processes in the universe."
   ],
   "id": "564c9ddb-d811-4dd6-a4ea-51385319143e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brownian Motion and Wiener\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_physics/includes/brownian-wiener.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_physics/includes/brownian-wiener.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "Robert Brown was a botanist who was studying plant pollen in 1827 when\n",
    "he noticed a trembling motion of very small particles contained within\n",
    "cavities within the pollen. He worked hard to eliminate the potential\n",
    "source of the movement by exploring other materials where he found it to\n",
    "be continuously present. Thus, the movement was not associated, as he\n",
    "originally thought, with life.\n",
    "\n",
    "In 1905 Albert Einstein produced the first mathematical explanation of\n",
    "the phenomenon. This can be seen as our first model of a ‘curve of a\n",
    "simple molecule of air’. To model the phenomenon Einstein introduced\n",
    "stochasticity to a differential equation. The particles were being\n",
    "peppered with high-speed water molecules, that was triggering the\n",
    "motion. Einstein modelled this as a stochastic process.\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//physics/Albert_Einstein_photo_1921.jpg\" style=\"width:40%\">\n",
    "\n",
    "Figure: <i>Albert Einstein’s 1905 paper on Brownian motion introduced\n",
    "stochastic differential equations which can be used to model the ‘curve\n",
    "of a simple molecule of air’.</i>\n",
    "\n",
    "Norbert Wiener was a child prodigy, whose father had schooled him in\n",
    "philosophy. He was keen to have his son work with the leading\n",
    "philosophers of the age, so at the age of 18 Wiener arrived in Cambridge\n",
    "(already with a PhD). He was despatched to study with Bertrand Russell\n",
    "but Wiener and Russell didn’t get along. Wiener wasn’t persuaded by\n",
    "Russell’s ideas for theories of knowledge through logic. He was more\n",
    "aligned with Laplace and his desire for a theory of ignorance. In is\n",
    "autobiography he relates it as the first thing he could see his father\n",
    "was proud of (at around the age of 10 or 11) (Wiener, 1953).\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td width=\"30%\">\n",
    "<center>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//philosophy/Bertrand_Russell_1957.jpg\" style=\"width:100%\">\n",
    "\n",
    "</center>\n",
    "</td>\n",
    "<td width=\"30%\">\n",
    "<center>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//physics/Albert_Einstein_photo_1921.jpg\" style=\"width:85%\">\n",
    "\n",
    "</center>\n",
    "</td>\n",
    "<td width=\"30%\">\n",
    "<center>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//physics/Norbert_wiener.jpg\" style=\"width:100%\">\n",
    "\n",
    "</center>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Figure: <i>Bertrand Russell (1872-1970), Albert Einstein (1879-1955),\n",
    "Norbert Wiener, (1894-1964)</i>\n",
    "\n",
    "But Russell (despite also not getting along well with Wiener) introduced\n",
    "Wiener to Einstein’s works, and Wiener also met G. H. Hardy. He left\n",
    "Cambridge for Göttingen where he studied with Hilbert. He developed the\n",
    "underlying mathematics for proving the existence of the solutions to\n",
    "Einstein’s equation, which are now known as Wiener processes.\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//physics/brownian-motion.gif\" style=\"width:40%\">\n",
    "\n",
    "Figure: <i>Brownian motion of a large particle in a group of smaller\n",
    "particles. The movement is known as a *Wiener process* after Norbert\n",
    "Wiener.</i>\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td width=\"45%\">\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//physics/Norbert_wiener.jpg\" style=\"width:100%\">\n",
    "\n",
    "</td>\n",
    "<td width=\"45%\">\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//books/wiener-yellow-peril.png\" style=\"width:100%\">\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Figure: <i>Norbert Wiener (1894 - 1964). Founder of cybernetics and the\n",
    "information era. He used Gibbs’s ideas to develop a “theory of\n",
    "ignorance” that he deployed in early communication. On the right is\n",
    "Wiener’s wartime report that used stochastic processes in forecasting\n",
    "with applications in radar control (image from Coales and Kane\n",
    "(2014)).</i>\n",
    "\n",
    "Wiener himself used the processes in his work. He was focused on\n",
    "mathematical theories of communication. Between the world wars he was\n",
    "based at Massachusetts Institute of Technology where the burgeoning\n",
    "theory of electrical engineering was emerging, with a particular focus\n",
    "on communication lines. Winer developed theories of communication that\n",
    "used Gibbs’s entropy to encode information. He also used the ideas\n",
    "behind the Wiener process for developing tracking methods for radar\n",
    "systems in the second world war. These processes are what we know of now\n",
    "as Gaussian processes (Wiener (1949))."
   ],
   "id": "55f41a07-fd8e-4b79-86a4-b9adcc2b00a0"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kappenball\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_physics/includes/kappenball.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_physics/includes/kappenball.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<span style=\"float:left;\">Score:\n",
    "\n",
    "<output id=\"kappenball-score\">\n",
    "</output>\n",
    "\n",
    "</span> <span style=\"float:right;\">Energy:\n",
    "\n",
    "<output id=\"kappenball-energy\">\n",
    "</output>\n",
    "\n",
    "</span>\n",
    "\n",
    "<canvas id=\"kappenball-canvas\" width=\"900\" height=\"500\" style=\"border:1px solid black;display:inline;text-align:center \">\n",
    "</canvas>\n",
    "\n",
    "<input type=\"range\" min=\"0\" max=\"100\" value=\"0\" class=\"slider\" id=\"kappenball-stochasticity\" style=\"width:900px;\"/>\n",
    "\n",
    "<button id=\"kappenball-newball\" style=\"text-align:right\">\n",
    "\n",
    "New Ball\n",
    "\n",
    "</button>\n",
    "<button id=\"kappenball-pause\" style=\"text-align:right\">\n",
    "\n",
    "Pause\n",
    "\n",
    "</button>\n",
    "\n",
    "<output id=\"kappenball-count\">\n",
    "</output>\n",
    "<script src=\"https://inverseprobability.com/talks/scripts//ballworld/kappenball.js\"></script>\n",
    "\n",
    "Figure: <i>Kappen Ball</i>\n",
    "\n",
    "If you want to complete a task, should you do it now or should you put\n",
    "it off until tomorrow? Despite being told to not delay tasks, many of us\n",
    "are deadline driven. Why is this?\n",
    "\n",
    "Kappenball is a simple game that illustrates that this behaviour can be\n",
    "optimal. It is inspired by an example in stochastic optimal control by\n",
    "[Bert Kappen](https://www.snn.ru.nl/~bertk/). The game is as follows:\n",
    "you need to place a falling balloon into one of two holes, but if the\n",
    "balloon misses the holes it will pop on pins placed in the ground. In\n",
    "‘deterministic mode’, the balloon falls straight towards the ground and\n",
    "the game is easy. You simply choose which hole to place the ball in, and\n",
    "you can start to place it there as soon as the ball appears at the top\n",
    "of the screen. The game becomes more interesting as you increase the\n",
    "uncertainty. In Kappenball, the uncertainty takes the form of the\n",
    "balloon being blown left and right as it falls. This movement means that\n",
    "it is not sensible to decide early on which hole to place the balloon\n",
    "in. A better strategy is to wait and see which hole the ball falls\n",
    "towards. You can then place it in that hole using less energy than in\n",
    "deterministic mode. Sometimes, the ball even falls into the hole on its\n",
    "own, and you don’t have to expend any energy, but it requires some skill\n",
    "to judge when you need to intervene. For this system Bert Kappen has\n",
    "shown mathematically that the best solution is to wait until the ball is\n",
    "close to the hole before you push it in. In other words, you should be\n",
    "deadline driven.\n",
    "\n",
    "In fact, it seems here uncertainty is a good thing, because on average\n",
    "you’ll get the ball into the hole with less energy (by playing\n",
    "intelligently, and being deadline driven!) than you do with\n",
    "\\`deterministic mode’. It requires some skill to do this, more than the\n",
    "deterministic system, but by using your resources intelligently you can\n",
    "get more out of the system. However, if the uncertainty increases too\n",
    "much then regardless of your skill, you can’t control the ball at all.\n",
    "\n",
    "This simple game explains many of the behaviours we exhibit in real\n",
    "life. If a system is completely deterministic, then we can make a\n",
    "decision early on and be sure that the ball will ‘drop in the hole’.\n",
    "However, if there is uncertainty in a system, it can make sense to delay\n",
    "our decision making until we’ve seen how events ‘pan out’. Be careful\n",
    "though, as we also see that when the uncertainty is large, if you don’t\n",
    "have the resources or the skill to be deadline-driven the uncertainty\n",
    "can overwhelm you and events can quickly move beyond our control."
   ],
   "id": "98513a57-b186-4c24-8df1-9c5816e90925"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Inference by Rejection Sampling\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_gp/includes/gp-intro-very-short.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_gp/includes/gp-intro-very-short.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "One view of Bayesian inference is to assume we are given a mechanism for\n",
    "generating samples, where we assume that mechanism is representing an\n",
    "accurate view on the way we believe the world works.\n",
    "\n",
    "This mechanism is known as our *prior* belief.\n",
    "\n",
    "We combine our prior belief with our observations of the real world by\n",
    "discarding all those prior samples that are inconsistent with our\n",
    "observations. The *likelihood* defines mathematically what we mean by\n",
    "inconsistent with the observations. The higher the noise level in the\n",
    "likelihood, the looser the notion of consistent.\n",
    "\n",
    "The samples that remain are samples from the *posterior*.\n",
    "\n",
    "This approach to Bayesian inference is closely related to two sampling\n",
    "techniques known as *rejection sampling* and *importance sampling*. It\n",
    "is realized in practice in an approach known as *approximate Bayesian\n",
    "computation* (ABC) or likelihood-free inference.\n",
    "\n",
    "In practice, the algorithm is often too slow to be practical, because\n",
    "most samples will be inconsistent with the observations and as a result\n",
    "the mechanism must be operated many times to obtain a few posterior\n",
    "samples.\n",
    "\n",
    "However, in the Gaussian process case, when the likelihood also assumes\n",
    "Gaussian noise, we can operate this mechanism mathematically, and obtain\n",
    "the posterior density *analytically*. This is the benefit of Gaussian\n",
    "processes.\n",
    "\n",
    "First, we will load in two python functions for computing the covariance\n",
    "function."
   ],
   "id": "6cdc084f-84d7-4f82-8c2b-1eccfc4ba060"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai"
   ],
   "id": "0153135c-55de-4e05-ae99-6ea4561b2589"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load -n mlai.Kernel"
   ],
   "id": "bb653d28-1f3b-4555-a257-536cb6fe8a72"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -n mlai.Kernel\n",
    "class Kernel():\n",
    "    \"\"\"Covariance function\n",
    "    :param function: covariance function\n",
    "    :type function: function\n",
    "    :param name: name of covariance function\n",
    "    :type name: string\n",
    "    :param shortname: abbreviated name of covariance function\n",
    "    :type shortname: string\n",
    "    :param formula: latex formula of covariance function\n",
    "    :type formula: string\n",
    "    :param function: covariance function\n",
    "    :type function: function\n",
    "    :param \\**kwargs:\n",
    "        See below\n",
    "\n",
    "    :Keyword Arguments:\n",
    "        * \"\"\"\n",
    "\n",
    "    def __init__(self, function, name=None, shortname=None, formula=None, **kwargs):        \n",
    "        self.function=function\n",
    "        self.formula = formula\n",
    "        self.name = name\n",
    "        self.shortname = shortname\n",
    "        self.parameters=kwargs\n",
    "        \n",
    "    def K(self, X, X2=None):\n",
    "        \"\"\"Compute the full covariance function given a kernel function for two data points.\"\"\"\n",
    "        if X2 is None:\n",
    "            X2 = X\n",
    "        K = np.zeros((X.shape[0], X2.shape[0]))\n",
    "        for i in np.arange(X.shape[0]):\n",
    "            for j in np.arange(X2.shape[0]):\n",
    "                K[i, j] = self.function(X[i, :], X2[j, :], **self.parameters)\n",
    "\n",
    "        return K\n",
    "\n",
    "    def diag(self, X):\n",
    "        \"\"\"Compute the diagonal of the covariance function\"\"\"\n",
    "        diagK = np.zeros((X.shape[0], 1))\n",
    "        for i in range(X.shape[0]):            \n",
    "            diagK[i] = self.function(X[i, :], X[i, :], **self.parameters)\n",
    "        return diagK\n",
    "\n",
    "    def _repr_html_(self):\n",
    "        raise NotImplementedError"
   ],
   "id": "0e741eca-f55d-4462-b580-f937c94c8f31"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai"
   ],
   "id": "9aa9846c-f1a8-4eba-bdcd-332d76e02ab5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load -n mlai.eq_cov"
   ],
   "id": "77505c8a-2523-41d0-bb3b-809ddfc34112"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -n mlai.eq_cov\n",
    "def eq_cov(x, x_prime, variance=1., lengthscale=1.):\n",
    "    \"\"\"Exponentiated quadratic covariance function.\"\"\"\n",
    "    diffx = x - x_prime\n",
    "    return variance*np.exp(-0.5*np.dot(diffx, diffx)/lengthscale**2)"
   ],
   "id": "d5fa8cf4-0ca6-493c-8ffe-4d885e77924d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = Kernel(function=eq_cov,\n",
    "                     name='Exponentiated Quadratic',\n",
    "                     shortname='eq',                     \n",
    "                     lengthscale=0.25)"
   ],
   "id": "4da95e12-73e1-42e7-8987-6461e678079b"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we sample from a multivariate normal density (a multivariate\n",
    "Gaussian), using the covariance function as the covariance matrix."
   ],
   "id": "86f134af-a0b7-4502-8d47-1cba7dde5081"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(10)\n",
    "import mlai.plot as plot"
   ],
   "id": "593c9638-6be4-4ec2-aa59-a9870d10e5d0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.rejection_samples(kernel=kernel, \n",
    "    diagrams='./gp')"
   ],
   "id": "9b8e4f88-3e25-4ff4-8746-f1142f7b6760"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import notutils as nu\n",
    "from ipywidgets import IntSlider"
   ],
   "id": "46936309-aefd-4519-9e4a-0c09828fe65d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nu.display_plots('gp_rejection_sample{sample:0>3}.png', \n",
    "                 directory='./gp', \n",
    "                 sample=IntSlider(1,1,5,1))"
   ],
   "id": "953867b5-2da9-4e0a-92fd-91adff6c94d7"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//gp/gp_rejection_sample003.png\" style=\"width:100%\">\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//gp/gp_rejection_sample004.png\" style=\"width:100%\">\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//gp/gp_rejection_sample005.png\" style=\"width:100%\">\n",
    "\n",
    "Figure: <i>One view of Bayesian inference is we have a machine for\n",
    "generating samples (the *prior*), and we discard all samples\n",
    "inconsistent with our data, leaving the samples of interest (the\n",
    "*posterior*). This is a rejection sampling view of Bayesian inference.\n",
    "The Gaussian process allows us to do this analytically by multiplying\n",
    "the *prior* by the *likelihood*.</i>"
   ],
   "id": "cf61abd2-7877-4cb5-a077-b67d85d29b53"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maxwell’s Demon\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_physics/includes/maxwells-demon-short.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_physics/includes/maxwells-demon-short.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//physics/maxwells-demon.svg\" class=\"\" width=\"100%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Maxwell’s demon opens and closes a door which allows fast\n",
    "particles to pass from left to right and slow particles to pass from\n",
    "right to left. This makes the left hand side colder than the right.</i>\n",
    "\n",
    "<canvas id=\"maxwell-canvas\" width=\"700\" height=\"500\" style=\"border:1px solid black;display:inline;text-align:left\">\n",
    "</canvas>\n",
    "\n",
    "Entropy:\n",
    "\n",
    "<output id=\"maxwell-entropy\">\n",
    "</output>\n",
    "\n",
    "<button id=\"maxwell-newball\" style=\"text-align:right\">\n",
    "\n",
    "New Ball\n",
    "\n",
    "</button>\n",
    "<button id=\"maxwell-pause\" style=\"text-align:right\">\n",
    "\n",
    "Pause\n",
    "\n",
    "</button>\n",
    "<button id=\"maxwell-skip\" style=\"text-align:right\">\n",
    "\n",
    "Skip 1000s\n",
    "\n",
    "</button>\n",
    "<button id=\"maxwell-histogram\" style=\"text-align:right\">\n",
    "\n",
    "Histogram\n",
    "\n",
    "</button>\n",
    "\n",
    "<script src=\"https://inverseprobability.com/talks/scripts//ballworld/maxwell.js\"></script>\n",
    "\n",
    "Figure: <i>Maxwell’s Demon. The demon decides balls are either cold\n",
    "(blue) or hot (red) according to their velocity. Balls are allowed to\n",
    "pass the green membrane from right to left only if they are cold, and\n",
    "from left to right, only if they are hot.</i>"
   ],
   "id": "86550cc0-0029-414e-8036-3f8563b68446"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "The probabilistic modelling community has evolved in an era where the\n",
    "assumption was that ambiguous conclusions are best shared with a\n",
    "(trained) professional through probabilities. Recent advances in\n",
    "generative AI offer the possibility of machines that have a better\n",
    "understanding of human subjective ambiguities and therefore machines\n",
    "that can summarise information in a way that can be interogated rather\n",
    "than just through a series of numbers.\n",
    "\n",
    "<!-- lecture 3 -->\n",
    "<center>\n",
    "\n",
    "A chance for us to acknowledge our ignorance and to rediscover\n",
    "interdisplinary science.\n",
    "\n",
    "</center>"
   ],
   "id": "9d838165-bbcc-440a-9650-a8c607cc2d39"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepFace\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_ml/includes/deep-face.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ml/includes/deep-face.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//deepface_neg.png\" style=\"width:100%\">\n",
    "\n",
    "Figure: <i>The DeepFace architecture (Taigman et al., 2014), visualized\n",
    "through colors to represent the functional mappings at each layer. There\n",
    "are 120 million parameters in the model.</i>\n",
    "\n",
    "The DeepFace architecture (Taigman et al., 2014) consists of layers that\n",
    "deal with *translation* invariances, known as convolutional layers.\n",
    "These layers are followed by three locally-connected layers and two\n",
    "fully-connected layers. Color illustrates feature maps produced at each\n",
    "layer. The neural network includes more than 120 million parameters,\n",
    "where more than 95% come from the local and fully connected layers."
   ],
   "id": "dc45fefe-797f-4486-ac4e-8f65951c4663"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning as Pinball\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_ml/includes/deep-learning-as-pinball.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ml/includes/deep-learning-as-pinball.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//576px-Early_Pinball.jpg\" style=\"width:50%\">\n",
    "\n",
    "Figure: <i>Deep learning models are composition of simple functions. We\n",
    "can think of a pinball machine as an analogy. Each layer of pins\n",
    "corresponds to one of the layers of functions in the model. Input data\n",
    "is represented by the location of the ball from left to right when it is\n",
    "dropped in from the top. Output class comes from the position of the\n",
    "ball as it leaves the pins at the bottom.</i>\n",
    "\n",
    "Sometimes deep learning models are described as being like the brain, or\n",
    "too complex to understand, but one analogy I find useful to help the\n",
    "gist of these models is to think of them as being similar to early pin\n",
    "ball machines.\n",
    "\n",
    "In a deep neural network, we input a number (or numbers), whereas in\n",
    "pinball, we input a ball.\n",
    "\n",
    "Think of the location of the ball on the left-right axis as a single\n",
    "number. Our simple pinball machine can only take one number at a time.\n",
    "As the ball falls through the machine, each layer of pins can be thought\n",
    "of as a different layer of ‘neurons’. Each layer acts to move the ball\n",
    "from left to right.\n",
    "\n",
    "In a pinball machine, when the ball gets to the bottom it might fall\n",
    "into a hole defining a score, in a neural network, that is equivalent to\n",
    "the decision: a classification of the input object.\n",
    "\n",
    "An image has more than one number associated with it, so it is like\n",
    "playing pinball in a *hyper-space*.\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//pinball001.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>At initialization, the pins, which represent the parameters\n",
    "of the function, aren’t in the right place to bring the balls to the\n",
    "correct decisions.</i>\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//pinball002.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>After learning the pins are now in the right place to bring\n",
    "the balls to the correct decisions.</i>\n",
    "\n",
    "Learning involves moving all the pins to be in the correct position, so\n",
    "that the ball ends up in the right place when it’s fallen through the\n",
    "machine. But moving all these pins in hyperspace can be difficult.\n",
    "\n",
    "In a hyper-space you have to put a lot of data through the machine for\n",
    "to explore the positions of all the pins. Even when you feed many\n",
    "millions of data points through the machine, there are likely to be\n",
    "regions in the hyper-space where no ball has passed. When future test\n",
    "data passes through the machine in a new route unusual things can\n",
    "happen.\n",
    "\n",
    "*Adversarial examples* exploit this high dimensional space. If you have\n",
    "access to the pinball machine, you can use gradient methods to find a\n",
    "position for the ball in the hyper space where the image looks like one\n",
    "thing, but will be classified as another.\n",
    "\n",
    "Probabilistic methods explore more of the space by considering a range\n",
    "of possible paths for the ball through the machine. This helps to make\n",
    "them more data efficient and gives some robustness to adversarial\n",
    "examples.\n",
    "\n",
    "<!--Connect supply chain as a \"challenge\" tot he abstraction of Schroedinger's bridge. Link to Optimal Transport (matching without the \"physics\"). Maxwell's demon.-->\n",
    "<!--Control ability paper with Mauricio and Simo??)-->\n",
    "<!-- Interfaces AI for Science -->\n",
    "<!--include{_ai/includes/interfaces-ai-for-science.md}-->\n",
    "<!--include{_gp/includes/what-is-a-gp.md} -->"
   ],
   "id": "54f447a9-5ca4-4c74-abd0-884c27d0a404"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Gaussian Processes\n",
    "\n",
    "-   *Deep Gaussian Processes and Variational Propagation of Uncertainty*\n",
    "    Damianou (2015)"
   ],
   "id": "1bf87cc7-526c-4a8a-8d92-ff47650b91ac"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure of Priors\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_gp/includes/mackay-bathwater.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_gp/includes/mackay-bathwater.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "Even in the early days of Gaussian processes in machine learning, it was\n",
    "understood that we were throwing something fundamental away. This is\n",
    "perhaps captured best by David MacKay in his 1997 NeurIPS tutorial on\n",
    "Gaussian processes, where he asked “Have we thrown out the baby with the\n",
    "bathwater?”. The quote below is from his summarization paper.\n",
    "\n",
    "> According to the hype of 1987, neural networks were meant to be\n",
    "> intelligent models which discovered features and patterns in data.\n",
    "> Gaussian processes in contrast are simply smoothing devices. How can\n",
    "> Gaussian processes possibly replace neural networks? What is going on?\n",
    ">\n",
    "> MacKay (n.d.)"
   ],
   "id": "30e0997f-2147-4a35-9eff-16e6524084ac"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Neural Network\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_deepnn/includes/deep-neural-network.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_deepnn/includes/deep-neural-network.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
   ],
   "id": "015dfa24-e2c9-4e45-ad8c-8ae6733e0ba1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install daft"
   ],
   "id": "28b8fcce-0fa9-4a19-85d8-a51aa9a2ecb5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "# Comment for google colab (no latex available)\n",
    "#matplotlib.rc('text', usetex=True)\n",
    "#matplotlib.rcParams['text.latex.preamble']=[r\"\\usepackage{amsmath}\"]"
   ],
   "id": "27ba1ea9-5635-4311-bf43-465e784d68da"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai.plot as plot"
   ],
   "id": "15edbf0b-ab05-4861-b893-a6470c97884f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot.deep_nn(diagrams='./deepgp/')"
   ],
   "id": "9863420d-8a8b-4786-acac-46c2063ba30d"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//deepgp/deep-nn2.svg\" class=\"\" width=\"70%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>A deep neural network. Input nodes are shown at the bottom.\n",
    "Each hidden layer is the result of applying an affine transformation to\n",
    "the previous layer and placing through an activation function.</i>\n",
    "\n",
    "Mathematically, each layer of a neural network is given through\n",
    "computing the activation function, $\\phi(\\cdot)$, contingent on the\n",
    "previous layer, or the inputs. In this way the activation functions, are\n",
    "composed to generate more complex interactions than would be possible\n",
    "with any single layer. $$\n",
    "\\begin{align*}\n",
    "    \\mathbf{ h}_{1} &= \\phi\\left(\\mathbf{W}_1 \\mathbf{ x}\\right)\\\\\n",
    "    \\mathbf{ h}_{2} &=  \\phi\\left(\\mathbf{W}_2\\mathbf{ h}_{1}\\right)\\\\\n",
    "    \\mathbf{ h}_{3} &= \\phi\\left(\\mathbf{W}_3 \\mathbf{ h}_{2}\\right)\\\\\n",
    "    f&= \\mathbf{ w}_4 ^\\top\\mathbf{ h}_{3}\n",
    "\\end{align*}\n",
    "$$"
   ],
   "id": "b19be1b4-902e-472a-9a78-ba4f06ab76eb"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_deepgp/includes/overfitting-low-rank.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_deepgp/includes/overfitting-low-rank.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "One potential problem is that as the number of nodes in two adjacent\n",
    "layers increases, the number of parameters in the affine transformation\n",
    "between layers, $\\mathbf{W}$, increases. If there are $k_{i-1}$ nodes in\n",
    "one layer, and $k_i$ nodes in the following, then that matrix contains\n",
    "$k_i k_{i-1}$ parameters, when we have layer widths in the 1000s that\n",
    "leads to millions of parameters.\n",
    "\n",
    "One proposed solution is known as *dropout* where only a sub-set of the\n",
    "neural network is trained at each iteration. An alternative solution\n",
    "would be to reparameterize $\\mathbf{W}$ with its *singular value\n",
    "decomposition*. $$\n",
    "  \\mathbf{W}= \\mathbf{U}\\boldsymbol{ \\Lambda}\\mathbf{V}^\\top\n",
    "  $$ or $$\n",
    "  \\mathbf{W}= \\mathbf{U}\\mathbf{V}^\\top\n",
    "  $$ where if $\\mathbf{W}\\in \\Re^{k_1\\times k_2}$ then\n",
    "$\\mathbf{U}\\in \\Re^{k_1\\times q}$ and $\\mathbf{V}\\in \\Re^{k_2\\times q}$,\n",
    "i.e. we have a low rank matrix factorization for the weights."
   ],
   "id": "dca07fdc-a211-4910-bef6-31e8ce942e94"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai.plot as plot"
   ],
   "id": "e127eb18-0d65-4238-a53d-e3e58b2282b3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.low_rank_approximation(diagrams='.')"
   ],
   "id": "13762287-1901-436a-a425-26fccbb7fb58"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//wisuvt.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Pictorial representation of the low rank form of the matrix\n",
    "$\\mathbf{W}$.</i>\n",
    "\n",
    "In practice there is evidence that deep models seek these low rank\n",
    "solutions where we expect better generalisation. See e.g. Arora et al.\n",
    "(2019);Jacot et al. (2021)."
   ],
   "id": "8afd3ded-1cfd-4572-ab9b-b5f71ad68464"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bottleneck Layers in Deep Neural Networks\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_deepgp/includes/deep-gp.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_deepgp/includes/deep-gp.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
   ],
   "id": "46c5f0dc-195e-4728-b33b-db874dabe4e3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai.plot as plot"
   ],
   "id": "604becf2-c82e-4022-907f-f071f6ae495c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.deep_nn_bottleneck(diagrams='./deepgp')"
   ],
   "id": "b4d4fcb3-3d70-4cbb-9f38-ede46145867d"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//deepgp/deep-nn-bottleneck2.svg\" class=\"\" width=\"70%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Inserting the bottleneck layers introduces a new set of\n",
    "variables.</i>\n",
    "\n",
    "Including the low rank decomposition of $\\mathbf{W}$ in the neural\n",
    "network, we obtain a new mathematical form. Effectively, we are adding\n",
    "additional *latent* layers, $\\mathbf{ z}$, in between each of the\n",
    "existing hidden layers. In a neural network these are sometimes known as\n",
    "*bottleneck* layers. The network can now be written mathematically as $$\n",
    "\\begin{align}\n",
    "  \\mathbf{ z}_{1} &= \\mathbf{V}^\\top_1 \\mathbf{ x}\\\\\n",
    "  \\mathbf{ h}_{1} &= \\phi\\left(\\mathbf{U}_1 \\mathbf{ z}_{1}\\right)\\\\\n",
    "  \\mathbf{ z}_{2} &= \\mathbf{V}^\\top_2 \\mathbf{ h}_{1}\\\\\n",
    "  \\mathbf{ h}_{2} &= \\phi\\left(\\mathbf{U}_2 \\mathbf{ z}_{2}\\right)\\\\\n",
    "  \\mathbf{ z}_{3} &= \\mathbf{V}^\\top_3 \\mathbf{ h}_{2}\\\\\n",
    "  \\mathbf{ h}_{3} &= \\phi\\left(\\mathbf{U}_3 \\mathbf{ z}_{3}\\right)\\\\\n",
    "  \\mathbf{ y}&= \\mathbf{ w}_4^\\top\\mathbf{ h}_{3}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "  \\mathbf{ z}_{1} &= \\mathbf{V}^\\top_1 \\mathbf{ x}\\\\\n",
    "  \\mathbf{ z}_{2} &= \\mathbf{V}^\\top_2 \\phi\\left(\\mathbf{U}_1 \\mathbf{ z}_{1}\\right)\\\\\n",
    "  \\mathbf{ z}_{3} &= \\mathbf{V}^\\top_3 \\phi\\left(\\mathbf{U}_2 \\mathbf{ z}_{2}\\right)\\\\\n",
    "  \\mathbf{ y}&= \\mathbf{ w}_4 ^\\top \\mathbf{ z}_{3}\n",
    "\\end{align}\n",
    "$$"
   ],
   "id": "329a4fd0-7992-47bf-a15c-8df385e0a0ff"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cascade of Gaussian Processes\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_deepgp/includes/cascade-of-gps.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_deepgp/includes/cascade-of-gps.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "Now if we replace each of these neural networks with a Gaussian process.\n",
    "This is equivalent to taking the limit as the width of each layer goes\n",
    "to infinity, while appropriately scaling down the outputs.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "  \\mathbf{ z}_{1} &= \\mathbf{ f}_1\\left(\\mathbf{ x}\\right)\\\\\n",
    "  \\mathbf{ z}_{2} &= \\mathbf{ f}_2\\left(\\mathbf{ z}_{1}\\right)\\\\\n",
    "  \\mathbf{ z}_{3} &= \\mathbf{ f}_3\\left(\\mathbf{ z}_{2}\\right)\\\\\n",
    "  \\mathbf{ y}&= \\mathbf{ f}_4\\left(\\mathbf{ z}_{3}\\right)\n",
    "\\end{align}\n",
    "$$"
   ],
   "id": "7d34a387-25e9-443a-b719-f410f97011a0"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_ml/includes/deep-learning-overview.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ml/includes/deep-learning-overview.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<!-- No slide titles in this context -->\n",
    "\n",
    "Mathematically, a deep Gaussian process can be seen as a composite\n",
    "*multivariate* function, $$\n",
    "  \\mathbf{g}(\\mathbf{ x})=\\mathbf{ f}_5(\\mathbf{ f}_4(\\mathbf{ f}_3(\\mathbf{ f}_2(\\mathbf{ f}_1(\\mathbf{ x}))))).\n",
    "  $$ Or if we view it from the probabilistic perspective we can see that\n",
    "a deep Gaussian process is specifying a factorization of the joint\n",
    "density, the standard deep model takes the form of a Markov chain."
   ],
   "id": "13eebe95-ca62-474d-85a8-14c70490018d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rc\n",
    "\n",
    "rc(\"font\", **{'family':'sans-serif','sans-serif':['Helvetica'],'size':30})\n",
    "rc(\"text\", usetex=True)"
   ],
   "id": "67dfa855-84ce-497d-ac90-66661556f3e2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgm = plot.horizontal_chain(depth=5)\n",
    "pgm.render().figure.savefig(\"./deepgp/deep-markov.svg\", transparent=True)"
   ],
   "id": "36a15b7c-43ce-4b8e-a49d-bbd9220cc8b3"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "  p(\\mathbf{ y}|\\mathbf{ x})= p(\\mathbf{ y}|\\mathbf{ f}_5)p(\\mathbf{ f}_5|\\mathbf{ f}_4)p(\\mathbf{ f}_4|\\mathbf{ f}_3)p(\\mathbf{ f}_3|\\mathbf{ f}_2)p(\\mathbf{ f}_2|\\mathbf{ f}_1)p(\\mathbf{ f}_1|\\mathbf{ x})\n",
    "  $$\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//deepgp/deep-markov.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Probabilistically the deep Gaussian process can be\n",
    "represented as a Markov chain. Indeed they can even be analyzed in this\n",
    "way (Dunlop et al., n.d.).</i>"
   ],
   "id": "9b541dc6-aa42-4287-8eff-e0e3c508a9e6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rc\n",
    "rc(\"font\", **{'family':'sans-serif','sans-serif':['Helvetica'], 'size':15})\n",
    "rc(\"text\", usetex=True)"
   ],
   "id": "109dc023-9437-421d-aec3-fccdefdea897"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgm = plot.vertical_chain(depth=5)\n",
    "pgm.render().figure.savefig(\"./deepgp/deep-markov-vertical.svg\", transparent=True)"
   ],
   "id": "69745b99-0ce4-4098-8acd-780089a8db9e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//deepgp/deep-markov-vertical.svg\" class=\"\" width=\"7%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>More usually deep probabilistic models are written vertically\n",
    "rather than horizontally as in the Markov chain.</i>"
   ],
   "id": "81fe8ff0-621c-4252-8267-fc2dcf7498a8"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Composition?\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_deepgp/includes/process-composition.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_deepgp/includes/process-composition.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "If the result of composing many functions together is simply another\n",
    "function, then why do we bother? The key point is that we can change the\n",
    "class of functions we are modeling by composing in this manner. A\n",
    "Gaussian process is specifying a prior over functions, and one with a\n",
    "number of elegant properties. For example, the derivative process (if it\n",
    "exists) of a Gaussian process is also Gaussian distributed. That makes\n",
    "it easy to assimilate, for example, derivative observations. But that\n",
    "also might raise some alarm bells. That implies that the *marginal\n",
    "derivative distribution* is also Gaussian distributed. If that’s the\n",
    "case, then it means that functions which occasionally exhibit very large\n",
    "derivatives are hard to model with a Gaussian process. For example, a\n",
    "function with jumps in.\n",
    "\n",
    "A one off discontinuity is easy to model with a Gaussian process, or\n",
    "even multiple discontinuities. They can be introduced in the mean\n",
    "function, or independence can be forced between two covariance functions\n",
    "that apply in different areas of the input space. But in these cases we\n",
    "will need to specify the number of discontinuities and where they occur.\n",
    "In otherwords we need to *parameterise* the discontinuities. If we do\n",
    "not know the number of discontinuities and don’t wish to specify where\n",
    "they occur, i.e. if we want a non-parametric representation of\n",
    "discontinuities, then the standard Gaussian process doesn’t help."
   ],
   "id": "3f38989f-84b7-4d49-923c-aec632a6ef72"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Process Composition\n",
    "\n",
    "The deep Gaussian process leads to *non-Gaussian* models, and\n",
    "non-Gaussian characteristics in the covariance function. In effect, what\n",
    "we are proposing is that we change the properties of the functions we\n",
    "are considering by *composing stochastic processes*. This is an approach\n",
    "to creating new stochastic processes from well known processes."
   ],
   "id": "ad868353-10c3-43ed-969f-fba356e16764"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import daft"
   ],
   "id": "e5363ee9-ae36-416e-b9e6-a857bdfbefca"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgm = plot.vertical_chain(depth=5, shape=[2, 7])\n",
    "pgm.add_node(daft.Node('y_2', r'$\\mathbf{y}_2$', 1.5, 3.5, observed=True))\n",
    "pgm.add_edge('f_2', 'y_2')\n",
    "pgm.render().figure.savefig(\"./deepgp/deep-markov-vertical-side.svg\", transparent=True)"
   ],
   "id": "864d501a-a579-438b-a6f0-7172fc3c48b2"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we are not constrained to the formalism of the chain. For\n",
    "example, we can easily add single nodes emerging from some point in the\n",
    "depth of the chain. This allows us to combine the benefits of the\n",
    "graphical modelling formalism, but with a powerful framework for\n",
    "relating one set of variables to another, that of Gaussian processes\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//deepgp/deep-markov-vertical-side.svg\" class=\"\" width=\"15%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>More generally we aren’t constrained by the Markov chain. We\n",
    "can design structures that respect our belief about the underlying\n",
    "conditional dependencies. Here we are adding a side note from the\n",
    "chain.</i>"
   ],
   "id": "e8c4434d-d081-4a99-97ba-042b92e98374"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difficulty for Probabilistic Approaches\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_dimred/includes/non-linear-difficulty.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_dimred/includes/non-linear-difficulty.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
   ],
   "id": "15c70319-4ccb-4ba3-9b7b-090b6b5427ec"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai.plot as plot"
   ],
   "id": "36c182ae-cdac-4879-908c-f466ef3f417c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.non_linear_difficulty_plot_3(diagrams='./dimred/')"
   ],
   "id": "c713fb4e-cb95-42c5-922c-00615ae27810"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The challenge for composition of probabilistic models is that you need\n",
    "to propagate a probability densities through non linear mappings. This\n",
    "allows you to create broader classes of probability density.\n",
    "Unfortunately it renders the resulting densities *intractable*.\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//dimred/nonlinear-mapping-3d-plot.svg\" class=\"\" width=\"60%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>A two dimensional grid mapped into three dimensions to form a\n",
    "two dimensional manifold.</i>"
   ],
   "id": "965563ef-1a31-4572-a02e-4d981ce2b069"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.non_linear_difficulty_plot_2(diagrams='./dimred/')"
   ],
   "id": "47bc510b-ad6b-4ef7-a2fb-568c8e9e91eb"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//dimred/nonlinear-mapping-2d-plot.svg\" class=\"\" width=\"60%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>A one dimensional line mapped into two dimensions by two\n",
    "separate independent functions. Each point can be mapped exactly through\n",
    "the mappings.</i>"
   ],
   "id": "91e079a5-1b8a-49e1-a0eb-8a8197f52959"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.non_linear_difficulty_plot_1(diagrams='./dimred')"
   ],
   "id": "693b2ffb-cf65-4dfe-ac81-609ad0ea4b4c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//dimred/gaussian-through-nonlinear.svg\" class=\"\" width=\"100%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>A Gaussian density over the input of a non linear function\n",
    "leads to a very non Gaussian output. Here the output is multimodal.</i>"
   ],
   "id": "eaa48cdb-3450-4165-aef1-3b578fdd7147"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Variational Approach Fails\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_gplvm/includes/variational-bayes-gplvm-long.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_gplvm/includes/variational-bayes-gplvm-long.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "-   Standard variational bound has the form: $$\n",
    "    \\mathcal{L}= \\left\\langle\\log p(\\mathbf{ y}|\\mathbf{Z})\\right\\rangle_{q(\\mathbf{Z})} + \\text{KL}\\left( q(\\mathbf{Z})\\,\\|\\,p(\\mathbf{Z}) \\right)\n",
    "    $$\n",
    "\n",
    "The standard variational approach would require the expectation of\n",
    "$\\log p(\\mathbf{ y}|\\mathbf{Z})$ under $q(\\mathbf{Z})$. $$\n",
    "  \\begin{align}\n",
    "  \\log p(\\mathbf{ y}|\\mathbf{Z}) = & -\\frac{1}{2}\\mathbf{ y}^\\top\\left(\\mathbf{K}_{\\mathbf{ f}, \\mathbf{ f}}+\\sigma^2\\mathbf{I}\\right)^{-1}\\mathbf{ y}\\\\ & -\\frac{1}{2}\\log \\det{\\mathbf{K}_{\\mathbf{ f}, \\mathbf{ f}}+\\sigma^2 \\mathbf{I}} -\\frac{n}{2}\\log 2\\pi\n",
    "  \\end{align}\n",
    "  $$ But this is extremely difficult to compute because\n",
    "$\\mathbf{K}_{\\mathbf{ f}, \\mathbf{ f}}$ is dependent on $\\mathbf{Z}$ and\n",
    "it appears in the inverse."
   ],
   "id": "d8d33a34-1c19-49ad-866d-38ac93f08c84"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Bayesian GP-LVM\n",
    "\n",
    "The alternative approach is to consider the collapsed variational bound\n",
    "(used for low rank (sparse is a misnomer) Gaussian process\n",
    "approximations. $$\n",
    "    p(\\mathbf{ y})\\geq \\prod_{i=1}^nc_i \\int \\mathcal{N}\\left(\\mathbf{ y}|\\left\\langle\\mathbf{ f}\\right\\rangle,\\sigma^2\\mathbf{I}\\right)p(\\mathbf{ u}) \\text{d}\\mathbf{ u}\n",
    "  $$ $$\n",
    "    p(\\mathbf{ y}|\\mathbf{Z})\\geq \\prod_{i=1}^nc_i \\int \\mathcal{N}\\left(\\mathbf{ y}|\\left\\langle\\mathbf{ f}\\right\\rangle_{p(\\mathbf{ f}|\\mathbf{ u}, \\mathbf{Z})},\\sigma^2\\mathbf{I}\\right)p(\\mathbf{ u}) \\text{d}\\mathbf{ u}\n",
    "  $$ $$\n",
    "      \\int p(\\mathbf{ y}|\\mathbf{Z})p(\\mathbf{Z}) \\text{d}\\mathbf{Z}\\geq \\int \\prod_{i=1}^nc_i \\mathcal{N}\\left(\\mathbf{ y}|\\left\\langle\\mathbf{ f}\\right\\rangle_{p(\\mathbf{ f}|\\mathbf{ u}, \\mathbf{Z})},\\sigma^2\\mathbf{I}\\right) p(\\mathbf{Z})\\text{d}\\mathbf{Z}p(\\mathbf{ u}) \\text{d}\\mathbf{ u}\n",
    "  $$\n",
    "\n",
    "To integrate across $\\mathbf{Z}$ we apply the lower bound to the inner\n",
    "integral. $$\n",
    "    \\begin{align}\n",
    "    \\int \\prod_{i=1}^nc_i \\mathcal{N}\\left(\\mathbf{ y}|\\left\\langle\\mathbf{ f}\\right\\rangle_{p(\\mathbf{ f}|\\mathbf{ u}, \\mathbf{Z})},\\sigma^2\\mathbf{I}\\right) p(\\mathbf{Z})\\text{d}\\mathbf{Z}\\geq & \\left\\langle\\sum_{i=1}^n\\log  c_i\\right\\rangle_{q(\\mathbf{Z})}\\\\ & +\\left\\langle\\log\\mathcal{N}\\left(\\mathbf{ y}|\\left\\langle\\mathbf{ f}\\right\\rangle_{p(\\mathbf{ f}|\\mathbf{ u}, \\mathbf{Z})},\\sigma^2\\mathbf{I}\\right)\\right\\rangle_{q(\\mathbf{Z})}\\\\& + \\text{KL}\\left( q(\\mathbf{Z})\\,\\|\\,p(\\mathbf{Z}) \\right)    \n",
    "    \\end{align}\n",
    "  $$ \\* Which is analytically tractable for Gaussian $q(\\mathbf{Z})$ and\n",
    "some covariance functions.\n",
    "\n",
    "-   Need expectations under $q(\\mathbf{Z})$ of: $$\n",
    "    \\log c_i = \\frac{1}{2\\sigma^2} \\left[k_{i, i} - \\mathbf{ k}_{i, \\mathbf{ u}}^\\top \\mathbf{K}_{\\mathbf{ u}, \\mathbf{ u}}^{-1} \\mathbf{ k}_{i, \\mathbf{ u}}\\right]\n",
    "    $$ and $$\n",
    "    \\log \\mathcal{N}\\left(\\mathbf{ y}|\\left\\langle\\mathbf{ f}\\right\\rangle_{p(\\mathbf{ f}|\\mathbf{ u},\\mathbf{Y})},\\sigma^2\\mathbf{I}\\right) = -\\frac{1}{2}\\log 2\\pi\\sigma^2 - \\frac{1}{2\\sigma^2}\\left(y_i - \\mathbf{K}_{\\mathbf{ f}, \\mathbf{ u}}\\mathbf{K}_{\\mathbf{ u},\\mathbf{ u}}^{-1}\\mathbf{ u}\\right)^2\n",
    "    $$\n",
    "\n",
    "-   This requires the expectations $$\n",
    "    \\left\\langle\\mathbf{K}_{\\mathbf{ f},\\mathbf{ u}}\\right\\rangle_{q(\\mathbf{Z})}\n",
    "    $$ and $$\n",
    "    \\left\\langle\\mathbf{K}_{\\mathbf{ f},\\mathbf{ u}}\\mathbf{K}_{\\mathbf{ u},\\mathbf{ u}}^{-1}\\mathbf{K}_{\\mathbf{ u},\\mathbf{ f}}\\right\\rangle_{q(\\mathbf{Z})}\n",
    "    $$ which can be computed analytically for some covariance functions\n",
    "    (Damianou et al., 2016) or through sampling (Damianou, 2015;\n",
    "    Salimbeni and Deisenroth, 2017).\n",
    "\n",
    "Variational approximations aren’t the only approach to approximate\n",
    "inference. The original work on deep Gaussian processes made use of MAP\n",
    "approximations (Lawrence and Moore, 2007), which couldn’t propagate the\n",
    "uncertainty through the model at the data points but sustain uncertainty\n",
    "elsewhere. Since the variational approximation was proposed researchers\n",
    "have also considered sampling approaches (Havasi et al., 2018) and\n",
    "expectation propagation (Bui et al., 2016).\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//deepgp/neural-network-uncertainty.png\" style=\"width:90%\">\n",
    "\n",
    "Figure: <i>Even the latest work on Bayesian neural networks has severe\n",
    "problems handling uncertainty. In this example, (Izmailov et al., 2019),\n",
    "methods even fail to interpolate through the data correctly or provide\n",
    "well calibrated error bars in regions where data is observed.</i>\n",
    "\n",
    "The argument in the deep learning revolution is that deep architectures\n",
    "allow us to develop an abstraction of the feature set through model\n",
    "composition. Composing Gaussian processes is analytically intractable.\n",
    "To form deep Gaussian processes we use a variational approach to stack\n",
    "the models."
   ],
   "id": "c532ec88-ecd7-4b2d-abeb-671818e58c58"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked PCA\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_deepgp/includes/stacked-pca.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_deepgp/includes/stacked-pca.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
   ],
   "id": "fc274c22-dd2c-4232-a2c7-9dd15d05f567"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai.plot as plot"
   ],
   "id": "5f340823-b4cc-44ea-96a2-71cb11ed09d2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.stack_gp_sample(kernel=GPy.kern.Linear,\n",
    "                     diagrams=\"./deepgp\")"
   ],
   "id": "9a9f6ef1-71ac-4547-8aad-4af00300b0a8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import notutils as nu"
   ],
   "id": "38f73bec-0bc3-4e5b-ad0f-e3240ea3d602"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import notutils as nu"
   ],
   "id": "7f2045d9-c689-48ad-b671-05947b8b1dc0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nu.display_plots('stack-gp-sample-Linear-{sample:0>1}.svg', \n",
    "                            directory='./deepgp', sample=(0,4))"
   ],
   "id": "68876139-2849-46d3-921c-e759b6f3e331"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//stack-pca-sample-4.svg\" class=\"\" width=\"20%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Composition of linear functions just leads to a new linear\n",
    "function. Here you see the result of multiple affine transformations\n",
    "applied to a square in two dimensions.</i>\n",
    "\n",
    "Stacking a series of linear functions simply leads to a new linear\n",
    "function. The use of multiple linear function merely changes the\n",
    "covariance of the resulting Gaussian. If $$\n",
    "\\mathbf{Z}\\sim \\mathcal{N}\\left(\\mathbf{0},\\mathbf{I}\\right)\n",
    "$$ and the $i$th hidden layer is a multivariate linear transformation\n",
    "defined by $\\mathbf{W}_i$, $$\n",
    "\\mathbf{Y}= \\mathbf{Z}\\mathbf{W}_1 \\mathbf{W}_2 \\dots \\mathbf{W}_\\ell\n",
    "$$ then the rules of multivariate Gaussians tell us that $$\n",
    "\\mathbf{Y}\\sim \\mathcal{N}\\left(\\mathbf{0},\\mathbf{W}_\\ell\\dots \\mathbf{W}_1 \\mathbf{W}^\\top_1 \\dots \\mathbf{W}^\\top_\\ell\\right).\n",
    "$$ So the model can be replaced by one where we set\n",
    "$\\mathbf{V}= \\mathbf{W}_\\ell\\dots \\mathbf{W}_2 \\mathbf{W}_1$. So is such\n",
    "a model trivial? The answer is that it depends. There are two cases in\n",
    "which such a model remaisn interesting. Firstly, if we make intermediate\n",
    "observations stemming from the chain. So, for example, if we decide\n",
    "that, $$\n",
    "\\mathbf{Z}_i = \\mathbf{W}_i \\mathbf{Z}_{i-1}\n",
    "$$ and set\n",
    "$\\mathbf{Z}_{0} = \\mathbf{X}\\sim \\mathcal{N}\\left(\\mathbf{0},\\mathbf{I}\\right)$,\n",
    "then the matrices $\\mathbf{W}$ inter-relate a series of jointly Gaussian\n",
    "observations in an interesting way, stacking the full data matrix to\n",
    "give $$\n",
    "\\mathbf{Z}= \\begin{bmatrix}\n",
    "\\mathbf{Z}_0 \\\\\n",
    "\\mathbf{Z}_1 \\\\\n",
    "\\vdots \\\\\n",
    "\\mathbf{Z}_\\ell\n",
    "\\end{bmatrix}\n",
    "$$ we can obtain\n",
    "$$\\mathbf{Z}\\sim \\mathcal{N}\\left(\\mathbf{0},\\begin{bmatrix}\n",
    "\\mathbf{I}& \\mathbf{W}^\\top_1 & \\mathbf{W}_1^\\top\\mathbf{W}_2^\\top & \\dots & \\mathbf{V}^\\top \\\\\n",
    "\\mathbf{W}_1 & \\mathbf{W}_1 \\mathbf{W}_1^\\top & \\mathbf{W}_1 \\mathbf{W}_1^\\top \\mathbf{W}_2^\\top & \\dots & \\mathbf{W}_1 \\mathbf{V}^\\top \\\\\n",
    "\\mathbf{W}_2 \\mathbf{W}_1 & \\mathbf{W}_2 \\mathbf{W}_1 \\mathbf{W}_1^\\top & \\mathbf{W}_2 \\mathbf{W}_1 \\mathbf{W}_1^\\top \\mathbf{W}_2^\\top & \\dots & \\mathbf{W}_2 \\mathbf{W}_1 \\mathbf{V}^\\top \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "\\mathbf{V}& \\mathbf{V}\\mathbf{W}_1^\\top  & \\mathbf{V}\\mathbf{W}_1^\\top \\mathbf{W}_2^\\top& \\dots & \\mathbf{V}\\mathbf{V}^\\top\n",
    "\\end{bmatrix}\\right)$$ which is a highly structured Gaussian covariance\n",
    "with hierarchical dependencies between the variables $\\mathbf{Z}_i$."
   ],
   "id": "702eabc5-4cd7-4406-b85f-f2fc9c9dae1e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked GP\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_deepgp/includes/stacked-gp.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_deepgp/includes/stacked-gp.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
   ],
   "id": "e6277a4c-7abd-4ea5-acac-3bfa6e457894"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.stack_gp_sample(kernel=GPy.kern.RBF,\n",
    "                     diagrams=\"./deepgp\")"
   ],
   "id": "6490c0ee-c920-468a-8ac6-f6e8233424c6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import notutils as nu"
   ],
   "id": "b4f9ac95-e739-4dfa-9f64-b659aa24a8a9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nu.display_plots('stack-gp-sample-RBF-{sample:0>1}.svg', \n",
    "                            directory='./deepgp', sample=(0,4))"
   ],
   "id": "c170153a-fe82-4878-94bc-338e8e853242"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//stack-gp-sample-4.svg\" class=\"\" width=\"20%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Stacking Gaussian process models leads to non linear mappings\n",
    "at each stage. Here we are mapping from two dimensions to two dimensions\n",
    "in each layer.</i>\n",
    "\n",
    "Note that once the box has folded over on itself, it cannot be unfolded.\n",
    "So a feature that is generated near the top of the model cannot be\n",
    "removed further down the model.\n",
    "\n",
    "This folding over effect happens in low dimensions. In higher dimensions\n",
    "it is less common.\n",
    "\n",
    "Observation of this effect at a talk in Cambridge was one of the things\n",
    "that caused David Duvenaud (and collaborators) to consider the behavior\n",
    "of deeper Gaussian process models (Duvenaud et al., 2014).\n",
    "\n",
    "Such folding over in the latent spaces necessarily forces the density to\n",
    "be non-Gaussian. Indeed, since folding-over is avoided as we increase\n",
    "the dimensionality of the latent spaces, such processes become more\n",
    "Gaussian. If we take the limit of the latent space dimensionality as it\n",
    "tends to infinity, the entire deep Gaussian process returns to a\n",
    "standard Gaussian process, with a covariance function given as a deep\n",
    "kernel (such as those described by Cho and Saul (2009)).\n",
    "\n",
    "Further analysis of these deep networks has been conducted by Dunlop et\n",
    "al. (n.d.), who use analysis of the deep network’s stationary density\n",
    "(treating it as a Markov chain across layers), to explore the nature of\n",
    "the implied process prior for a deep GP.\n",
    "\n",
    "Both of these works, however, make constraining assumptions on the form\n",
    "of the Gaussian process prior at each layer (e.g. same covariance at\n",
    "each layer). In practice, the form of this covariance can be learnt and\n",
    "the densities described by the deep GP are more general than those\n",
    "mentioned in either of these papers."
   ],
   "id": "3822a4e1-7c49-401d-8a44-bc55cae8a28c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked GPs (video by David Duvenaud)\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_deepgp/includes/deep-pathologies.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_deepgp/includes/deep-pathologies.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
   ],
   "id": "47f9b1ef-d797-47c8-a35e-24123bdb9e34"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.lib.display import YouTubeVideo\n",
    "YouTubeVideo('XhIvygQYFFQ')"
   ],
   "id": "2d456a8b-beb3-4e46-b21d-1d9d3e8ccb4f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure: <i>Visualization of mapping of a two dimensional space through a\n",
    "deep Gaussian process.</i>\n",
    "\n",
    "David Duvenaud also created a YouTube video to help visualize what\n",
    "happens as you drop through the layers of a deep GP."
   ],
   "id": "b9caad4c-3073-4376-9cf6-3f0959fc29c7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install gpy"
   ],
   "id": "c3204130-2451-4ce8-95dd-2bf61759d027"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPy: A Gaussian Process Framework in Python\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_software/includes/gpy-software.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_software/includes/gpy-software.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "Gaussian processes are a flexible tool for non-parametric analysis with\n",
    "uncertainty. The GPy software was started in Sheffield to provide a easy\n",
    "to use interface to GPs. One which allowed the user to focus on the\n",
    "modelling rather than the mathematics.\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//gp/gpy.png\" style=\"width:70%\">\n",
    "\n",
    "Figure: <i>GPy is a BSD licensed software code base for implementing\n",
    "Gaussian process models in Python. It is designed for teaching and\n",
    "modelling. We welcome contributions which can be made through the GitHub\n",
    "repository <https://github.com/SheffieldML/GPy></i>\n",
    "\n",
    "GPy is a BSD licensed software code base for implementing Gaussian\n",
    "process models in python. This allows GPs to be combined with a wide\n",
    "variety of software libraries.\n",
    "\n",
    "The software itself is available on\n",
    "[GitHub](https://github.com/SheffieldML/GPy) and the team welcomes\n",
    "contributions.\n",
    "\n",
    "The aim for GPy is to be a probabilistic-style programming language,\n",
    "i.e., you specify the model rather than the algorithm. As well as a\n",
    "large range of covariance functions the software allows for non-Gaussian\n",
    "likelihoods, multivariate outputs, dimensionality reduction and\n",
    "approximations for larger data sets.\n",
    "\n",
    "The documentation for GPy can be found\n",
    "[here](https://gpy.readthedocs.io/en/latest/).\n",
    "\n",
    "This notebook depends on PyDeepGP. This library can be installed via\n",
    "pip."
   ],
   "id": "8d5061c7-ff20-4d78-9a6f-e033b8535934"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade git+https://github.com/SheffieldML/PyDeepGP.git"
   ],
   "id": "55f1399c-7b88-4ef1-b0ed-c5ff2a5af3b1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install mlai"
   ],
   "id": "764f53f3-c83a-4f11-921b-2c7c61a24012"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Late bind setup methods to DeepGP object\n",
    "from mlai.deepgp_tutorial import initialize\n",
    "from mlai.deepgp_tutorial import staged_optimize\n",
    "from mlai.deepgp_tutorial import posterior_sample\n",
    "from mlai.deepgp_tutorial import visualize\n",
    "from mlai.deepgp_tutorial import visualize_pinball\n",
    "\n",
    "import deepgp\n",
    "deepgp.DeepGP.initialize=initialize\n",
    "deepgp.DeepGP.staged_optimize=staged_optimize\n",
    "deepgp.DeepGP.posterior_sample=posterior_sample\n",
    "deepgp.DeepGP.visualize=visualize\n",
    "deepgp.DeepGP.visualize_pinball=visualize_pinball"
   ],
   "id": "c0a276db-d321-4163-b9a4-f21d70d8cec5"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Olympic Marathon Data\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_datasets/includes/olympic-marathon-data.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_datasets/includes/olympic-marathon-data.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td width=\"70%\">\n",
    "\n",
    "-   Gold medal times for Olympic Marathon since 1896.\n",
    "-   Marathons before 1924 didn’t have a standardized distance.\n",
    "-   Present results using pace per km.\n",
    "-   In 1904 Marathon was badly organized leading to very slow times.\n",
    "\n",
    "</td>\n",
    "<td width=\"30%\">\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//Stephen_Kiprotich.jpg\" style=\"width:100%\">\n",
    "<small>Image from Wikimedia Commons <http://bit.ly/16kMKHQ></small>\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "The first thing we will do is load a standard data set for regression\n",
    "modelling. The data consists of the pace of Olympic Gold Medal Marathon\n",
    "winners for the Olympics from 1896 to present. Let’s load in the data\n",
    "and plot."
   ],
   "id": "7f83b247-68a4-47fb-ba91-ca6ec2fd8e91"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pods"
   ],
   "id": "1e949fdc-d102-4a91-beb8-484894c3b48e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pods"
   ],
   "id": "ba424244-90e6-4761-8209-5df8074e064a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pods.datasets.olympic_marathon_men()\n",
    "x = data['X']\n",
    "y = data['Y']\n",
    "\n",
    "offset = y.mean()\n",
    "scale = np.sqrt(y.var())\n",
    "yhat = (y - offset)/scale"
   ],
   "id": "04effd81-7256-42f4-b143-e0a221f19592"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mlai.plot as plot\n",
    "import mlai"
   ],
   "id": "6f1d3084-380d-408a-9aa6-734880ad8632"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xlim = (1875,2030)\n",
    "ylim = (2.5, 6.5)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=plot.big_wide_figsize)\n",
    "_ = ax.plot(x, y, 'r.',markersize=10)\n",
    "ax.set_xlabel('year', fontsize=20)\n",
    "ax.set_ylabel('pace min/km', fontsize=20)\n",
    "ax.set_xlim(xlim)\n",
    "ax.set_ylim(ylim)\n",
    "\n",
    "mlai.write_figure(filename='olympic-marathon.svg', \n",
    "                  directory='./datasets')"
   ],
   "id": "54541415-e421-4f77-9c30-121d4b53fcaa"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//datasets/olympic-marathon.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Olympic marathon pace times since 1896.</i>\n",
    "\n",
    "Things to notice about the data include the outlier in 1904, in that\n",
    "year the Olympics was in St Louis, USA. Organizational problems and\n",
    "challenges with dust kicked up by the cars following the race meant that\n",
    "participants got lost, and only very few participants completed. More\n",
    "recent years see more consistently quick marathons."
   ],
   "id": "29b368c3-1860-4ec8-bcb1-af0c405e600f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alan Turing\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_ml/includes/alan-turing-marathon.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ml/includes/alan-turing-marathon.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td width=\"50%\">\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//turing-times.gif\" style=\"width:100%\">\n",
    "\n",
    "</td>\n",
    "<td width=\"50%\">\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//turing-run.jpg\" style=\"width:50%\">\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Figure: <i>Alan Turing, in 1946 he was only 11 minutes slower than the\n",
    "winner of the 1948 games. Would he have won a hypothetical games held in\n",
    "1946? Source:\n",
    "<a href=\"http://www.turing.org.uk/scrapbook/run.html\" target=\"_blank\">Alan\n",
    "Turing Internet Scrapbook</a>.</i>\n",
    "\n",
    "If we had to summarise the objectives of machine learning in one word, a\n",
    "very good candidate for that word would be *generalization*. What is\n",
    "generalization? From a human perspective it might be summarised as the\n",
    "ability to take lessons learned in one domain and apply them to another\n",
    "domain. If we accept the definition given in the first session for\n",
    "machine learning, $$\n",
    "\\text{data} + \\text{model} \\stackrel{\\text{compute}}{\\rightarrow} \\text{prediction}\n",
    "$$ then we see that without a model we can’t generalise: we only have\n",
    "data. Data is fine for answering very specific questions, like “Who won\n",
    "the Olympic Marathon in 2012?”, because we have that answer stored,\n",
    "however, we are not given the answer to many other questions. For\n",
    "example, Alan Turing was a formidable marathon runner, in 1946 he ran a\n",
    "time 2 hours 46 minutes (just under four minutes per kilometer, faster\n",
    "than I and most of the other [Endcliffe Park\n",
    "Run](http://www.parkrun.org.uk/sheffieldhallam/) runners can do 5 km).\n",
    "What is the probability he would have won an Olympics if one had been\n",
    "held in 1946?\n",
    "\n",
    "To answer this question we need to generalize, but before we formalize\n",
    "the concept of generalization let’s introduce some formal representation\n",
    "of what it means to generalize in machine learning."
   ],
   "id": "a80f10b0-0d20-485d-b76a-165fb3b922ee"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Process Fit\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_gp/includes/olympic-marathon-gp.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_gp/includes/olympic-marathon-gp.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "Our first objective will be to perform a Gaussian process fit to the\n",
    "data, we’ll do this using the [GPy\n",
    "software](https://github.com/SheffieldML/GPy)."
   ],
   "id": "55c584b3-1e3c-482b-8ea3-4cf6d5d9f69d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPy"
   ],
   "id": "cd4c73be-909a-4692-b548-c3f9064ca584"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_full = GPy.models.GPRegression(x,yhat)\n",
    "_ = m_full.optimize() # Optimize parameters of covariance function"
   ],
   "id": "5919d411-e35b-4751-8503-e055e67f8d41"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first command sets up the model, then `m_full.optimize()` optimizes\n",
    "the parameters of the covariance function and the noise level of the\n",
    "model. Once the fit is complete, we’ll try creating some test points,\n",
    "and computing the output of the GP model in terms of the mean and\n",
    "standard deviation of the posterior functions between 1870 and 2030. We\n",
    "plot the mean function and the standard deviation at 200 locations. We\n",
    "can obtain the predictions using `y_mean, y_var = m_full.predict(xt)`"
   ],
   "id": "823af1c4-a4bb-464f-854b-121ee6a41c96"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = np.linspace(1870,2030,200)[:,np.newaxis]\n",
    "yt_mean, yt_var = m_full.predict(xt)\n",
    "yt_sd=np.sqrt(yt_var)"
   ],
   "id": "456605f2-e96e-43a4-b219-e87c055c4401"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plot the results using the helper function in `mlai.plot`."
   ],
   "id": "2bc50342-cb77-4b83-9f8b-9935d847d7f4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mlai.plot as plot\n",
    "import mlai"
   ],
   "id": "6c2386ff-b68c-43c7-a494-07224b6c4981"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=plot.big_wide_figsize)\n",
    "plot.model_output(m_full, scale=scale, offset=offset, ax=ax, xlabel=\"year\", ylabel=\"pace min/km\", fontsize=20, portion=0.2)\n",
    "ax.set_xlim(xlim)\n",
    "ax.set_ylim(ylim)\n",
    "mlai.write_figure(figure=fig,\n",
    "                  filename=\"olympic-marathon-gp.svg\", \n",
    "                  directory = \"./gp\",\n",
    "                  transparent=True, frameon=True)"
   ],
   "id": "605f9bce-ecf1-494f-9301-7bf95ce71d90"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//gp/olympic-marathon-gp.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Gaussian process fit to the Olympic Marathon data. The error\n",
    "bars are too large, perhaps due to the outlier from 1904.</i>"
   ],
   "id": "7d40cce1-c27a-4f82-906c-b3c492517b71"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Quality\n",
    "\n",
    "In the fit we see that the error bars (coming mainly from the noise\n",
    "variance) are quite large. This is likely due to the outlier point in\n",
    "1904, ignoring that point we can see that a tighter fit is obtained. To\n",
    "see this make a version of the model, `m_clean`, where that point is\n",
    "removed."
   ],
   "id": "b5fe392b-2259-466b-8977-a8bd146f1973"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_clean=np.vstack((x[0:2, :], x[3:, :]))\n",
    "y_clean=np.vstack((yhat[0:2, :], yhat[3:, :]))\n",
    "\n",
    "m_clean = GPy.models.GPRegression(x_clean,y_clean)\n",
    "_ = m_clean.optimize()"
   ],
   "id": "8e92f492-0623-4fdb-bbe4-06b9f9735ab5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mlai.plot as plot\n",
    "import mlai"
   ],
   "id": "3ed3bd0d-7485-46f4-86c3-80fe6da58dcb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=plot.big_wide_figsize)\n",
    "plot.model_output(m_clean, scale=scale, offset=offset, ax=ax, xlabel='year', ylabel='pace min/km', fontsize=20, portion=0.2)\n",
    "ax.set_xlim(xlim)\n",
    "ax.set_ylim(ylim)\n",
    "mlai.write_figure(figure=fig,\n",
    "                  filename='./gp/olympic-marathon-gp.svg', \n",
    "                  transparent=True, frameon=True)"
   ],
   "id": "431f8e35-9a83-44b1-8be9-7b3aa2b8f62c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep GP Fit\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_deepgp/includes/olympic-marathon-deep-gp.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_deepgp/includes/olympic-marathon-deep-gp.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "Let’s see if a deep Gaussian process can help here. We will construct a\n",
    "deep Gaussian process with one hidden layer (i.e. one Gaussian process\n",
    "feeding into another).\n",
    "\n",
    "Build a Deep GP with an additional hidden layer (one dimensional) to fit\n",
    "the model."
   ],
   "id": "a2b56571-4f7f-4659-a0d7-b73b18d29baa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPy\n",
    "import deepgp"
   ],
   "id": "935754fe-4276-408e-aaf4-307050d6f591"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = 1\n",
    "m = deepgp.DeepGP([y.shape[1],hidden,x.shape[1]],Y=yhat, X=x, inits=['PCA','PCA'], \n",
    "                  kernels=[GPy.kern.RBF(hidden,ARD=True),\n",
    "                           GPy.kern.RBF(x.shape[1],ARD=True)], # the kernels for each layer\n",
    "                  num_inducing=50, back_constraint=False)"
   ],
   "id": "96054e45-3e42-42cc-9bc7-d99014d3419a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the initalization\n",
    "m.initialize()"
   ],
   "id": "ddb88c31-1fe7-4c76-a64f-876c99f35040"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now optimize the model."
   ],
   "id": "b1c919cd-381d-414c-9f12-1ac518a35586"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in m.layers:\n",
    "    layer.likelihood.variance.constrain_positive(warning=False)\n",
    "m.optimize(messages=True,max_iters=10000)"
   ],
   "id": "5b09c460-1229-4d3f-9018-a14b9219d555"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.staged_optimize(messages=(True,True,True))"
   ],
   "id": "22e3b618-4835-4dbb-b82e-4dde38e88e8f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mlai.plot as plot\n",
    "import mlai"
   ],
   "id": "b245214a-7fd4-444c-b6e6-03e16ca9cfaf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=plot.big_wide_figsize)\n",
    "plot.model_output(m, scale=scale, offset=offset, ax=ax, xlabel='year', ylabel='pace min/km', \n",
    "          fontsize=20, portion=0.2)\n",
    "ax.set_xlim(xlim)\n",
    "\n",
    "ax.set_ylim(ylim)\n",
    "mlai.write_figure(figure=fig, filename='./deepgp/olympic-marathon-deep-gp.svg', \n",
    "                transparent=True, frameon=True)"
   ],
   "id": "d6a9ace3-b59f-45a8-99a5-620d0440b9fa"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Olympic Marathon Data Deep GP\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//deepgp/olympic-marathon-deep-gp.svg\" class=\"\" width=\"100%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Deep GP fit to the Olympic marathon data. Error bars now\n",
    "change as the prediction evolves.</i>"
   ],
   "id": "fa495c94-5bdb-4851-9d13-1110eee91d53"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=plot.big_wide_figsize)\n",
    "plot.model_sample(m, scale=scale, offset=offset, samps=10, ax=ax, \n",
    "                  xlabel='year', ylabel='pace min/km', portion = 0.225)\n",
    "ax.set_xlim(xlim)\n",
    "ax.set_ylim(ylim)\n",
    "mlai.write_figure(figure=fig, filename='./deepgp/olympic-marathon-deep-gp-samples.svg', \n",
    "                  transparent=True, frameon=True)"
   ],
   "id": "faea5f27-ab01-442a-90c3-fcaf25a9ea73"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Olympic Marathon Data Deep GP\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//deepgp/olympic-marathon-deep-gp-samples.svg\" class=\"\" width=\"\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Point samples run through the deep Gaussian process show the\n",
    "distribution of output locations.</i>"
   ],
   "id": "ac910e71-2330-4eab-88bc-9f5a1157ca6c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitted GP for each layer\n",
    "\n",
    "Now we explore the GPs the model has used to fit each layer. First of\n",
    "all, we look at the hidden layer."
   ],
   "id": "602a8721-fbdb-436f-b930-56bd92984045"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.visualize(scale=scale, offset=offset, xlabel='year',\n",
    "            ylabel='pace min/km',xlim=xlim, ylim=ylim,\n",
    "            dataset='olympic-marathon',\n",
    "            diagrams='./deepgp')"
   ],
   "id": "05f3f83d-c77a-4d4c-9441-a7c05908a969"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import notutils as nu"
   ],
   "id": "6d1541e4-627f-42ca-9ee3-cfaa73aa771c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nu.display_plots('olympic-marathon-deep-gp-layer-{sample:0>1}.svg', \n",
    "                            './deepgp', sample=(0,1))"
   ],
   "id": "2c88b1b9-a1b2-4ee2-b4c9-525ad72d6d42"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//deepgp/olympic-marathon-deep-gp-layer-0.svg\" class=\"\" width=\"\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>The mapping from input to the latent layer is broadly, with\n",
    "some flattening as time goes on. Variance is high across the input\n",
    "range.</i>\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//deepgp/olympic-marathon-deep-gp-layer-1.svg\" class=\"\" width=\"\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>The mapping from the latent layer to the output layer.</i>"
   ],
   "id": "32760b14-1e58-43e3-a995-2449c1675776"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=plot.big_wide_figsize)\n",
    "m.visualize_pinball(ax=ax, scale=scale, offset=offset, points=30, portion=0.1,\n",
    "                    xlabel='year', ylabel='pace km/min', vertical=True)\n",
    "mlai.write_figure(figure=fig, filename='./deepgp/olympic-marathon-deep-gp-pinball.svg', \n",
    "                  transparent=True, frameon=True)"
   ],
   "id": "8eb18f36-e567-47c6-b45f-f1477d597229"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Olympic Marathon Pinball Plot\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//deepgp/olympic-marathon-deep-gp-pinball.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>A pinball plot shows the movement of the ‘ball’ as it passes\n",
    "through each layer of the Gaussian processes. Mean directions of\n",
    "movement are shown by lines. Shading gives one standard deviation of\n",
    "movement position. At each layer, the uncertainty is reset. The overal\n",
    "uncertainty is the cumulative uncertainty from all the layers. There is\n",
    "some grouping of later points towards the right in the first layer,\n",
    "which also injects a large amount of uncertainty. Due to flattening of\n",
    "the curve in the second layer towards the right the uncertainty is\n",
    "reduced in final output.</i>\n",
    "\n",
    "The pinball plot shows the flow of any input ball through the deep\n",
    "Gaussian process. In a pinball plot a series of vertical parallel lines\n",
    "would indicate a purely linear function. For the olypmic marathon data\n",
    "we can see the first layer begins to shift from input towards the right.\n",
    "Note it also does so with some uncertainty (indicated by the shaded\n",
    "backgrounds). The second layer has less uncertainty, but bunches the\n",
    "inputs more strongly to the right. This input layer of uncertainty,\n",
    "followed by a layer that pushes inputs to the right is what gives the\n",
    "heteroschedastic noise."
   ],
   "id": "35a3fd0d-c8bd-4c92-9a4e-e2adf5ba27e8"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gene Expression Example\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_gp/includes/della-gatta-gene-gp.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_gp/includes/della-gatta-gene-gp.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "We now consider an example in gene expression. Gene expression is the\n",
    "measurement of mRNA levels expressed in cells. These mRNA levels show\n",
    "which genes are ‘switched on’ and producing data. In the example we will\n",
    "use a Gaussian process to determine whether a given gene is active, or\n",
    "we are merely observing a noise response."
   ],
   "id": "08d8a7c4-1463-4edf-96da-9bc853f0b2b5"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Della Gatta Gene Data\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_datasets/includes/della-gatta-gene-data.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_datasets/includes/della-gatta-gene-data.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "-   Given given expression levels in the form of a time series from\n",
    "    Della Gatta et al. (2008)."
   ],
   "id": "99b07583-ed97-4956-9643-eb2747fb6a74"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pods"
   ],
   "id": "ef185a74-6dd1-4d37-bd41-0ca895188fac"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pods.datasets.della_gatta_TRP63_gene_expression(data_set='della_gatta',gene_number=937)\n",
    "\n",
    "x = data['X']\n",
    "y = data['Y']\n",
    "\n",
    "offset = y.mean()\n",
    "scale = np.sqrt(y.var())"
   ],
   "id": "b74c45ed-8cd8-459e-a788-7ab55acc13f5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mlai.plot as plot\n",
    "import mlai"
   ],
   "id": "bfcde5a9-880a-4f11-adee-5d00a123cf99"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xlim = (-20,260)\n",
    "ylim = (5, 7.5)\n",
    "yhat = (y-offset)/scale\n",
    "\n",
    "fig, ax = plt.subplots(figsize=plot.big_wide_figsize)\n",
    "_ = ax.plot(x, y, 'r.',markersize=10)\n",
    "ax.set_xlabel('time/min', fontsize=20)\n",
    "ax.set_ylabel('expression', fontsize=20)\n",
    "ax.set_xlim(xlim)\n",
    "ax.set_ylim(ylim)\n",
    "\n",
    "mlai.write_figure(figure=fig, \n",
    "                  filename='./datasets/della-gatta-gene.svg', \n",
    "                  transparent=True, \n",
    "                  frameon=True)"
   ],
   "id": "25bc4331-cfbf-476a-b3f1-605904e5d6b9"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//datasets/della-gatta-gene.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Gene expression levels over time for a gene from data\n",
    "provided by Della Gatta et al. (2008). We would like to understand\n",
    "whether there is signal in the data, or we are only observing noise.</i>\n",
    "\n",
    "-   Want to detect if a gene is expressed or not, fit a GP to each gene\n",
    "    Kalaitzis and Lawrence (2011).\n",
    "\n",
    "<svg viewBox=\"0 0 200 200\" style=\"width:15%\">\n",
    "\n",
    "<defs> <clipPath id=\"clip4\">\n",
    "\n",
    "<style>\n",
    "circle {\n",
    "  fill: black;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<circle cx=\"100\" cy=\"100\" r=\"100\"/> </clipPath> </defs>\n",
    "\n",
    "<title>\n",
    "\n",
    "Freddie Kalaitzis\n",
    "\n",
    "</title>\n",
    "\n",
    "<image preserveAspectRatio=\"xMinYMin slice\" width=\"100%\" xlink:href=\"https://inverseprobability.com/talks/../slides/diagrams//people/freddie-kalaitzis.jpg\" clip-path=\"url(#clip4)\"/>\n",
    "\n",
    "</svg>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//health/1471-2105-12-180_1.png\" style=\"width:80%\">\n",
    "\n",
    "Figure: <i>The example is taken from the paper “A Simple Approach to\n",
    "Ranking Differentially Expressed Gene Expression Time Courses through\n",
    "Gaussian Process Regression.” Kalaitzis and Lawrence (2011).</i>\n",
    "\n",
    "<center>\n",
    "\n",
    "<http://www.biomedcentral.com/1471-2105/12/180>\n",
    "\n",
    "</center>\n",
    "\n",
    "Our first objective will be to perform a Gaussian process fit to the\n",
    "data, we’ll do this using the [GPy\n",
    "software](https://github.com/SheffieldML/GPy)."
   ],
   "id": "d960d489-4c36-4342-8018-a91c61f6040f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPy"
   ],
   "id": "667b5c2e-09f2-42bc-a39c-c38e0208717e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_full = GPy.models.GPRegression(x,yhat)\n",
    "m_full.kern.lengthscale=50\n",
    "_ = m_full.optimize() # Optimize parameters of covariance function"
   ],
   "id": "f6252f4b-262b-4f5b-be76-e7f1f1dcc222"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the length scale parameter (which here actually represents a\n",
    "*time scale* of the covariance function) to a reasonable value. Default\n",
    "would be 1, but here we set it to 50 minutes, given points are arriving\n",
    "across zero to 250 minutes."
   ],
   "id": "564a0bf2-9c5c-490b-9eb7-20182eaa00d9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = np.linspace(-20,260,200)[:,np.newaxis]\n",
    "yt_mean, yt_var = m_full.predict(xt)\n",
    "yt_sd=np.sqrt(yt_var)"
   ],
   "id": "92e37a48-6aff-4efd-9cb3-81a9c6bd0ae5"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plot the results using the helper function in `mlai.plot`."
   ],
   "id": "e2342e71-3f23-45ee-a293-22768a86038c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai.plot as plot"
   ],
   "id": "1ce9b486-7ae6-4fa0-be40-96f402509a96"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=plot.big_wide_figsize)\n",
    "plot.model_output(m_full, scale=scale, offset=offset, ax=ax, xlabel='time/min', ylabel='expression', fontsize=20, portion=0.2)\n",
    "ax.set_xlim(xlim)\n",
    "ax.set_ylim(ylim)\n",
    "ax.set_title('log likelihood: {ll:.3}'.format(ll=m_full.log_likelihood()), fontsize=20)\n",
    "mlai.write_figure(figure=fig,\n",
    "                  filename='./gp/della-gatta-gene-gp.svg', \n",
    "                  transparent=True, frameon=True)"
   ],
   "id": "6e599f72-eb56-492e-87a4-532a4d996d8b"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//gp/della-gatta-gene-gp.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Result of the fit of the Gaussian process model with the time\n",
    "scale parameter initialized to 50 minutes.</i>\n",
    "\n",
    "Now we try a model initialized with a longer length scale."
   ],
   "id": "47ba4fd2-89aa-4d00-b3a0-bcbc8cf61af8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_full2 = GPy.models.GPRegression(x,yhat)\n",
    "m_full2.kern.lengthscale=2000\n",
    "_ = m_full2.optimize() # Optimize parameters of covariance function"
   ],
   "id": "c329f568-ff8a-4506-8b91-0d6b4b2cf1e4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai.plot as plot"
   ],
   "id": "745a6060-dfee-456b-aa87-c730ed465e01"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=plot.big_wide_figsize)\n",
    "plot.model_output(m_full2, scale=scale, offset=offset, ax=ax, xlabel='time/min', ylabel='expression', fontsize=20, portion=0.2)\n",
    "ax.set_xlim(xlim)\n",
    "ax.set_ylim(ylim)\n",
    "ax.set_title('log likelihood: {ll:.3}'.format(ll=m_full2.log_likelihood()), fontsize=20)\n",
    "mlai.write_figure(figure=fig,\n",
    "                  filename='./gp/della-gatta-gene-gp2.svg', \n",
    "                  transparent=True, frameon=True)"
   ],
   "id": "d0c3754c-ffce-4398-91d9-3dc1a2860938"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//gp/della-gatta-gene-gp2.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Result of the fit of the Gaussian process model with the time\n",
    "scale parameter initialized to 2000 minutes.</i>\n",
    "\n",
    "Now we try a model initialized with a lower noise."
   ],
   "id": "efb8ce46-b8ad-4706-881f-28c62a86778a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_full3 = GPy.models.GPRegression(x,yhat)\n",
    "m_full3.kern.lengthscale=20\n",
    "m_full3.likelihood.variance=0.001\n",
    "_ = m_full3.optimize() # Optimize parameters of covariance function"
   ],
   "id": "4631a6ce-765b-4849-9d6b-1294a8752e2b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai.plot as plot"
   ],
   "id": "926f11b7-1be5-4925-b47b-7778259a4c5d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=plot.big_wide_figsize)\n",
    "plot.model_output(m_full3, scale=scale, offset=offset, ax=ax, xlabel='time/min', ylabel='expression', fontsize=20, portion=0.2)\n",
    "ax.set_xlim(xlim)\n",
    "ax.set_ylim(ylim)\n",
    "ax.set_title('log likelihood: {ll:.3}'.format(ll=m_full3.log_likelihood()), fontsize=20)\n",
    "mlai.write_figure(figure=fig,\n",
    "                  filename='./gp/della-gatta-gene-gp3.svg', \n",
    "                  transparent=True, frameon=True)"
   ],
   "id": "8a61a733-0a44-49e0-9360-a9165527f511"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//gp/della-gatta-gene-gp3.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Result of the fit of the Gaussian process model with the\n",
    "noise initialized low (standard deviation 0.1) and the time scale\n",
    "parameter initialized to 20 minutes.</i>"
   ],
   "id": "ecfcaca3-e91a-415e-ad5c-0e641e7794c7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai.plot as plot"
   ],
   "id": "552193fa-21fd-4046-90d1-859c6defcd34"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.multiple_optima(diagrams='./gp')"
   ],
   "id": "e920879d-4455-4f45-b19b-b8e37080af26"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//gp/multiple-optima000.svg\" class=\"\" width=\"50%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i></i>\n",
    "\n",
    "<!--\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//gp/multiple-optima001.svg\" class=\"\" width=\"\" style=\"vertical-align:middle;\">-->"
   ],
   "id": "16d34a1b-8247-42f3-801d-88336759140f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [y.shape[1], 1,x.shape[1]]\n",
    "inits = ['PCA']*(len(layers)-1)\n",
    "kernels = []\n",
    "for i in layers[1:]:\n",
    "    kernels += [GPy.kern.RBF(i)]\n",
    "m = deepgp.DeepGP(layers,Y=yhat, X=x, \n",
    "                  inits=inits, \n",
    "                  kernels=kernels, # the kernels for each layer\n",
    "                  num_inducing=20, back_constraint=False)"
   ],
   "id": "777a19a0-350a-41e2-a40a-45a1d9aea224"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.initialize()\n",
    "m.staged_optimize()"
   ],
   "id": "39663ad1-9577-43be-8f4e-801d34b37240"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(figsize=plot.big_wide_figsize)\n",
    "plot.model_output(m, scale=scale, offset=offset, ax=ax, fontsize=20, portion=0.5)\n",
    "ax.set_ylim(ylim)\n",
    "ax.set_xlim(xlim)\n",
    "mlai.write_figure(filename=\"./deepgp/della-gatta-gene-deep-gp.svg\", \n",
    "            transparent=True, frameon=True)"
   ],
   "id": "c7e1e3c7-4be5-4ae1-817a-da30271c78d5"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Della Gatta Gene Data Deep GP\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_deepgp/includes/della-gatta-deep-gp.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_deepgp/includes/della-gatta-deep-gp.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//deepgp/della-gatta-gene-deep-gp.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Deep Gaussian process fit to the Della Gatta gene expression\n",
    "data.</i>"
   ],
   "id": "f750ceea-4e43-4728-a3c4-8b7da6637f2c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(figsize=plot.big_wide_figsize)\n",
    "plot.model_sample(m, scale=scale, offset=offset, samps=10, ax=ax, portion = 0.5)\n",
    "ax.set_ylim(ylim)\n",
    "ax.set_xlim(xlim)\n",
    "mlai.write_figure(figure=fig, filename='./deepgp/della-gatta-gene-deep-gp-samples.svg', \n",
    "                  transparent=True, frameon=True)"
   ],
   "id": "cf8d1bd8-a666-46a9-b32f-fc7a19c90426"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Della Gatta Gene Data Deep GP\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//deepgp/della-gatta-gene-deep-gp-samples.svg\" class=\"\" width=\"\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Deep Gaussian process samples fitted to the Della Gatta gene\n",
    "expression data.</i>"
   ],
   "id": "7581dfad-8e2c-42a3-8969-c6b612fba52d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.visualize(offset=offset, scale=scale, xlim=xlim, ylim=ylim,\n",
    "            dataset=\"della-gatta-gene\",\n",
    "            diagrams=\"./deepgp\")"
   ],
   "id": "3b5ff5eb-5c52-4395-b601-8d82a04ca303"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Della Gatta Gene Data Latent 1\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//deepgp/della-gatta-gene-deep-gp-layer-0.svg\" class=\"\" width=\"50%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Gaussian process mapping from input to latent layer for the\n",
    "della Gatta gene expression data.</i>"
   ],
   "id": "9a98cd38-fef6-4601-bd5b-b0a93b0a1e22"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Della Gatta Gene Data Latent 2\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//deepgp/della-gatta-gene-deep-gp-layer-1.svg\" class=\"\" width=\"50%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Gaussian process mapping from latent to output layer for the\n",
    "della Gatta gene expression data.</i>"
   ],
   "id": "b81d8fbf-c017-4c39-9038-439f408a8afc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(figsize=plot.big_wide_figsize)\n",
    "m.visualize_pinball(offset=offset, ax=ax, scale=scale, xlim=xlim, ylim=ylim, portion=0.1, points=50)\n",
    "mlai.write_figure(figure=fig, filename=\"./deepgp/della-gatta-gene-deep-gp-pinball.svg\", \n",
    "                  transparent=True, frameon=True, ax=ax)"
   ],
   "id": "489afdc5-f325-48e0-9651-e57bb226bc11"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TP53 Gene Pinball Plot\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//deepgp/della-gatta-gene-deep-gp-pinball.svg\" class=\"\" width=\"60%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>A pinball plot shows the movement of the ‘ball’ as it passes\n",
    "through each layer of the Gaussian processes. Mean directions of\n",
    "movement are shown by lines. Shading gives one standard deviation of\n",
    "movement position. At each layer, the uncertainty is reset. The overal\n",
    "uncertainty is the cumulative uncertainty from all the layers. Pinball\n",
    "plot of the della Gatta gene expression data.</i>"
   ],
   "id": "be9a4711-3d1d-4f32-b54a-6363b37628c5"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step Function\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_ml/includes/step-function-data.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ml/includes/step-function-data.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "Next we consider a simple step function data set."
   ],
   "id": "255680f5-cb7a-4412-a397-22b08b1e936e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_low=25\n",
    "num_high=25\n",
    "gap = -.1\n",
    "noise=0.0001\n",
    "x = np.vstack((np.linspace(-1, -gap/2.0, num_low)[:, np.newaxis],\n",
    "              np.linspace(gap/2.0, 1, num_high)[:, np.newaxis]))\n",
    "y = np.vstack((np.zeros((num_low, 1)), np.ones((num_high,1))))\n",
    "scale = np.sqrt(y.var())\n",
    "offset = y.mean()\n",
    "yhat = (y-offset)/scale"
   ],
   "id": "f56d63e8-e832-44e2-a0bb-309da0298a52"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=plot.big_wide_figsize)\n",
    "_ = ax.plot(x, y, 'r.',markersize=10)\n",
    "_ = ax.set_xlabel('$x$', fontsize=20)\n",
    "_ = ax.set_ylabel('$y$', fontsize=20)\n",
    "xlim = (-2, 2)\n",
    "ylim = (-0.6, 1.6)\n",
    "ax.set_ylim(ylim)\n",
    "ax.set_xlim(xlim)\n",
    "mlai.write_figure(figure=fig, filename='./datasets/step-function.svg', \n",
    "            transparent=True, frameon=True)"
   ],
   "id": "5860bacd-1d47-4c75-bf44-4dc19816b52d"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step Function Data\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//datasets/step-function.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Simulation study of step function data artificially\n",
    "generated. Here there is a small overlap between the two lines.</i>"
   ],
   "id": "fe18ceec-c494-47e9-bd48-d3b70a3048cd"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step Function Data GP\n",
    "\n",
    "We can fit a Gaussian process to the step function data using `GPy` as\n",
    "follows."
   ],
   "id": "84bc6c10-c9fd-42be-93ba-21f6541dfabd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_full = GPy.models.GPRegression(x,yhat)\n",
    "_ = m_full.optimize() # Optimize parameters of covariance function"
   ],
   "id": "0cd2583a-4847-4821-ba6b-94e397282ac5"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where `GPy.models.GPRegression()` gives us a standard GP regression\n",
    "model with exponentiated quadratic covariance function.\n",
    "\n",
    "The model is optimized using `m_full.optimize()` which calls an L-BGFS\n",
    "gradient based solver in python."
   ],
   "id": "b31f36b6-948f-44d8-b764-f8fb48faaff9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(figsize=plot.big_wide_figsize)\n",
    "plot.model_output(m_full, scale=scale, offset=offset, ax=ax, fontsize=20, portion=0.5)\n",
    "ax.set_ylim(ylim)\n",
    "ax.set_xlim(xlim)\n",
    "\n",
    "mlai.write_figure(figure=fig,filename='./gp/step-function-gp.svg', \n",
    "            transparent=True, frameon=True)"
   ],
   "id": "32b03126-ee3d-457f-afde-7c92d1f001e2"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//gp/step-function-gp.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Gaussian process fit to the step function data. Note the\n",
    "large error bars and the over-smoothing of the discontinuity. Error bars\n",
    "are shown at two standard deviations.</i>\n",
    "\n",
    "The resulting fit to the step function data shows some challenges. In\n",
    "particular, the over smoothing at the discontinuity. If we know how many\n",
    "discontinuities there are, we can parameterize them in the step\n",
    "function. But by doing this, we form a semi-parametric model. The\n",
    "parameters indicate how many discontinuities are, and where they are.\n",
    "They can be optimized as part of the model fit. But if new, unforeseen,\n",
    "discontinuities arise when the model is being deployed in practice,\n",
    "these won’t be accounted for in the predictions."
   ],
   "id": "5348794f-b765-49c3-ac52-6591ac10c99e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step Function Data Deep GP\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_deepgp/includes/step-function-deep-gp.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_deepgp/includes/step-function-deep-gp.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "First we initialize a deep Gaussian process with three latent layers\n",
    "(four layers total). Within each layer we create a GP with an\n",
    "exponentiated quadratic covariance (`GPy.kern.RBF`).\n",
    "\n",
    "At each layer we use 20 inducing points for the variational\n",
    "approximation."
   ],
   "id": "187ca05d-2041-4855-a4a5-033129477947"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [y.shape[1], 1, 1, 1,x.shape[1]]\n",
    "inits = ['PCA']*(len(layers)-1)\n",
    "kernels = []\n",
    "for i in layers[1:]:\n",
    "    kernels += [GPy.kern.RBF(i)]\n",
    "    \n",
    "m = deepgp.DeepGP(layers,Y=yhat, X=x, \n",
    "                  inits=inits, \n",
    "                  kernels=kernels, # the kernels for each layer\n",
    "                  num_inducing=20, back_constraint=False)"
   ],
   "id": "acd1d5da-ab1a-4d10-a52c-9b8970ff3357"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is constructed we initialize the parameters, and perform\n",
    "the staged optimization which starts by optimizing variational\n",
    "parameters with a low noise and proceeds to optimize the whole model."
   ],
   "id": "848c43e1-305d-4865-a6b4-f3c5103ff9e1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.initialize()\n",
    "m.staged_optimize()"
   ],
   "id": "b65c2076-209d-45c6-b681-aece92fb9a5c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the output of the deep Gaussian process fitted to the step data\n",
    "as follows."
   ],
   "id": "07fe551c-c03e-4d2a-9419-c6fbde9d8239"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(figsize=plot.big_wide_figsize)\n",
    "plot.model_output(m, scale=scale, offset=offset, ax=ax, fontsize=20, portion=0.5)\n",
    "ax.set_ylim(ylim)\n",
    "ax.set_xlim(xlim)\n",
    "mlai.write_figure(filename='./deepgp/step-function-deep-gp.svg', \n",
    "            transparent=True, frameon=True)"
   ],
   "id": "73450122-d3cb-4ee9-9079-cdf216c41ee0"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The deep Gaussian process does a much better job of fitting the data. It\n",
    "handles the discontinuity easily, and error bars drop to smaller values\n",
    "in the regions of data.\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//deepgp/step-function-deep-gp.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Deep Gaussian process fit to the step function data.</i>"
   ],
   "id": "6e285563-e4f7-4bed-9344-dec69c562363"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step Function Data Deep GP\n",
    "\n",
    "The samples of the model can be plotted with the helper function from\n",
    "`mlai.plot`, `model_sample`"
   ],
   "id": "0f36d479-7c8b-4349-8a41-185cc07a30c0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai.plot as plot"
   ],
   "id": "c531c6e4-f955-49d4-b08a-3c8b7b78197a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(figsize=plot.big_wide_figsize)\n",
    "\n",
    "plot.model_sample(m, scale=scale, offset=offset, samps=10, ax=ax, portion = 0.5)\n",
    "ax.set_ylim(ylim)\n",
    "ax.set_xlim(xlim)\n",
    "mlai.write_figure(figure=fig, filename='./deepgp/step-function-deep-gp-samples.svg', \n",
    "                  transparent=True, frameon=True)"
   ],
   "id": "c5517d24-ae23-483b-b9dc-94f4a0b8371f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The samples from the model show that the error bars, which are\n",
    "informative for Gaussian outputs, are less informative for this model.\n",
    "They make clear that the data points lie, in output mainly at 0 or 1, or\n",
    "occasionally in between.\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//deepgp/step-function-deep-gp-samples.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Samples from the deep Gaussian process model for the step\n",
    "function fit.</i>\n",
    "\n",
    "The visualize code allows us to inspect the intermediate layers in the\n",
    "deep GP model to understand how it has reconstructed the step function."
   ],
   "id": "afb66995-8d85-42f3-8f64-0bd4a992ebde"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.visualize(offset=offset, scale=scale, xlim=xlim, ylim=ylim,\n",
    "            dataset='step-function',\n",
    "            diagrams='./deepgp')"
   ],
   "id": "6bb5cd57-ef2b-4628-a349-55eee5d3fa38"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//deepgp/step-function-deep-gp-layer-0.svg\" class=\"\" width=\"60%\" style=\"vertical-align:middle;\">\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//deepgp/step-function-deep-gp-layer-1.svg\" class=\"\" width=\"60%\" style=\"vertical-align:middle;\">\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//deepgp/step-function-deep-gp-layer-2.svg\" class=\"\" width=\"60%\" style=\"vertical-align:middle;\">\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//deepgp/step-function-deep-gp-layer-3.svg\" class=\"\" width=\"60%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>From top to bottom, the Gaussian process mapping function\n",
    "that makes up each layer of the resulting deep Gaussian process.</i>\n",
    "\n",
    "A pinball plot can be created for the resulting model to understand how\n",
    "the input is being translated to the output across the different layers."
   ],
   "id": "46bcbe86-7a77-4b93-8b14-13b55fb7e2d8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mlai.plot as plot\n",
    "import mlai"
   ],
   "id": "9391bef8-72e4-4873-a2e8-b85215c7b6c6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(figsize=plot.big_wide_figsize)\n",
    "m.visualize_pinball(offset=offset, ax=ax, scale=scale, xlim=xlim, ylim=ylim, portion=0.1, points=50)\n",
    "mlai.write_figure(figure=fig, filename='./deepgp/step-function-deep-gp-pinball.svg', \n",
    "                  transparent=True, frameon=True, ax=ax)"
   ],
   "id": "82c3620e-9f5e-4045-aeae-63d0cfbba63d"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//deepgp/step-function-deep-gp-pinball.svg\" class=\"\" width=\"60%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Pinball plot of the deep GP fitted to the step function data.\n",
    "Each layer of the model pushes the ‘ball’ towards the left or right,\n",
    "saturating at 1 and 0. This causes the final density to be be peaked at\n",
    "0 and 1. Transitions occur driven by the uncertainty of the mapping in\n",
    "each layer.</i>"
   ],
   "id": "c78d15f3-b12d-41e2-9b0b-6cb00003a67b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pods"
   ],
   "id": "eff10761-b44e-4117-b607-a5965680a530"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pods.datasets.mcycle()\n",
    "x = data['X']\n",
    "y = data['Y']\n",
    "scale=np.sqrt(y.var())\n",
    "offset=y.mean()\n",
    "yhat = (y - offset)/scale"
   ],
   "id": "6d85e14e-dfdf-4ecd-9032-d9ba3c032ff8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mlai\n",
    "import mlai.plot as plot"
   ],
   "id": "72a78690-d7e6-4563-82a6-e4ba5fc0188a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=plot.big_wide_figsize)\n",
    "_ = ax.plot(x, y, 'r.',markersize=10)\n",
    "_ = ax.set_xlabel('time', fontsize=20)\n",
    "_ = ax.set_ylabel('acceleration', fontsize=20)\n",
    "xlim = (-20, 80)\n",
    "ylim = (-175, 125)\n",
    "ax.set_xlim(xlim)\n",
    "ax.set_ylim(ylim)\n",
    "mlai.write_figure(filename='motorcycle-helmet.svg', directory='./datasets/',\n",
    "            transparent=True, frameon=True)"
   ],
   "id": "f817fc24-894e-4393-a40e-595edd212567"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motorcycle Helmet Data\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_datasets/includes/motorcycle-helmet-data.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_datasets/includes/motorcycle-helmet-data.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//datasets/motorcycle-helmet.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Motorcycle helmet data. The data consists of acceleration\n",
    "readings on a motorcycle helmet undergoing a collision. The data\n",
    "exhibits heteroschedastic (time varying) noise levles and\n",
    "non-stationarity.</i>"
   ],
   "id": "78ad331e-38df-401c-959e-449a20795fed"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_full = GPy.models.GPRegression(x,yhat)\n",
    "_ = m_full.optimize() # Optimize parameters of covariance function"
   ],
   "id": "f1266d3d-328b-429e-9dfb-f92619cd180f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mlai.plot as plot\n",
    "import mlai"
   ],
   "id": "728c396c-15b8-478a-9292-94e19a919aa8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(figsize=plot.big_wide_figsize)\n",
    "plot.model_output(m_full, scale=scale, offset=offset, ax=ax, xlabel='time', ylabel='acceleration/$g$', fontsize=20, portion=0.5)\n",
    "xlim=(-20,80)\n",
    "ylim=(-180,120)\n",
    "ax.set_ylim(ylim)\n",
    "ax.set_xlim(xlim)\n",
    "mlai.write_figure(figure=fig,filename='./gp/motorcycle-helmet-gp.svg', \n",
    "            transparent=True, frameon=True)"
   ],
   "id": "87d51983-0c84-405b-bf76-7f8a33bcb292"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motorcycle Helmet Data GP\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_gp/includes/motorcycle-helmet-gp.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_gp/includes/motorcycle-helmet-gp.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//gp/motorcycle-helmet-gp.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Gaussian process fit to the motorcycle helmet accelerometer\n",
    "data.</i>"
   ],
   "id": "fa6d6048-e6c0-48f7-888b-7a8dde0cc073"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motorcycle Helmet Data Deep GP\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_deepgp/includes/motorcycle-helmet-deep-gp.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_deepgp/includes/motorcycle-helmet-deep-gp.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
   ],
   "id": "ad834727-1f7a-40d2-94aa-899566d9514f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepgp"
   ],
   "id": "2bada59a-49f5-466c-be04-5b2f7f7fa66e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [y.shape[1], 1, x.shape[1]]\n",
    "inits = ['PCA']*(len(layers)-1)\n",
    "kernels = []\n",
    "for i in layers[1:]:\n",
    "    kernels += [GPy.kern.RBF(i)]\n",
    "m = deepgp.DeepGP(layers,Y=yhat, X=x, \n",
    "                  inits=inits, \n",
    "                  kernels=kernels, # the kernels for each layer\n",
    "                  num_inducing=20, back_constraint=False)\n",
    "\n",
    "\n",
    "\n",
    "m.initialize()"
   ],
   "id": "1c25d658-be88-42b0-8753-1f45aba8fc46"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.staged_optimize(iters=(1000,1000,10000), messages=(True, True, True))"
   ],
   "id": "d3dd8ecf-ae95-4021-9efc-ed4342bbbaec"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mlai.plot as plot\n",
    "import mlai"
   ],
   "id": "dcfbc80a-5120-45ad-b914-6005a491b22f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(figsize=plot.big_wide_figsize)\n",
    "plot.model_output(m, scale=scale, offset=offset, ax=ax, xlabel='time', ylabel='acceleration/$g$', fontsize=20, portion=0.5)\n",
    "ax.set_ylim(ylim)\n",
    "ax.set_xlim(xlim)\n",
    "mlai.write_figure(filename='./deepgp/motorcycle-helmet-deep-gp.svg', \n",
    "            transparent=True, frameon=True)"
   ],
   "id": "f2fc885e-a594-4be8-8934-04dd5334492f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//deepgp/motorcycle-helmet-deep-gp.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Deep Gaussian process fit to the motorcycle helmet\n",
    "accelerometer data.</i>"
   ],
   "id": "938af27b-003c-4048-a272-f97fe10b212c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai.plot as plot\n",
    "import mlai"
   ],
   "id": "bb7881f6-30bf-4e02-b8eb-8259f63e97e5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(figsize=plot.big_wide_figsize)\n",
    "plot.model_sample(m, scale=scale, offset=offset, samps=10, ax=ax, xlabel='time', ylabel='acceleration/$g$', portion = 0.5)\n",
    "ax.set_ylim(ylim)\n",
    "ax.set_xlim(xlim)\n",
    "\n",
    "mlai.write_figure(figure=fig, filename='./deepgp/motorcycle-helmet-deep-gp-samples.svg', \n",
    "                  transparent=True, frameon=True)"
   ],
   "id": "45110474-224d-4f04-af4e-168bac35f004"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motorcycle Helmet Data Deep GP\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//deepgp/motorcycle-helmet-deep-gp-samples.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Samples from the deep Gaussian process as fitted to the\n",
    "motorcycle helmet accelerometer data.</i>"
   ],
   "id": "1e7699a8-0243-4ba2-816c-ffd50a7412bd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.visualize(xlim=xlim, ylim=ylim, scale=scale,offset=offset, \n",
    "            xlabel=\"time\", ylabel=\"acceleration/$g$\", portion=0.5,\n",
    "            dataset='motorcycle-helmet',\n",
    "            diagrams='./deepgp')"
   ],
   "id": "71a08c3b-b1e8-438a-b50d-ef2d38908d24"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motorcycle Helmet Data Latent 1\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//deepgp/motorcycle-helmet-deep-gp-layer-0.svg\" class=\"\" width=\"60%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Mappings from the input to the latent layer for the\n",
    "motorcycle helmet accelerometer data.</i>"
   ],
   "id": "1b10c6d4-2b4c-4a43-a1e5-4a725e410e38"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motorcycle Helmet Data Latent 2\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//deepgp/motorcycle-helmet-deep-gp-layer-1.svg\" class=\"\" width=\"60%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Mappings from the latent layer to the output layer for the\n",
    "motorcycle helmet accelerometer data.</i>"
   ],
   "id": "e5da75f2-32c1-4835-8b3a-a5079ec2060f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(figsize=plot.big_wide_figsize)\n",
    "m.visualize_pinball(ax=ax, xlabel='time', ylabel='acceleration/g', \n",
    "                    points=50, scale=scale, offset=offset, portion=0.1)\n",
    "mlai.write_figure(figure=fig, filename='./deepgp/motorcycle-helmet-deep-gp-pinball.svg', \n",
    "                  transparent=True, frameon=True)"
   ],
   "id": "1aa09f0a-e804-4cdc-af80-64e820477688"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motorcycle Helmet Pinball Plot\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//deepgp/motorcycle-helmet-deep-gp-pinball.svg\" class=\"\" width=\"60%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Pinball plot for the mapping from input to output layer for\n",
    "the motorcycle helmet accelerometer data.</i>"
   ],
   "id": "740d37c8-3a37-4184-946b-38d727e8d22f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robot Wireless Data\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_datasets/includes/robot-wireless-data.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_datasets/includes/robot-wireless-data.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "The robot wireless data is taken from an experiment run by Brian Ferris\n",
    "at University of Washington. It consists of the measurements of WiFi\n",
    "access point signal strengths as Brian walked in a loop. It was\n",
    "published at IJCAI in 2007 (Ferris et al., 2007)."
   ],
   "id": "b15f1d86-fbcb-47e6-8f7c-75e5ac4d9c98"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pods\n",
    "import numpy as np"
   ],
   "id": "9a7baa89-a14a-40af-8ecd-d3e229fa5d6e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pods.datasets.robot_wireless()"
   ],
   "id": "f29fcea9-f75a-49be-8b09-df3eb88ee85a"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ground truth is recorded in the data, the actual loop is given in\n",
    "the plot below."
   ],
   "id": "09fb6cda-0d36-4f69-af1e-84548201f644"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mlai\n",
    "import mlai.plot as plot"
   ],
   "id": "5d393097-c70b-49f6-a642-f212c97f9f2b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=plot.big_figsize)\n",
    "plt.plot(data['X'][:, 1], data['X'][:, 2], 'r.', markersize=5)\n",
    "ax.set_xlabel('x position', fontsize=20)\n",
    "ax.set_ylabel('y position', fontsize=20)\n",
    "mlai.write_figure(figure=fig, \n",
    "                  filename='robot-wireless-ground-truth.svg',\n",
    "                  directory='./datasets')"
   ],
   "id": "585672f6-d101-40e2-8a96-19a43a6d3234"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robot Wireless Ground Truth\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//datasets/robot-wireless-ground-truth.svg\" class=\"\" width=\"60%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Ground truth movement for the position taken while recording\n",
    "the multivariate time-course of wireless access point signal\n",
    "strengths.</i>\n",
    "\n",
    "We will ignore this ground truth in making our predictions, but see if\n",
    "the model can recover something similar in one of the latent layers."
   ],
   "id": "98a45771-3db6-4812-bef0-a704df4f93a5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim=1\n",
    "xlim = (-0.3, 1.3)\n",
    "fig, ax = plt.subplots(figsize=plot.big_wide_figsize)\n",
    "_ = ax.plot(np.linspace(0,1,215),\n",
    "            data['Y'][:, output_dim], \n",
    "            'r.', markersize=5)\n",
    "\n",
    "ax.set_xlabel('time', fontsize=20)\n",
    "ax.set_ylabel('signal strength', fontsize=20)\n",
    "xlim = (-0.2, 1.2)\n",
    "ylim = (-0.6, 2.0)\n",
    "ax.set_xlim(xlim)\n",
    "ax.set_ylim(ylim)\n",
    "\n",
    "ma.write_figure(figure=fig, \n",
    "                filename='robot-wireless-dim-' + str(output_dim) + '.svg', \n",
    "                directory='./datasets')"
   ],
   "id": "10150db5-2cec-4162-8642-71777bab19e2"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robot WiFi Data\n",
    "\n",
    "One challenge with the data is that the signal strength ‘drops out’.\n",
    "This is because the device only tracks a limited number of wifi access\n",
    "points, when one of the access points falls outside the track, the value\n",
    "disappears (in the plot below it reads -0.5). The data is missing, but\n",
    "it is not missing at random because the implication is that the wireless\n",
    "access point must be weak to have dropped from the list of those that\n",
    "are tracked.\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//datasets/robot-wireless-dim-1.svg\" class=\"\" width=\"60%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Output dimension 1 from the robot wireless data. This plot\n",
    "shows signal strength changing over time.</i>"
   ],
   "id": "4bff596c-f79e-4dec-b3da-eedb2907c38e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Process Fit to Robot Wireless Data\n",
    "\n",
    "Perform a Gaussian process fit on the data using GPy."
   ],
   "id": "894ff80d-ff45-4ade-b82a-a5ef8140881b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_full = GPy.models.GPRegression(x,yhat)\n",
    "_ = m_full.optimize() # Optimize parameters of covariance function"
   ],
   "id": "74a68b3c-52dd-4ad7-b575-c16180ef22be"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robot WiFi Data GP"
   ],
   "id": "00fee916-8495-45f9-a166-b99aef3d0ebf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import mlai\n",
    "import mlai.plot as plot"
   ],
   "id": "7d32145c-6841-44e9-aa18-2e4f17125768"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//gp/robot-wireless-gp-dim-1.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Gaussian process fit to the Robot Wireless dimension 1.</i>"
   ],
   "id": "a58c0883-c530-40c6-b167-a847448c5047"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [y.shape[1], 10, 5, 2, 2, x.shape[1]]\n",
    "inits = ['PCA']*(len(layers)-1)\n",
    "kernels = []\n",
    "for i in layers[1:]:\n",
    "    kernels += [GPy.kern.RBF(i, ARD=True)]"
   ],
   "id": "a67caf6a-ce05-4efb-b589-dd03b9aa8134"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = deepgp.DeepGP(layers,Y=y, X=x, inits=inits, \n",
    "                  kernels=kernels,\n",
    "                  num_inducing=50, back_constraint=False)\n",
    "m.initialize()"
   ],
   "id": "a362d5dc-7245-4acf-8224-0ba6288515ed"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.staged_optimize(messages=(True,True,True))"
   ],
   "id": "7db6cac3-3111-4223-87ed-1f87ca48020b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(figsize=plot.big_wide_figsize)\n",
    "plot.model_output(m, output_dim=output_dim, scale=scale, offset=offset, ax=ax, \n",
    "                  xlabel='time', ylabel='signal strength', fontsize=20, portion=0.5)\n",
    "ax.set_ylim(ylim)\n",
    "ax.set_xlim(xlim)\n",
    "mlai.write_figure(figure=fig, filename='./deepgp/robot-wireless-deep-gp-dim-' + str(output_dim)+ '.svg', \n",
    "                  transparent=True, frameon=True)"
   ],
   "id": "c6d66054-b8f6-49e1-89b9-764d4268d70e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robot WiFi Data Deep GP\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_deepgp/includes/robot-wireless-deep-gp.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_deepgp/includes/robot-wireless-deep-gp.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//deepgp/robot-wireless-deep-gp-dim-1.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Fit of the deep Gaussian process to dimension 1 of the robot\n",
    "wireless data.</i>"
   ],
   "id": "3bd9af0d-d981-4721-90c2-2ecbcd2b3dde"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(figsize=plot.big_wide_figsize)\n",
    "plot.model_sample(m, output_dim=output_dim, scale=scale, offset=offset, samps=10, ax=ax,\n",
    "                  xlabel='time', ylabel='signal strength', fontsize=20, portion=0.5)\n",
    "ax.set_ylim(ylim)\n",
    "ax.set_xlim(xlim)\n",
    "mlai.write_figure(figure=fig, filename='./deepgp/robot-wireless-deep-gp-samples-dim-' + str(output_dim)+ '.svg', \n",
    "                  transparent=True, frameon=True)"
   ],
   "id": "7f0468e7-4b8b-480a-92c2-add156609ca3"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robot WiFi Data Deep GP\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//deepgp/robot-wireless-deep-gp-samples-dim-1.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Samples from the deep Gaussian process fit to dimension 1 of\n",
    "the robot wireless data.</i>"
   ],
   "id": "22a4d5e1-e8b0-468a-b518-f42246e6462f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robot WiFi Data Latent Space"
   ],
   "id": "028ac59c-0e80-4e21-938b-43eb9f63b17d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=plot.big_figsize)\n",
    "ax.plot(m.layers[-2].latent_space.mean[:, 0], \n",
    "        m.layers[-2].latent_space.mean[:, 1], \n",
    "        'r.-', markersize=5)\n",
    "\n",
    "ax.set_xlabel('latent dimension 1', fontsize=20)\n",
    "ax.set_ylabel('latent dimension 2', fontsize=20)\n",
    "\n",
    "mlai.write_figure(figure=fig, filename='./deepgp/robot-wireless-latent-space.svg', \n",
    "            transparent=True, frameon=True)"
   ],
   "id": "8efdc79e-5fa8-4422-9b41-b21054360206"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//deepgp/robot-wireless-latent-space.svg\" class=\"\" width=\"60%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Inferred two dimensional latent space from the model for the\n",
    "robot wireless data.</i>"
   ],
   "id": "14212753-ce98-40db-9c3c-b5c09d916b3a"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‘High Five’ Motion Capture Data\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_datasets/includes/high-five-data.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_datasets/includes/high-five-data.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "Motion capture data from the CMU motion capture data base (CMU Motion\n",
    "Capture Lab, 2003). It contains two subjects approaching each other and\n",
    "executing a ‘high five’. The subjects are number 10 and 11 and their\n",
    "motion numbers are 21."
   ],
   "id": "e58440b7-c96d-449a-a657-9031719c5bc7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pods"
   ],
   "id": "53437825-745b-4998-8d84-b4e74b16030e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pods.datasets.cmu_mocap_high_five()"
   ],
   "id": "5d9868ad-a42c-49e9-81f9-de296f8374f4"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data dictionary contains the keys ‘Y1’ and ‘Y2’, which represent the\n",
    "motions of the two different subjects. Their skeleton files are included\n",
    "in the keys ‘skel1’ and ‘skel2’."
   ],
   "id": "05b3b7dc-7c17-48ff-b910-6c31d0fb6632"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Y1'].shape\n",
    "data['Y2'].shape"
   ],
   "id": "9bce754d-753c-401f-aa7d-53c0a93b90ab"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data was used in the hierarchical GP-LVM paper (Lawrence and Moore,\n",
    "2007) in an experiment that was also recreated in the Deep Gaussian\n",
    "process paper (Damianou and Lawrence, 2013)."
   ],
   "id": "f838c65f-169c-4f5a-889e-9ab48ee6fa3a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['citation'])"
   ],
   "id": "5e21b9d4-bba7-4fa3-bbfd-af627e7f6f1f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And extra information about the data is included, as standard, under the\n",
    "keys `info` and `details`."
   ],
   "id": "6d140f80-f0e3-4aac-9f43-62ddb1398fd4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['info'])\n",
    "print()\n",
    "print(data['details'])"
   ],
   "id": "586c1793-8876-49e1-9dc9-8491709a3a63"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared LVM\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_deepgp/includes/high-five-deep-gp.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_deepgp/includes/high-five-deep-gp.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//shared.svg\" class=\"\" width=\"60%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Shared latent variable model structure. Here two related data\n",
    "sets are brought together with a set of latent variables that are\n",
    "partially shared and partially specific to one of the data sets.</i>\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/../slides/diagrams//deep-gp-high-five2.png\" style=\"width:80%\">\n",
    "\n",
    "Figure: <i>Latent spaces of the ‘high five’ data. The structure of the\n",
    "model is automatically learnt. One of the latent spaces is coordinating\n",
    "how the two figures walk together, the other latent spaces contain\n",
    "latent variables that are specific to each of the figures\n",
    "separately.</i>"
   ],
   "id": "e9290818-3e1e-4ce3-a29c-a974400d525d"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsample of the MNIST Data\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_datasets/includes/mnist-digits-subsample-data.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_datasets/includes/mnist-digits-subsample-data.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "We will look at a sub-sample of the MNIST digit data set.\n",
    "\n",
    "First load in the MNIST data set from scikit learn. This can take a\n",
    "little while because it’s large to download."
   ],
   "id": "7f95ec17-96d5-4e6d-a8a7-6e9e91e160cd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml"
   ],
   "id": "2bb13df6-3991-416c-8fe6-f3e631e97bd9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784')"
   ],
   "id": "878f6e6f-675b-4a0f-8389-a3779c2ff096"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sub-sample the dataset to make the training faster."
   ],
   "id": "8a8c5710-287f-4ce6-a69a-ef0fbcbac0d9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "id": "4b2e38df-1aa3-4546-9601-2a69775e2eb9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "digits = [0,1,2,3,4]\n",
    "N_per_digit = 100\n",
    "Y = []\n",
    "labels = []\n",
    "for d in digits:\n",
    "    imgs = mnist['data'][mnist['target']==str(d)]\n",
    "    Y.append(imgs.loc[np.random.permutation(imgs.index)[:N_per_digit]])\n",
    "    labels.append(np.ones(N_per_digit)*d)\n",
    "Y = np.vstack(Y).astype(np.float64)\n",
    "labels = np.hstack(labels)\n",
    "Y /= 255"
   ],
   "id": "e1425973-b4ba-480c-9b21-35c538bf9877"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a Deep GP to a the MNIST Digits Subsample\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_deepgp/includes/mnist-digits-subsample-deep-gp.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_deepgp/includes/mnist-digits-subsample-deep-gp.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<svg viewBox=\"0 0 200 200\" style=\"width:15%\">\n",
    "\n",
    "<defs> <clipPath id=\"clip5\">\n",
    "\n",
    "<style>\n",
    "circle {\n",
    "  fill: black;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<circle cx=\"100\" cy=\"100\" r=\"100\"/> </clipPath> </defs>\n",
    "\n",
    "<title>\n",
    "\n",
    "Zhenwen Dai\n",
    "\n",
    "</title>\n",
    "\n",
    "<image preserveAspectRatio=\"xMinYMin slice\" width=\"100%\" xlink:href=\"https://inverseprobability.com/talks/../slides/diagrams//people/zhenwen-dai.jpg\" clip-path=\"url(#clip5)\"/>\n",
    "\n",
    "</svg>\n",
    "<svg viewBox=\"0 0 200 200\" style=\"width:15%\">\n",
    "\n",
    "<defs> <clipPath id=\"clip6\">\n",
    "\n",
    "<style>\n",
    "circle {\n",
    "  fill: black;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<circle cx=\"100\" cy=\"100\" r=\"100\"/> </clipPath> </defs>\n",
    "\n",
    "<title>\n",
    "\n",
    "Andreas Damianou\n",
    "\n",
    "</title>\n",
    "\n",
    "<image preserveAspectRatio=\"xMinYMin slice\" width=\"100%\" xlink:href=\"https://inverseprobability.com/talks/../slides/diagrams//people/andreas-damianou.png\" clip-path=\"url(#clip6)\"/>\n",
    "\n",
    "</svg>\n",
    "\n",
    "We now look at the deep Gaussian processes’ capacity to perform\n",
    "unsupervised learning."
   ],
   "id": "a2a0e22c-597c-4c43-a214-6e3727a3b887"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a Deep GP\n",
    "\n",
    "We’re going to fit a Deep Gaussian process model to the MNIST data with\n",
    "two hidden layers. Each of the two Gaussian processes (one from the\n",
    "first hidden layer to the second, one from the second hidden layer to\n",
    "the data) has an exponentiated quadratic covariance."
   ],
   "id": "860718d5-6d58-419e-826d-3ed09648c9a9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepgp\n",
    "import GPy"
   ],
   "id": "60bfd290-5334-4f64-ae06-3fa6aac574be"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_latent = 2\n",
    "num_hidden_2 = 5\n",
    "m = deepgp.DeepGP([Y.shape[1],num_hidden_2,num_latent],\n",
    "                  Y,\n",
    "                  kernels=[GPy.kern.RBF(num_hidden_2,ARD=True), \n",
    "                           GPy.kern.RBF(num_latent,ARD=False)], \n",
    "                  num_inducing=50, back_constraint=False, \n",
    "                  encoder_dims=[[200],[200]])"
   ],
   "id": "20a2c40c-7f4c-45fd-8079-3f99eaec65ed"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "Just like deep neural networks, there are some tricks to intitializing\n",
    "these models. The tricks we use here include some early training of the\n",
    "model with model parameters constrained. This gives the variational\n",
    "inducing parameters some scope to tighten the bound for the case where\n",
    "the noise variance is small and the variances of the Gaussian processes\n",
    "are around 1."
   ],
   "id": "864f86a9-1cb8-4ff4-bd55-e45e3316449e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.obslayer.likelihood.variance[:] = Y.var()*0.01\n",
    "for layer in m.layers:\n",
    "    layer.kern.variance.fix(warning=False)\n",
    "    layer.likelihood.variance.fix(warning=False)"
   ],
   "id": "e59d9c10-f665-4c17-88ba-b863333c5eb0"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now we optimize for a hundred iterations with the constrained model."
   ],
   "id": "1cbf6101-04ea-4292-b5f7-3dcda8f1b12c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.optimize(messages=False,max_iters=100)"
   ],
   "id": "5450355c-e66c-48f0-a0c6-4332206afaf3"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we remove the fixed constraint on the kernel variance parameters,\n",
    "but keep the noise output constrained, and run for a further 100\n",
    "iterations."
   ],
   "id": "ca6de734-0007-4e01-8786-b82ab016c428"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in m.layers:\n",
    "    layer.kern.variance.constrain_positive(warning=False)\n",
    "m.optimize(messages=False,max_iters=100)"
   ],
   "id": "077a0620-1b8f-41cc-86c4-57ed7481265b"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we unconstrain the layer likelihoods and allow the full model to\n",
    "be trained for 1000 iterations."
   ],
   "id": "f3515149-c387-4e3b-9e7e-600e97a47516"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in m.layers:\n",
    "    layer.likelihood.variance.constrain_positive(warning=False)\n",
    "m.optimize(messages=True,max_iters=10000)"
   ],
   "id": "0fbf0479-e7ad-4014-ad8c-6859799505da"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the latent space of the top layer\n",
    "\n",
    "Now the model is trained, let’s plot the mean of the posterior\n",
    "distributions in the top latent layer of the model."
   ],
   "id": "b70d73fc-7635-4186-8812-6c2741923ce2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mlai.plot as plot\n",
    "import mlai"
   ],
   "id": "7dd9e2d5-6c8f-4634-be42-d3ada2b5e27f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rc"
   ],
   "id": "a459fa75-732a-4e13-b9c5-d2105c9a83a5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc(\"font\", **{'family':'sans-serif','sans-serif':['Helvetica'],'size':20})\n",
    "fig, ax = plt.subplots(figsize=plot.big_figsize)\n",
    "for d in digits:\n",
    "    ax.plot(m.layer_1.X.mean[labels==d,0],m.layer_1.X.mean[labels==d,1],'.',label=str(d))\n",
    "_ = plt.legend()\n",
    "mlai.write_figure(figure=fig, filename=\"./deepgp/mnist-digits-subsample-latent.svg\", transparent=True)"
   ],
   "id": "319cd2e5-b62d-4c71-b94f-7b36b40c89df"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//deepgp/mnist-digits-subsample-latent.svg\" class=\"\" width=\"60%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Latent space for the deep Gaussian process learned through\n",
    "unsupervised learning and fitted to a subset of the MNIST digits\n",
    "subsample.</i>"
   ],
   "id": "7f9cc7e2-c654-4fe2-a790-d05914c42a70"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the latent space of the intermediate layer\n",
    "\n",
    "We can also visualize dimensions of the intermediate layer. First the\n",
    "lengthscale of those dimensions is given by"
   ],
   "id": "133e86b2-a3be-4be4-9643-01de38443bfb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.obslayer.kern.lengthscale"
   ],
   "id": "37e0fe19-51f8-4ab3-aaec-ba4811639480"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mlai.plot as plot\n",
    "import mlai"
   ],
   "id": "f96a558f-a8eb-4162-b16a-9273a51673e7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=plot.big_figsize)\n",
    "for i in range(5):\n",
    "    for j in range(i):\n",
    "        dims=[i, j]\n",
    "        ax.cla()\n",
    "        for d in digits:\n",
    "            ax.plot(m.obslayer.X.mean[labels==d,dims[0]],\n",
    "                 m.obslayer.X.mean[labels==d,dims[1]],\n",
    "                 '.', label=str(d))\n",
    "        plt.legend()\n",
    "        plt.xlabel('dimension ' + str(dims[0]))\n",
    "        plt.ylabel('dimension ' + str(dims[1]))\n",
    "        mlai.write_figure(figure=fig, filename=\"./deepgp/mnist-digits-subsample-hidden-\" + str(dims[0]) + '-' + str(dims[1]) + '.svg', transparent=True)"
   ],
   "id": "61fb0f80-8e65-46a1-a6b4-d445d4506040"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//deepgp/mnist-digits-subsample-hidden-1-0.svg\" class=\"\" width=\"60%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Visualisation of the intermediate layer, plot of dimension 1\n",
    "vs dimension 0.</i>\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//deepgp/mnist-digits-subsample-hidden-2-0.svg\" class=\"\" width=\"60%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Visualisation of the intermediate layer, plot of dimension 1\n",
    "vs dimension 0.</i>\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//deepgp/mnist-digits-subsample-hidden-3-0.svg\" class=\"\" width=\"60%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Visualisation of the intermediate layer, plot of dimension 1\n",
    "vs dimension 0.</i>\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//deepgp/mnist-digits-subsample-hidden-4-0.svg\" class=\"\" width=\"60%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Visualisation of the intermediate layer, plot of dimension 1\n",
    "vs dimension 0.</i>"
   ],
   "id": "ad9a5487-77ce-4ec0-aaef-d05dbe461334"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate From Model\n",
    "\n",
    "Now we can take a look at a sample from the model, by drawing a Gaussian\n",
    "random sample in the latent space and propagating it through the model."
   ],
   "id": "b3a8fbaf-73df-4f02-8745-264377282479"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rows = 10\n",
    "cols = 20\n",
    "t=np.linspace(-1, 1, rows*cols)[:, None]\n",
    "kern = GPy.kern.RBF(1,lengthscale=0.05)\n",
    "cov = kern.K(t, t)\n",
    "x = np.random.multivariate_normal(np.zeros(rows*cols), cov, num_latent).T"
   ],
   "id": "972737d1-bb15-4005-ae27-38bf097819d7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mlai.plot as plot\n",
    "import mlai"
   ],
   "id": "64fb394a-9a7f-4472-a8d2-e173c8b3c290"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt = m.predict(x)\n",
    "fig, axs = plt.subplots(rows,cols,figsize=(10,6))\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        #v = np.random.normal(loc=yt[0][i*cols+j, :], scale=np.sqrt(yt[1][i*cols+j, :]))\n",
    "        v = yt[0][i*cols+j, :]\n",
    "        axs[i,j].imshow(v.reshape(28,28), \n",
    "                        cmap='gray', interpolation='none',\n",
    "                        aspect='equal')\n",
    "        axs[i,j].set_axis_off()\n",
    "mlai.write_figure(figure=fig, filename=\"./deepgp/digit-samples-deep-gp.svg\", transparent=True)"
   ],
   "id": "dff8d04f-c117-4671-9574-9f11ff72ef3f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//deepgp/digit-samples-deep-gp.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>These digits are produced by taking a tour of the two\n",
    "dimensional latent space (as described by a Gaussian process sample) and\n",
    "mapping the tour into the data space. We visualize the mean of the\n",
    "mapping in the images.</i>"
   ],
   "id": "a3373575-125a-440c-bb18-470bcee405b6"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Health\n",
    "\n",
    "<span class=\"editsection-bracket\"\n",
    "style=\"\">\\[</span><span class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_health/includes/deep-health-model.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_health/includes/deep-health-model.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/../slides/diagrams//deep-health.svg\" class=\"\" width=\"70%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>The deep health model uses different layers of abstraction in\n",
    "the deep Gaussian process to represent information about diagnostics and\n",
    "treatment to model interelationships between a patients different data\n",
    "modalities.</i>\n",
    "\n",
    "From a machine learning perspective, we’d like to be able to interrelate\n",
    "all the different modalities that are informative about the state of the\n",
    "disease. For deep health, the notion is that the state of the disease is\n",
    "appearing at the more abstract levels, as we descend the model, we\n",
    "express relationships between the more abstract concept, that sits\n",
    "within the physician’s mind, and the data we can measure."
   ],
   "id": "6b9b1708-e4a7-49d5-9ed6-19ee399d7a7d"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "The probabilistic modelling community has evolved in an era where the\n",
    "assumption was that ambiguous conclusions are best shared with a\n",
    "(trained) professional through probabilities. Recent advances in\n",
    "generative AI offer the possibility of machines that have a better\n",
    "understanding of human subjective ambiguities and therefore machines\n",
    "that can summarise information in a way that can be interogated rather\n",
    "than just through a series of numbers."
   ],
   "id": "f3196b7b-df43-4fe4-998a-3bf22984c6e8"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thanks!\n",
    "\n",
    "For more information on these subjects and more you might want to check\n",
    "the following resources.\n",
    "\n",
    "-   book: [The Atomic\n",
    "    Human](https://www.penguin.co.uk/books/455130/the-atomic-human-by-lawrence-neil-d/9780241625248)\n",
    "-   twitter: [@lawrennd](https://twitter.com/lawrennd)\n",
    "-   podcast: [The Talking Machines](http://thetalkingmachines.com)\n",
    "-   newspaper: [Guardian Profile\n",
    "    Page](http://www.theguardian.com/profile/neil-lawrence)\n",
    "-   blog:\n",
    "    [http://inverseprobability.com](http://inverseprobability.com/blog.html)"
   ],
   "id": "4d017139-54c7-4365-97f3-19425bb7568f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ],
   "id": "75ed4c61-4b97-4a34-a056-b63ea5098c4d"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A brief history of time, 1988. Bantam Dell Publishing Group, London.\n",
    "\n",
    "Ananthanarayanan, R., Esser, S.K., Simon, H.D., Modha, D.S., 2009. The\n",
    "cat is out of the bag: Cortical simulations with $10^9$ neurons,\n",
    "$10^{13}$ synapses, in: Proceedings of the Conference on High\n",
    "Performance Computing Networking, Storage and Analysis - SC ’09.\n",
    "<https://doi.org/10.1145/1654059.1654124>\n",
    "\n",
    "Arora, S., Cohen, N., Golowich, N., Hu, W., 2019. [A convergence\n",
    "analysis of gradient descent for deep linear neural\n",
    "networks](https://openreview.net/forum?id=SkMQg3C5K7), in: International\n",
    "Conference on Learning Representations.\n",
    "\n",
    "Boltzmann, L., n.d. Über die Beziehung zwischen dem zweiten Hauptsatze\n",
    "der mechanischen Warmetheorie und der Wahrscheinlichkeitsrechnung,\n",
    "respective den Sätzen über das wärmegleichgewicht. Sitzungberichte der\n",
    "Kaiserlichen Akademie der Wissenschaften. Mathematisch-Naturwissen\n",
    "Classe. Abt. II LXXVI, 373–435.\n",
    "\n",
    "Bui, T., Hernandez-Lobato, D., Hernandez-Lobato, J., Li, Y., Turner, R.,\n",
    "2016. [Deep Gaussian processes for regression using approximate\n",
    "expectation propagation](http://proceedings.mlr.press/v48/bui16.html),\n",
    "in: Balcan, M.F., Weinberger, K.Q. (Eds.), Proceedings of the 33rd\n",
    "International Conference on Machine Learning, Proceedings of Machine\n",
    "Learning Research. PMLR, New York, New York, USA, pp. 1472–1481.\n",
    "\n",
    "Cabrera, C., Paleyes, A., Thodoroff, P., Lawrence, N.D., 2023.\n",
    "[Real-world machine learning systems: A survey from a data-oriented\n",
    "architecture perspective](https://arxiv.org/abs/2302.04810).\n",
    "\n",
    "Cho, Y., Saul, L.K., 2009. [Kernel methods for deep\n",
    "learning](http://papers.nips.cc/paper/3628-kernel-methods-for-deep-learning.pdf),\n",
    "in: Bengio, Y., Schuurmans, D., Lafferty, J.D., Williams, C.K.I.,\n",
    "Culotta, A. (Eds.), Advances in Neural Information Processing Systems\n",
    "22. Curran Associates, Inc., pp. 342–350.\n",
    "\n",
    "CMU Motion Capture Lab, 2003. The CMU mocap database.\n",
    "\n",
    "Coales, J.F., Kane, S.J., 2014. The “yellow peril” and after. IEEE\n",
    "Control Systems Magazine 34, 65–69.\n",
    "<https://doi.org/10.1109/MCS.2013.2287387>\n",
    "\n",
    "Damianou, A., 2015. Deep Gaussian processes and variational propagation\n",
    "of uncertainty (PhD thesis). University of Sheffield.\n",
    "\n",
    "Damianou, A., Lawrence, N.D., 2013. Deep Gaussian processes. pp.\n",
    "207–215.\n",
    "\n",
    "Damianou, A., Titsias, M.K., Lawrence, N.D., 2016. Variational inference\n",
    "for latent variables and uncertain inputs in Gaussian processes. Journal\n",
    "of Machine Learning Research 17.\n",
    "\n",
    "Della Gatta, G., Bansal, M., Ambesi-Impiombato, A., Antonini, D.,\n",
    "Missero, C., Bernardo, D. di, 2008. Direct targets of the TRP63\n",
    "transcription factor revealed by a combination of gene expression\n",
    "profiling and reverse engineering. Genome Research 18, 939–948.\n",
    "<https://doi.org/10.1101/gr.073601.107>\n",
    "\n",
    "Dunlop, M.M., Girolami, M.A., Stuart, A.M., Teckentrup, A.L., n.d. [How\n",
    "deep are deep Gaussian\n",
    "processes?](http://jmlr.org/papers/v19/18-015.html) Journal of Machine\n",
    "Learning Research 19, 1–46.\n",
    "\n",
    "Duvenaud, D., Rippel, O., Adams, R., Ghahramani, Z., 2014. Avoiding\n",
    "pathologies in very deep networks.\n",
    "\n",
    "Eddington, A.S., 1929. The nature of the physical world. Dent (London).\n",
    "<https://doi.org/10.2307/2180099>\n",
    "\n",
    "Ferris, B.D., Fox, D., Lawrence, N.D., 2007. WiFi-SLAM using Gaussian\n",
    "process latent variable models, in: Veloso, M.M. (Ed.), Proceedings of\n",
    "the 20th International Joint Conference on Artificial Intelligence\n",
    "(IJCAI 2007). pp. 2480–2485.\n",
    "\n",
    "Havasi, M., Hernández-Lobato, J.M., Murillo-Fuentes, J.J., 2018.\n",
    "[Inference in deep Gaussian processes using stochastic gradient\n",
    "Hamiltonian Monte\n",
    "Carlo](http://papers.nips.cc/paper/7979-inference-in-deep-gaussian-processes-using-stochastic-gradient-hamiltonian-monte-carlo.pdf),\n",
    "in: Bengio, S., Wallach, H., Larochelle, H., Grauman, K., Cesa-Bianchi,\n",
    "N., Garnett, R. (Eds.), Advances in Neural Information Processing\n",
    "Systems 31. Curran Associates, Inc., pp. 7506–7516.\n",
    "\n",
    "Heider, F., 1958. The psychology of interpersonal relations. John Wiley.\n",
    "\n",
    "Heider, F., Simmel, M., 1944. An experimental study of apparent\n",
    "behavior. The American Journal of Psychology 57, 243–259.\n",
    "<https://doi.org/10.2307/1416950>\n",
    "\n",
    "Henrich, J., Muthukrishna, M., 2021. The origins and psychology of human\n",
    "cooperation. Annual Review of Psychology 72, 207–240.\n",
    "<https://doi.org/10.1146/annurev-psych-081920-042106>\n",
    "\n",
    "Huang, W., Xia, F., Xiao, T., Chan, H., Liang, J., Florence, P., Zeng,\n",
    "A., Tompson, J., Mordatch, I., Chebotar, Y., Sermanet, P., Jackson, T.,\n",
    "Brown, N., Luu, L., Levine, S., Hausman, K., ichter, brian, 2023. [Inner\n",
    "monologue: Embodied reasoning through planning with language\n",
    "models](https://proceedings.mlr.press/v205/huang23c.html), in: Liu, K.,\n",
    "Kulic, D., Ichnowski, J. (Eds.), Proceedings of the 6th Conference on\n",
    "Robot Learning, Proceedings of Machine Learning Research. PMLR, pp.\n",
    "1769–1782.\n",
    "\n",
    "Izmailov, P., Maddox, W.J., Kirichenko, P., Garipov, T., Vetrov, D.P.,\n",
    "Wilson, A.G., 2019. [Subspace inference for bayesian deep\n",
    "learning](http://arxiv.org/abs/1907.07504). CoRR abs/1907.07504.\n",
    "\n",
    "Jacot, A., Ged, F., Gabriel, F., Şimşek, B., Hongler, C., 2021. [Deep\n",
    "linear networks dynamics: Low-rank biases induced by initialization\n",
    "scale and L2 regularization](https://arxiv.org/abs/2106.15933).\n",
    "\n",
    "Kalaitzis, A.A., Lawrence, N.D., 2011. A simple approach to ranking\n",
    "differentially expressed gene expression time courses through Gaussian\n",
    "process regression. BMC Bioinformatics 12.\n",
    "<https://doi.org/10.1186/1471-2105-12-180>\n",
    "\n",
    "Laplace, P.S., 1814. Essai philosophique sur les probabilités, 2nd ed.\n",
    "Courcier, Paris.\n",
    "\n",
    "Lawrence, N.D., 2024. The atomic human: Understanding ourselves in the\n",
    "age of AI. Allen Lane.\n",
    "\n",
    "Lawrence, N.D., 2017. [Living together: Mind and machine\n",
    "intelligence](https://arxiv.org/abs/1705.07996). arXiv.\n",
    "\n",
    "Lawrence, N.D., Moore, A.J., 2007. Hierarchical Gaussian process latent\n",
    "variable models. pp. 481–488.\n",
    "\n",
    "MacKay, D.J.C., n.d. Introduction to Gaussian processes. pp. 133–166.\n",
    "\n",
    "MacKay, D.M., 1991. Behind the eye. Basil Blackwell.\n",
    "\n",
    "Mikhailov, G.K., n.d. Daniel bernoulli, hydrodynamica (1738).\n",
    "\n",
    "O’Neill, O., 2002. A question of trust. Cambridge University Press.\n",
    "\n",
    "Reed, C., Durlach, N.I., 1998. Note on information transfer rates in\n",
    "human communication. Presence Teleoperators & Virtual Environments 7,\n",
    "509–518. <https://doi.org/10.1162/105474698565893>\n",
    "\n",
    "Salimbeni, H., Deisenroth, M., 2017. [Doubly stochastic variational\n",
    "inference for deep Gaussian\n",
    "processes](http://papers.nips.cc/paper/7045-doubly-stochastic-variational-inference-for-deep-gaussian-processes.pdf),\n",
    "in: Guyon, I., Luxburg, U.V., Bengio, S., Wallach, H., Fergus, R.,\n",
    "Vishwanathan, S., Garnett, R. (Eds.), Advances in Neural Information\n",
    "Processing Systems 30. Curran Associates, Inc., pp. 4591–4602.\n",
    "\n",
    "Sharp, K., Matschinsky, F., 2015. Translation of Ludwig Boltzmann’s\n",
    "paper “on the relationship between the second fundamental theorem of the\n",
    "mechanical theory of heat and probability calculations regarding the\n",
    "conditions for thermal equilibrium.” Entropy 17, 1971–2009.\n",
    "<https://doi.org/10.3390/e17041971>\n",
    "\n",
    "Simons, D.J., Chabris, C.F., 1999. Gorillas in our midst: Sustained\n",
    "inattentional blindness for dynamic events. Perception 28, 1059–1074.\n",
    "<https://doi.org/10.1068/p281059>\n",
    "\n",
    "Susskind, R.E., Susskind, D., 2015. The future of the professions: How\n",
    "technology will transform the work of human experts. Oxford University\n",
    "Press.\n",
    "\n",
    "Taigman, Y., Yang, M., Ranzato, M., Wolf, L., 2014. DeepFace: Closing\n",
    "the gap to human-level performance in face verification, in: Proceedings\n",
    "of the IEEE Computer Society Conference on Computer Vision and Pattern\n",
    "Recognition. <https://doi.org/10.1109/CVPR.2014.220>\n",
    "\n",
    "The Admiralty, 1945. [The gunnery pocket book, b.r.\n",
    "224/45](https://www.maritime.org/doc/br224/).\n",
    "\n",
    "Thompson, W.C., 1989. [Are juries competent to evaluate statistical\n",
    "evidence?](http://www.jstor.org/stable/1191906) Law and Contemporary\n",
    "Problems 52, 9–41.\n",
    "\n",
    "Wiener, N., 1953. Ex-prodigy: My childhood and youth. mitp, Cambridge,\n",
    "MA.\n",
    "\n",
    "Wiener, N., 1949. The extrapolation, interpolation and smoothing of\n",
    "stationary time series with engineering applications. wiley."
   ],
   "id": "a652a96f-57f7-46bf-8467-89cf0aaa3fa2"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}

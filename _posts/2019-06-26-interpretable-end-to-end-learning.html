---
title: "Interpretable End-to-End Learning"
venue: "Sheffield ML Group Research Retreat"
abstract: "Practical artificial intelligence systems can be seen as algorithmic decision makers. The fractal nature of decision making implies that this involves interacting systems of components where decisions are made multiple times across different time frames. This affects the decomposability of an artificial intelligence system. Classical systems design relies on decomposability for efficient maintenance and deployment of machine learning systems, in this talk we consider the challenges of optimizing and maintaining such systems."
author:
- given: Neil D.
  family: Lawrence
  url: http://inverseprobability.com
  institute: Amazon Cambridge and University of Sheffield
  twitter: lawrennd
  gscholar: r3SJcvoAAAAJ
  orchid: 
date: 2019-06-26
published: 2019-06-26
reveal: 2019-06-26-interpretable-end-to-end-learning.slides.html
ipynb: 2019-06-26-interpretable-end-to-end-learning.ipynb
layout: talk
categories:
- notes
---


<div style="display:none">
  $${% include talk-notation.tex %}$$
</div>

<script src="/talks/figure-magnify.js"></script>
<script src="/talks/figure-animate.js"></script>
    
<div id="modal-frame" class="modal">
  <span class="close" onclick="closeMagnify()">&times;</span>
  <div class="modal-figure">
    <div class="figure-frame">
      <div class="modal-content" id="modal01"></div>
      <!--<img class="modal-content" id="object01">-->
    </div>
    <div class="caption-frame" id="modal-caption"></div>
  </div>
</div>	  

<!-- Front matter -->
<!-- Front matter -->
<!-- Do not edit this file locally. -->
<!-- Do not edit this file locally. -->
<!---->
<!-- Do not edit this file locally. -->
<!--Back matter-->
<!-- Do not edit this file locally. -->
<!-- The last names to be defined. Should be defined entirely in terms of macros from above-->
<h1 id="introduction">Introduction</h1>
<p>The fourth industrial revolution bears the particular hallmark of being the first revolution that has been named before it has happened. This is particularly unfortunate, because it is not in fact an industrial revolution at all. Nor is it necessarily a distinct phenomenon. It is part of a revolution in information, one that goes back to digitisation and the invention of the silicon chip.</p>
<p>Or to put it more precisely, it is a revolution in how information can affect the physical world. The interchange between information and the physical world.</p>
<h2 id="amazons-new-delivery-drone-edit">Amazon’s New Delivery Drone <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ai/includes/amazon-delivery-drone.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ai/includes/amazon-delivery-drone.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<div class="figure">
<div id="delivery-drone-figure" class="figure-frame">
<iframe width="800" height="600" src="https://www.youtube.com/embed/3HJtmx5f1Fc?start=" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen>
</iframe>
</div>
<div id="delivery-drone-magnify" class="magnify" onclick="magnifyFigure(&#39;delivery-drone&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="delivery-drone-caption" class="caption-frame">
<p>Figure: Amazon’s new delivery drone. Machine learning algorithms are used across various systems including sensing (computer vision for detection of wires, people, dogs etc) and piloting. The technology is necessarily a combination of old and new ideas.</p>
</div>
</div>
<h2 id="machine-learning-in-supply-chain-edit">Machine Learning in Supply Chain <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_supply-chain/includes/supply-chain.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_supply-chain/includes/supply-chain.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<div class="figure">
<div id="packhorse-bridge-burbage-brook-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/supply-chain/packhorse-bridge-burbage-brook.jpg" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="packhorse-bridge-burbage-brook-magnify" class="magnify" onclick="magnifyFigure(&#39;packhorse-bridge-burbage-brook&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="packhorse-bridge-burbage-brook-caption" class="caption-frame">
<p>Figure: Packhorse Bridge under Burbage Edge. This packhorse route climbs steeply out of Hathersage and heads towards Sheffield. Packhorses were the main route for transporting goods across the Peak District. The high cost of transport is one driver of the ‘smith’ model, where there is a local skilled person responsible for assembling or creating goods (e.g. a blacksmith).</p>
</div>
</div>
<p>On Sunday mornings in Sheffield, I often used to run across Packhorse Bridge in Burbage valley. The bridge is part of an ancient network of trails crossing the Pennines that, before Turnpike roads arrived in the 18th century, was the main way in which goods were moved. Given that the moors around Sheffield were home to sand quarries, tin mines, lead mines and the villages in the Derwent valley were known for nail and pin manufacture, this wasn’t simply movement of agricultural goods, but it was the infrastructure for industrial transport.</p>
<p>The profession of leading the horses was known as a Jagger and leading out of the village of Hathersage is Jagger’s Lane, a trail that headed underneath Stanage Edge and into Sheffield.</p>
<p>The movement of goods from regions of supply to areas of demand is fundamental to our society. The physical infrastructure of supply chain has evolved a great deal over the last 300 years.</p>
<div class="figure">
<div id="cromford-mill-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/supply-chain/cromford-mill.jpg" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="cromford-mill-magnify" class="magnify" onclick="magnifyFigure(&#39;cromford-mill&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="cromford-mill-caption" class="caption-frame">
<p>Figure: Richard Arkwright is regarded of the founder of the modern factory system. Factories exploit distribution networks to centralize production of goods. Arkwright located his factory in Cromford due to proximity to Nottingham Weavers (his market) and availability of water power from the tributaries of the Derwent river. When he first arrived there was almost no transportation network. Over the following 200 years The Cromford Canal (1790s), a Turnpike (now the A6, 1816-18) and the High Peak Railway (now closed, 1820s) were all constructed to improve transportation access as the factory blossomed.</p>
</div>
</div>
<p>Richard Arkwright is known as the father of the modern factory system. In 1771 he set up a Mill for spinning cotton yarn in the village of Cromford, in the Derwent Valley. The Derwent valley is relatively inaccessible. Raw cotton arrived in Liverpool from the US and India. It needed to be transported on packhorse across the bridleways of the Pennines. But Cromford was a good location due to proximity to Nottingham, where weavers where consuming the finished thread, and the availability of water power from small tributaries of the Derwent river for Arkwright’s <a href="https://en.wikipedia.org/wiki/Spinning_jenny">water frames</a> which automated the production of yarn from raw cotton.</p>
<p>By 1794 the Cromford canal was opened to bring coal in to Cromford and give better transport to Nottingham. The construction of the canals was driven by the need to improve the transport infrastructure, facilitating the movement of goods across the UK. Canals, roads and railways were initially constructed by the economic need for moving goods. To improve supply chain.</p>
<h2 id="containerization-edit">Containerization <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_supply-chain/includes/containerisation.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_supply-chain/includes/containerisation.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<div class="figure">
<div id="container-2539942_1920-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/supply-chain/container-2539942_1920.jpg" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="container-2539942_1920-magnify" class="magnify" onclick="magnifyFigure(&#39;container-2539942_1920&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="container-2539942_1920-caption" class="caption-frame">
<p>Figure: The container is one of the major drivers of globalization, and arguably the largest agent of social change in the last 100 years. It reduces the cost of transportation, significantly changing the appropriate topology of distribution networks. The container makes it possible to ship goods halfway around the world for cheaper than it costs to process those goods, leading to an extended distribution topology.</p>
</div>
</div>
<p>Containerization has had a dramatic effect on global economics, placing many people in the developing world at the end of the supply chain.</p>
<div class="figure">
<div id="wild-alaskan-cod-figure" class="figure-frame">
<table>
<tr>
<td width="45%">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/supply-chain/wild-alaskan-cod.jpg" width="90%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
<td width="45%">
<div class="centered centered" style="">
<img class="" src="../slides/diagrams/supply-chain/wild-alaskan-cod-made-in-china.jpg" width="90%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
</tr>
</table>
</div>
<div id="wild-alaskan-cod-magnify" class="magnify" onclick="magnifyFigure(&#39;wild-alaskan-cod&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="wild-alaskan-cod-caption" class="caption-frame">
<p>Figure: Wild Alaskan Cod, being solid in the Pacific Northwest, that is a product of China. It is cheaper to ship the deep frozen fish thousands of kilometers for processing than to process locally.</p>
</div>
</div>
<p>For example, you can buy Wild Alaskan Cod fished from Alaska, processed in China, sold in North America. This is driven by the low cost of transport for frozen cod vs the higher relative cost of cod processing in the US versus China. Similarly, <a href="https://www.telegraph.co.uk/news/uknews/1534286/12000-mile-trip-to-have-seafood-shelled.html" target="_blank" >Scottish prawns are also processed in China for sale in the UK.</a></p>
<p>This effect on cost of transport vs cost of processing is the main driver of the topology of the modern supply chain and the associated effect of globalization. If transport is much cheaper than processing, then processing will tend to agglomerate in places where processing costs can be minimized.</p>
<p>Large scale global economic change has principally been driven by changes in the technology that drives supply chain.</p>
<p>Supply chain is a large-scale automated decision making network. Our aim is to make decisions not only based on our models of customer behavior (as observed through data), but also by accounting for the structure of our fulfilment center, and delivery network.</p>
<p>Many of the most important questions in supply chain take the form of counterfactuals. E.g. “What would happen if we opened a manufacturing facility in Cambridge?” A counter factual is a question that implies a mechanistic understanding of a system. It goes beyond simple smoothness assumptions or translation invariants. It requires a physical, or <em>mechanistic</em> understanding of the supply chain network. For this reason, the type of models we deploy in supply chain often involve simulations or more mechanistic understanding of the network.</p>
<p>In supply chain Machine Learning alone is not enough, we need to bridge between models that contain real mechanisms and models that are entirely data driven.</p>
<p>This is challenging, because as we introduce more mechanism to the models we use, it becomes harder to develop efficient algorithms to match those models to data.</p>
<div class="figure">
<div id="supply-chain-optimization-team-figure" class="figure-frame">
<iframe width="800" height="600" src="https://www.youtube.com/embed/ncwsr1Of6Cw?start=" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen>
</iframe>
</div>
<div id="supply-chain-optimization-team-magnify" class="magnify" onclick="magnifyFigure(&#39;supply-chain-optimization-team&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="supply-chain-optimization-team-caption" class="caption-frame">
<p>Figure: The Supply Chain Optimization Team (SCOT) at Amazon is responsible for the automated decision making in (probably) the world’s largest AI.</p>
</div>
</div>
<blockquote>
<p>Solve Supply Chain, then solve everything else.</p>
</blockquote>
<h1 id="end-to-end-environment-and-decision-edit">End-to-End: Environment and Decision <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/interpretable-end-to-end-learning.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/interpretable-end-to-end-learning.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h1>
<h2 id="from-model-to-decision-edit">From Model to Decision <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/what-is-ml-end-to-end.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/what-is-ml-end-to-end.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<p>The real challenge, however, is end-to-end decision making. Taking information from the environment and using it to drive decision making to achieve goals.</p>
<div class="figure">
<div id="experiment-analyze-design-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/ml/experiment-analyze-design.svg" width="50%" style=" ">
</object>
</div>
<div id="experiment-analyze-design-magnify" class="magnify" onclick="magnifyFigure(&#39;experiment-analyze-design&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="experiment-analyze-design-caption" class="caption-frame">
<p>Figure: The experiment, analyze, design flywheel for scientific innovation.</p>
</div>
</div>
<blockquote>
<p>We don’t know what science we’ll want to do in 5 years time, but we won’t want slower experiments, we won’t want more expensive experiments and we won’t want a narrower selection of experiments.</p>
</blockquote>
<ul>
<li>Faster, cheaper and more diverse experiments.</li>
<li>Better ecosystems for experimentation.</li>
<li>Data oriented architectures.</li>
</ul>
<h2 id="data-oriented-architectures-edit">Data Oriented Architectures <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_data-science/includes/data-oriented-architectures.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_data-science/includes/data-oriented-architectures.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<p>In a streaming architecture we shift from management of services, to management of data streams. Instead of worrying about availability of the services we shift to worrying about the quality of the data those services are producing.</p>
<h2 id="streaming-system">Streaming System</h2>
<p>Characteristics of a streaming system include a move from <em>pull</em> updates to <em>push</em> updates, i.e. the computation is driven by a change in the input data rather than the service calling for input data when it decides to run a computation. Streaming systems operate on ‘rows’ of the data rather than ‘columns’. This is because the full column isn’t normally available as it changes over time. As an important design principle, the services themselves are stateless, they take their state from the streaming ecosystem. This ensures the inputs and outputs of given computations are easy to declare. As a result, persistence of the data is also handled by the streaming ecosystem and decisions around data retention or recomputation can be taken at the systems level rather than the component level.</p>
<h2 id="apache-flink-edit">Apache Flink <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_data-science/includes/apache-flink.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_data-science/includes/apache-flink.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<p><a href="https://en.wikipedia.org/wiki/Apache_Flink">Apache Flink</a> is a stream processing framework. Flink is a foundation for event driven processing. This gives a high throughput and low latency framework that operates on dataflows.</p>
<p>Data storage is handled by other systems such as Apache Kafka or AWS Kinesis.</p>
<pre><code>stream.join(otherStream)
    .where(&lt;KeySelector&gt;)
    .equalTo(&lt;KeySelector&gt;)
    .window(&lt;WindowAssigner&gt;)
    .apply(&lt;JoinFunction&gt;)</code></pre>
<p>Apache Flink allows operations on streams. For example, the join operation above. In a traditional data base management system, this join operation may be written in SQL and called on demand. In a streaming ecosystem, computations occur as and when the streams update.</p>
<p>The join is handled by the ecosystem surrounding the business logic.</p>
<h2 id="trading-system">Trading System</h2>
<p>As a simple example we’ll consider a high frequency trading system. Anne wishes to build a share trading system. She has access to a high frequency trading system which provides prices and allows trades at millisecond intervals. She wishes to build an automated trading system.</p>
<p>Let’s assume that price trading data is available as a data stream. But the price now is not the only information that Anne needs, she needs an estimate of the price in the future.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb2-1" data-line-number="1"><span class="im">import</span> pandas <span class="im">as</span> pd</a>
<a class="sourceLine" id="cb2-2" data-line-number="2"><span class="im">import</span> numpy <span class="im">as</span> np</a>
<a class="sourceLine" id="cb2-3" data-line-number="3"><span class="im">import</span> os</a></code></pre></div>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb3-1" data-line-number="1"><span class="co"># Generate an artificial trading stream</span></a>
<a class="sourceLine" id="cb3-2" data-line-number="2">days<span class="op">=</span>pd.date_range(start<span class="op">=</span><span class="st">&#39;21/5/2017&#39;</span>, end<span class="op">=</span><span class="st">&#39;21/05/2020&#39;</span>)</a>
<a class="sourceLine" id="cb3-3" data-line-number="3">z <span class="op">=</span> np.random.randn(<span class="bu">len</span>(days), <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb3-4" data-line-number="4">x <span class="op">=</span> z.cumsum()<span class="op">+</span><span class="dv">400</span></a></code></pre></div>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb4-1" data-line-number="1">prices <span class="op">=</span> pd.Series(x, index<span class="op">=</span>days)</a>
<a class="sourceLine" id="cb4-2" data-line-number="2">hypothetical <span class="op">=</span> prices.loc[<span class="st">&#39;21/5/2019&#39;</span>:]</a>
<a class="sourceLine" id="cb4-3" data-line-number="3">real <span class="op">=</span> prices.copy()</a>
<a class="sourceLine" id="cb4-4" data-line-number="4">real[<span class="st">&#39;21/5/2019&#39;</span>:] <span class="op">=</span> np.NaN</a></code></pre></div>
<div class="figure">
<div id="hypothetical-prices-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/data-science/hypothetical-prices.svg" width="80%" style=" ">
</object>
</div>
<div id="hypothetical-prices-magnify" class="magnify" onclick="magnifyFigure(&#39;hypothetical-prices&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="hypothetical-prices-caption" class="caption-frame">
<p>Figure: Anne has access to the share prices in the black stream but not in the blue stream. A hypothetical stream is the stream of future prices. Anne can define this hypothetical under constraints (latency, input etc). The need for a model is now exposed in the software infrastructure</p>
</div>
</div>
<h2 id="hypothetical-streams">Hypothetical Streams</h2>
<p>We’ll call the future price a hypothetical stream.</p>
<p>A hypothetical stream is a desired stream of information which cannot be directly accessed. The lack of direct access may be because the events happen in the future, or there may be some latency between the event and the availability of the data.</p>
<p>Any hypothetical stream will only be provided as a prediction, ideally with an error bar.</p>
<p>The nature of the hypothetical Anne needs is dependent on her decision-making process. In Anne’s case it will depend over what period she is expecting her returns. In MDOP Anne specifies a hypothetical that is derived from the pricing stream.</p>
<p>It is not the price stream directly, but Anne looks for <em>future</em> predictions from the price stream, perhaps for price in <span class="math inline"><em>T</em></span> days’ time.</p>
<p>At this stage, this stream is merely typed as a hypothetical.</p>
<p>There are constraints on the hypothetical, they include: the <em>input</em> information, the upper limit of latency between input and prediction, and the decision Anne needs to make (how far ahead, what her upside, downside risks are). These three constraints mean that we can only recover an approximation to the hypothetical.</p>
<h2 id="hypothetical-advantage">Hypothetical Advantage</h2>
<p>What is the advantage to defining things in this way? By defining, clearly, the two streams as real and hypothetical variants of each other, we now enable automation of the deployment and any redeployment process. The hypothetical can be <em>instantiated</em> against the real, and design criteria can be constantly evaluated triggering retraining when necessary.</p>
<h2 id="ride-sharing-system">Ride Sharing System</h2>
<p>As a second example, we’ll consider a ride sharing app.</p>
<p>Anne is on her way home now; she wishes to hail a car using a ride sharing app.</p>
<p>The app is designed in the following way. On opening her app Anne is notified about driverss in the nearby neighborhood. She is given an estimate of the time a ride may take to come.</p>
<p>Given this information about driver availability, Anne may feel encouraged to enter a destination. Given this destination, a price estimate can be given. This price is conditioned on other riders that may wish to go in the same direction, but the price estimate needs to be made before the user agrees to the ride.</p>
<p>Business customer service constraints dictate that this price may not change after Anne’s order is confirmed.</p>
<p>In this simple system, several decisions are being made, each of them on the basis of a hypothetical.</p>
<p>When Anne calls for a ride, she is provided with an estimate based on the expected time a ride can be with her. But this estimate is made without knowing where Anne wants to go. There are constraints on drivers imposed by regional boundaries, reaching the end of their shift, or their current passengers mean that this estimate can only be a best guess.</p>
<p>This best guess may well be driven by previous data.</p>
<div class="figure">
<div id="ride-share-service-soa-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/data-science/ride-share-service-soa.svg" width="80%" style=" ">
</object>
</div>
<div id="ride-share-service-soa-magnify" class="magnify" onclick="magnifyFigure(&#39;ride-share-service-soa&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="ride-share-service-soa-caption" class="caption-frame">
<p>Figure: Service oriented architecture. The data access is buried in the cost allocation service. Data dependencies of the service cannot be found without trawling through the underlying code base.</p>
</div>
</div>
<div class="figure">
<div id="ride-share-service-doa-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/data-science/ride-share-service-doa.svg" width="80%" style=" ">
</object>
</div>
<div id="ride-share-service-doa-magnify" class="magnify" onclick="magnifyFigure(&#39;ride-share-service-doa&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="ride-share-service-doa-caption" class="caption-frame">
<p>Figure: Data oriented architecture. Now the joins and the updates are exposed within the streaming ecosystem. We can programatically determine the factor graph which gives the thread through the model.</p>
</div>
</div>
<div class="figure">
<div id="ride-share-service-doa-hypothetical-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/data-science/ride-share-service-doa-hypothetical.svg" width="80%" style=" ">
</object>
</div>
<div id="ride-share-service-doa-hypothetical-magnify" class="magnify" onclick="magnifyFigure(&#39;ride-share-service-doa-hypothetical&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="ride-share-service-doa-hypothetical-caption" class="caption-frame">
<p>Figure: Data-oriented programing. There is a requirement for an estimate of the driver allocation to give a rough cost estimate before the user has confirmed the ride. In data-oriented programming, this is achieved through declaring a hypothetical stream which approximates the true driver allocation, but with restricted input information and constraints on the computational latency.</p>
</div>
</div>
<p>For the ride sharing system, we start to see a common issue with a more complex algorithmic decision-making system. Several decisions are being made multilple times. Let’s look at the decisions we need along with some design criteria.</p>
<ol type="1">
<li>Car Availability: Estimate time to arrival for Anne’s ride using Anne’s location and local available car locations. Latency 50 milliseconds</li>
<li>Cost Estimate: Estimate cost for journey using Anne’s destination, location and local available car current destinations and availability. Latency 50 milliseconds</li>
<li>Driver Allocation: Allocate car to minimize transport cost to destination. Latency 2 seconds.</li>
</ol>
<p>So we need:</p>
<ol type="1">
<li>a hypothetical to estimate availability. It is constrained by lacking destination information and a low latency requirement.</li>
<li>a hypothetical to estimate cost. It is constrained by low latency requirement and</li>
</ol>
<p>Simultaneously, drivers in this data ecosystem have an app which notifies them about new jobs and recommends them where to go.</p>
<p>Further advantages. Strategies for data retention (when to snapshot) can be set globally.</p>
<p>A few decisions need to be made in this system. First of all, when the user opens the app, the estimate of the time to the nearest ride may need to be computed quickly, to avoid latency in the service.</p>
<p>This may require a quick estimate of the ride availability.</p>
<h2 id="information-dynamics">Information Dynamics</h2>
<p>With all the second guessing within a complex automated decision-making system, there are potential problems with information dynamics, the ‘closed loop’ problem, where the sub-systems are being approximated (second guessing) and predictions downstream are being affected.</p>
<p>This leads to the need for a closed loop analysis, for example, see the <a href="https://www.gla.ac.uk/schools/computing/research/researchsections/ida-section/closedloop/">“Closed Loop Data Science”</a> project led by Rod Murray-Smith at Glasgow.</p>
<p>Our aim is to release our first version of a data-oriented programming environment by end of June 2019 (pending internal approval).</p>
<div class="figure">
<div id="ride-allocation-system-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/ai/ride-allocation-prediction.svg" width="60%" style=" ">
</object>
</div>
<div id="ride-allocation-system-magnify" class="magnify" onclick="magnifyFigure(&#39;ride-allocation-system&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="ride-allocation-system-caption" class="caption-frame">
<p>Figure: Some software components in a ride allocation system. Circled components are hypothetical, rectangles represent actual data.</p>
</div>
</div>
<div class="figure">
<div id="ml-system-downstream-pedestrain-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/ai/ml-system-downstream-pedestrian000.svg" width="80%" style=" ">
</object>
</div>
<div id="ml-system-downstream-pedestrain-magnify" class="magnify" onclick="magnifyFigure(&#39;ml-system-downstream-pedestrain&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="ml-system-downstream-pedestrain-caption" class="caption-frame">
<p>Figure: A potential path of models in a machine learning system.</p>
</div>
</div>
<h2 id="emulation-edit">Emulation <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/emulation.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/emulation.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<div class="figure">
<div id="statistical-emulation-1-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/uq/statistical-emulation000.svg" width="80%" style=" ">
</object>
</div>
<div id="statistical-emulation-1-magnify" class="magnify" onclick="magnifyFigure(&#39;statistical-emulation-1&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="statistical-emulation-1-caption" class="caption-frame">
<p>Figure: Real world systems consiste of simulators, that capture our domain knowledge about how our systems operate. Different simulators run at different speeds and granularities.</p>
</div>
</div>
<p>In many real world systems, decisions are made through simulating the environment. Simulations may operate at different granularities. For example, simulations are used in weather forecasts and climate forecasts. The UK Met office uses the same code for both, but operates climate simulations one at greater spatial and temporal resolutions.</p>
<div class="figure">
<div id="statistical-emulation-2-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/uq/statistical-emulation001.svg" width="80%" style=" ">
</object>
</div>
<div id="statistical-emulation-2-magnify" class="magnify" onclick="magnifyFigure(&#39;statistical-emulation-2&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="statistical-emulation-2-caption" class="caption-frame">
<p>Figure: A statistical emulator is a system that reconstructs the simulation with a statistical model.</p>
</div>
</div>
<p>A statistical emulator is a data-driven model that learns about the underlying simulation. Importantly, learns with uncertainty, so it ‘knows what it doesn’t know’. In practice, we can call the emulator in place of the simulator. If the emulator ‘doesn’t know’, it can call the simulator for the answer.</p>
<div class="figure">
<div id="statistical-emulation-5-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/uq/statistical-emulation004.svg" width="80%" style=" ">
</object>
</div>
<div id="statistical-emulation-5-magnify" class="magnify" onclick="magnifyFigure(&#39;statistical-emulation-5&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="statistical-emulation-5-caption" class="caption-frame">
<p>Figure: A statistical emulator is a system that reconstructs the simulation with a statistical model. As well as reconstructing the simulation, a statistical emulator can be used to correlate with the real world.</p>
</div>
</div>
<div class="figure">
<div id="statistical-emulation-6-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/uq/statistical-emulation005.svg" width="80%" style=" ">
</object>
</div>
<div id="statistical-emulation-6-magnify" class="magnify" onclick="magnifyFigure(&#39;statistical-emulation-6&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="statistical-emulation-6-caption" class="caption-frame">
<p>Figure: In modern machine learning system design, the emulator may also consider the output of ML models (for monitoring bias or accuracy) and Operations Research models..</p>
</div>
</div>
<p>As well as reconstructing an individual simulator, the emulator can calibrate the simulation to the real world, by monitoring differences between the simulator and real data. This allows the emulator to characterise where the simulation can be relied on, i.e. we can validate the simulator.</p>
<p>Similarly, the emulator can adjudicate between simulations. This is known as <em>multi-fidelity emulation</em>. The emulator characterizes which emulations perform well where.</p>
<p>If all this modelling is done with judiscious handling of the uncertainty, the <em>computational doubt</em>, then the emulator can assist in desciding what experiment should be run next to aid a decision: should we run a simulator, in which case which one, or should we attempt to acquire data from a real world intervention.</p>
<div class="figure">
<div id="ml-system-downstream-pedestrain-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/ai/ml-system-downstream-pedestrian000.svg" width="80%" style=" ">
</object>
</div>
<div id="ml-system-downstream-pedestrain-magnify" class="magnify" onclick="magnifyFigure(&#39;ml-system-downstream-pedestrain&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="ml-system-downstream-pedestrain-caption" class="caption-frame">
<p>Figure: A potential path of models in a machine learning system.</p>
</div>
</div>
<div class="figure">
<div id="ml-system-downstream-pedestrain-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/ai/ml-system-downstream-pedestrian001.svg" width="80%" style=" ">
</object>
</div>
<div id="ml-system-downstream-pedestrain-magnify" class="magnify" onclick="magnifyFigure(&#39;ml-system-downstream-pedestrain&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="ml-system-downstream-pedestrain-caption" class="caption-frame">
<p>Figure: A potential path of models in a machine learning system.</p>
</div>
</div>
<div class="figure">
<div id="ml-system-downstream-pedestrain-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/ai/ml-system-downstream-pedestrian.svg" width="80%" style=" ">
</object>
</div>
<div id="ml-system-downstream-pedestrain-magnify" class="magnify" onclick="magnifyFigure(&#39;ml-system-downstream-pedestrain&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="ml-system-downstream-pedestrain-caption" class="caption-frame">
<p>Figure: A potential path of models in a machine learning system.</p>
</div>
</div>
<ul>
<li>Aim: maintain interpretable compoents.</li>
<li>Monitor downstream/upstream effects through emulation.</li>
<li>Optimize individual components considering upstream and downstream.</li>
</ul>
<h3 id="deepface-edit">DeepFace <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/deep-face.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/deep-face.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h3>
<div class="figure">
<div id="deep-face-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="../slides/diagrams/deepface_neg.png" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="deep-face-magnify" class="magnify" onclick="magnifyFigure(&#39;deep-face&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="deep-face-caption" class="caption-frame">
<p>Figure: The DeepFace architecture <span class="citation" data-cites="Taigman:deepface14">(Taigman et al. 2014)</span>, visualized through colors to represent the functional mappings at each layer. There are 120 million parameters in the model.</p>
</div>
</div>
<p>The DeepFace architecture <span class="citation" data-cites="Taigman:deepface14">(Taigman et al. 2014)</span> consists of layers that deal with <em>translation</em> and <em>rotational</em> invariances. These layers are followed by three locally-connected layers and two fully-connected layers. Color illustrates feature maps produced at each layer. The neural network includes more than 120 million parameters, where more than 95% come from the local and fully connected layers.</p>
<!--



### Deep Learning as Pinball <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/deep-learning-as-pinball.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/deep-learning-as-pinball.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>

<div class="figure">
<div class="figure-frame" id="early-pinball-figure">
<div class="centered centered" style=""><img class="" src="../slides/diagrams/576px-Early_Pinball.jpg" width="50%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle"></div>
</div>
<div class="magnify" id="early-pinball-magnify" onclick="magnifyFigure('early-pinball')">
<img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex">
</div>
<div class="caption-frame" id="early-pinball-caption">
Figure: Deep learning models are composition of simple functions. We can think of a pinball machine as an analogy. Each layer of pins corresponds to one of the layers of functions in the model. Input data is represented by the location of the ball from left to right when it is dropped in from the top. Output class comes from the position of the ball as it leaves the pins at the bottom.
</div>
</div>

Sometimes deep learning models are described as being like the brain, or too complex to understand, but one analogy I find useful to help the gist of these models is to think of them as being similar to early pin ball machines. 

In a deep neural network, we input a number (or numbers), whereas in pinball, we input a ball. 

Think of the location of the ball on the left-right axis as a single number. Our simple pinball machine can only take one number at a time. As the ball falls through the machine, each layer of pins can be thought of as a different layer of 'neurons'. Each layer acts to move the ball from left to right. 

In a pinball machine, when the ball gets to the bottom it might fall into a hole defining a score, in a neural network, that is equivalent to the decision: a classification of the input object. 

An image has more than one number associated with it, so it is like playing pinball in a *hyper-space*.

```{.python}
import pods
from ipywidgets import IntSlider
```
```{.python}
pods.notebook.display_plots('pinball{sample:0>3}.svg', 
                            '../slides/diagrams',
                            sample=IntSlider(1, 1, 2, 1))
```



<div class="figure">
<div class="figure-frame" id="pinball-initialization-figure">
<object class="svgplot " data="../slides/diagrams/pinball001.svg" width="80%" style=" "></object>
</div>
<div class="magnify" id="pinball-initialization-magnify" onclick="magnifyFigure('pinball-initialization')">
<img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex">
</div>
<div class="caption-frame" id="pinball-initialization-caption">
Figure: At initialization, the pins, which represent the parameters of the function, aren't in the right place to bring the balls to the correct decisions.
</div>
</div>



<div class="figure">
<div class="figure-frame" id="pinball-trained-figure">
<object class="svgplot " data="../slides/diagrams/pinball002.svg" width="80%" style=" "></object>
</div>
<div class="magnify" id="pinball-trained-magnify" onclick="magnifyFigure('pinball-trained')">
<img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex">
</div>
<div class="caption-frame" id="pinball-trained-caption">
Figure: After learning the pins are now in the right place to bring the balls to the correct decisions.
</div>
</div>

Learning involves moving all the pins to be in the correct position, so that the ball ends up in the right place when it's fallen through the machine. But moving all these pins in hyperspace can be difficult. 

In a hyper-space you have to put a lot of data through the machine for to explore the positions of all the pins. Even when you feed many millions of data points through the machine, there are likely to be regions in the hyper-space where no ball has passed. When future test data passes through the machine in a new route unusual things can happen.

*Adversarial examples* exploit this high dimensional space. If you have access to the pinball machine, you can use gradient methods to find a position for the ball in the hyper space where the image looks like one thing, but will be classified as another.

Probabilistic methods explore more of the space by considering a range of possible paths for the ball through the machine. This helps to make them more data efficient and gives some robustness to adversarial examples.


-->
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb5-1" data-line-number="1"><span class="im">import</span> teaching_plots <span class="im">as</span> plot</a></code></pre></div>
<div class="figure">
<div id="deep-neural-network-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/deepgp/deep-nn2.svg" width="70%" style=" ">
</object>
</div>
<div id="deep-neural-network-magnify" class="magnify" onclick="magnifyFigure(&#39;deep-neural-network&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="deep-neural-network-caption" class="caption-frame">
<p>Figure: A deep neural network. Input nodes are shown at the bottom. Each hidden layer is the result of applying an affine transformation to the previous layer and placing through an activation function.</p>
</div>
</div>
<p>Mathematically, each layer of a neural network is given through computing the activation function, <span class="math inline">$\basisFunction(\cdot)$</span>, contingent on the previous layer, or the inputs. In this way the activation functions, are composed to generate more complex interactions than would be possible with any single layer. <br /><span class="math display">$$
\begin{align}
    \hiddenVector_{1} &amp;= \basisFunction\left(\mappingMatrix_1 \inputVector\right)\\
    \hiddenVector_{2} &amp;=  \basisFunction\left(\mappingMatrix_2\hiddenVector_{1}\right)\\
    \hiddenVector_{3} &amp;= \basisFunction\left(\mappingMatrix_3 \hiddenVector_{2}\right)\\
    \dataVector &amp;= \mappingVector_4 ^\top\hiddenVector_{3}
\end{align}
$$</span><br /></p>
<h2 id="overfitting-edit">Overfitting <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_deepgp/includes/overfitting-low-rank.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_deepgp/includes/overfitting-low-rank.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<p>One potential problem is that as the number of nodes in two adjacent layers increases, the number of parameters in the affine transformation between layers, <span class="math inline">$\mappingMatrix$</span>, increases. If there are <span class="math inline"><em>k</em><sub><em>i</em> − 1</sub></span> nodes in one layer, and <span class="math inline"><em>k</em><sub><em>i</em></sub></span> nodes in the following, then that matrix contains <span class="math inline"><em>k</em><sub><em>i</em></sub><em>k</em><sub><em>i</em> − 1</sub></span> parameters, when we have layer widths in the 1000s that leads to millions of parameters.</p>
<p>One proposed solution is known as <em>dropout</em> where only a sub-set of the neural network is trained at each iteration. An alternative solution would be to reparameterize <span class="math inline">$\mappingMatrix$</span> with its <em>singular value decomposition</em>. <br /><span class="math display">$$
  \mappingMatrix = \eigenvectorMatrix\eigenvalueMatrix\eigenvectwoMatrix^\top
  $$</span><br /> or <br /><span class="math display">$$
  \mappingMatrix = \eigenvectorMatrix\eigenvectwoMatrix^\top
  $$</span><br /> where if <span class="math inline">$\mappingMatrix \in \Re^{k_1\times k_2}$</span> then <span class="math inline">$\eigenvectorMatrix\in \Re^{k_1\times q}$</span> and <span class="math inline">$\eigenvectwoMatrix \in \Re^{k_2\times q}$</span>, i.e. we have a low rank matrix factorization for the weights.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb6-1" data-line-number="1"><span class="im">import</span> teaching_plots <span class="im">as</span> plot</a></code></pre></div>
<div class="figure">
<div id="low-rank-mapping-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/wisuvt.svg" width="80%" style=" ">
</object>
</div>
<div id="low-rank-mapping-magnify" class="magnify" onclick="magnifyFigure(&#39;low-rank-mapping&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="low-rank-mapping-caption" class="caption-frame">
<p>Figure: Pictorial representation of the low rank form of the matrix <span class="math inline">$\mappingMatrix$</span>.</p>
</div>
</div>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb7-1" data-line-number="1"><span class="im">import</span> teaching_plots <span class="im">as</span> plot</a></code></pre></div>
<div class="figure">
<div id="deep-nn-bottleneck-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/deepgp/deep-nn-bottleneck2.svg" width="70%" style=" ">
</object>
</div>
<div id="deep-nn-bottleneck-magnify" class="magnify" onclick="magnifyFigure(&#39;deep-nn-bottleneck&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="deep-nn-bottleneck-caption" class="caption-frame">
<p>Figure: Inserting the bottleneck layers introduces a new set of variables.</p>
</div>
</div>
<p>Including the low rank decomposition of <span class="math inline">$\mappingMatrix$</span> in the neural network, we obtain a new mathematical form. Effectively, we are adding additional <em>latent</em> layers, <span class="math inline">$\latentVector$</span>, in between each of the existing hidden layers. In a neural network these are sometimes known as <em>bottleneck</em> layers. The network can now be written mathematically as <br /><span class="math display">$$
\begin{align}
  \latentVector_{1} &amp;= \eigenvectwoMatrix^\top_1 \inputVector\\
  \hiddenVector_{1} &amp;= \basisFunction\left(\eigenvectorMatrix_1 \latentVector_{1}\right)\\
  \latentVector_{2} &amp;= \eigenvectwoMatrix^\top_2 \hiddenVector_{1}\\
  \hiddenVector_{2} &amp;= \basisFunction\left(\eigenvectorMatrix_2 \latentVector_{2}\right)\\
  \latentVector_{3} &amp;= \eigenvectwoMatrix^\top_3 \hiddenVector_{2}\\
  \hiddenVector_{3} &amp;= \basisFunction\left(\eigenvectorMatrix_3 \latentVector_{3}\right)\\
  \dataVector &amp;= \mappingVector_4^\top\hiddenVector_{3}.
\end{align}
$$</span><br /></p>
<p><br /><span class="math display">$$
\begin{align}
  \latentVector_{1} &amp;= \eigenvectwoMatrix^\top_1 \inputVector\\
  \latentVector_{2} &amp;= \eigenvectwoMatrix^\top_2 \basisFunction\left(\eigenvectorMatrix_1 \latentVector_{1}\right)\\
  \latentVector_{3} &amp;= \eigenvectwoMatrix^\top_3 \basisFunction\left(\eigenvectorMatrix_2 \latentVector_{2}\right)\\
  \dataVector &amp;= \mappingVector_4 ^\top \latentVector_{3}
\end{align}
$$</span><br /></p>
<p>Now if we replace each of these neural networks with a Gaussian process. This is equivalent to taking the limit as the width of each layer goes to infinity, while appropriately scaling down the outputs.</p>
<p><br /><span class="math display">$$
\begin{align}
  \latentVector_{1} &amp;= \mappingFunctionVector_1\left(\inputVector\right)\\
  \latentVector_{2} &amp;= \mappingFunctionVector_2\left(\latentVector_{1}\right)\\
  \latentVector_{3} &amp;= \mappingFunctionVector_3\left(\latentVector_{2}\right)\\
  \dataVector &amp;= \mappingFunctionVector_4\left(\latentVector_{3}\right)
\end{align}
$$</span><br /></p>
<p><br /><span class="math display">$$\dataVector = \mappingFunctionVector_4\left(\mappingFunctionVector_3\left(\mappingFunctionVector_2\left(\mappingFunctionVector_1\left(\inputVector\right)\right)\right)\right)$$</span><br /> <!--include{_ai/includes/ai-vs-data-science-2.md}--></p>
<!-- in this short overview, don't introduce GPy or the data-->
<!-- -->
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb8-1" data-line-number="1"><span class="im">import</span> pods</a></code></pre></div>
<div class="sourceCode" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb9-1" data-line-number="1">data <span class="op">=</span> pods.datasets.mcycle()</a>
<a class="sourceLine" id="cb9-2" data-line-number="2">x <span class="op">=</span> data[<span class="st">&#39;X&#39;</span>]</a>
<a class="sourceLine" id="cb9-3" data-line-number="3">y <span class="op">=</span> data[<span class="st">&#39;Y&#39;</span>]</a>
<a class="sourceLine" id="cb9-4" data-line-number="4">scale<span class="op">=</span>np.sqrt(y.var())</a>
<a class="sourceLine" id="cb9-5" data-line-number="5">offset<span class="op">=</span>y.mean()</a>
<a class="sourceLine" id="cb9-6" data-line-number="6">yhat <span class="op">=</span> (y <span class="op">-</span> offset)<span class="op">/</span>scale</a></code></pre></div>
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb10-1" data-line-number="1">fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>plot.big_wide_figsize)</a>
<a class="sourceLine" id="cb10-2" data-line-number="2">_ <span class="op">=</span> ax.plot(x, y, <span class="st">&#39;r.&#39;</span>,markersize<span class="op">=</span><span class="dv">10</span>)</a>
<a class="sourceLine" id="cb10-3" data-line-number="3">_ <span class="op">=</span> ax.set_xlabel(<span class="st">&#39;time&#39;</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</a>
<a class="sourceLine" id="cb10-4" data-line-number="4">_ <span class="op">=</span> ax.set_ylabel(<span class="st">&#39;acceleration&#39;</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</a>
<a class="sourceLine" id="cb10-5" data-line-number="5">xlim <span class="op">=</span> (<span class="op">-</span><span class="dv">20</span>, <span class="dv">80</span>)</a>
<a class="sourceLine" id="cb10-6" data-line-number="6">ylim <span class="op">=</span> (<span class="op">-</span><span class="dv">175</span>, <span class="dv">125</span>)</a>
<a class="sourceLine" id="cb10-7" data-line-number="7">ax.set_xlim(xlim)</a>
<a class="sourceLine" id="cb10-8" data-line-number="8">ax.set_ylim(ylim)</a>
<a class="sourceLine" id="cb10-9" data-line-number="9">mlai.write_figure(filename<span class="op">=</span><span class="st">&#39;../slides/diagrams/datasets/motorcycle-helmet.svg&#39;</span>, </a>
<a class="sourceLine" id="cb10-10" data-line-number="10">            transparent<span class="op">=</span><span class="va">True</span>, frameon<span class="op">=</span><span class="va">True</span>)</a></code></pre></div>
<h2 id="motorcycle-helmet-data-edit">Motorcycle Helmet Data <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/motorcycle-helmet-data.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/motorcycle-helmet-data.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<div class="figure">
<div id="motorcycle-helment-data-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/datasets/motorcycle-helmet.svg" width="80%" style=" ">
</object>
</div>
<div id="motorcycle-helment-data-magnify" class="magnify" onclick="magnifyFigure(&#39;motorcycle-helment-data&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="motorcycle-helment-data-caption" class="caption-frame">
<p>Figure: Motorcycle helmet data. The data consists of acceleration readings on a motorcycle helmet undergoing a collision. The data exhibits heteroschedastic (time varying) noise levles and non-stationarity.</p>
</div>
</div>
<div class="sourceCode" id="cb11"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb11-1" data-line-number="1">m_full <span class="op">=</span> GPy.models.GPRegression(x,yhat)</a>
<a class="sourceLine" id="cb11-2" data-line-number="2">_ <span class="op">=</span> m_full.optimize() <span class="co"># Optimize parameters of covariance function</span></a></code></pre></div>
<h2 id="motorcycle-helmet-data-gp">Motorcycle Helmet Data GP</h2>
<div class="figure">
<div id="motorcycle-helmet-gp-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/gp/motorcycle-helmet-gp.svg" width="80%" style=" ">
</object>
</div>
<div id="motorcycle-helmet-gp-magnify" class="magnify" onclick="magnifyFigure(&#39;motorcycle-helmet-gp&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="motorcycle-helmet-gp-caption" class="caption-frame">
<p>Figure: Gaussian process fit to the motorcycle helmet accelerometer data.</p>
</div>
</div>
<p>The deep Gaussian process code we are using is research code by Andreas Damianou.</p>
<p>To extend the research code we introduce some approaches to initialization and optimization that we’ll use in examples. These approaches can be found in the <code>deepgp_tutorial.py</code> file.</p>
<p>Deep Gaussian process models also can require some thought in the initialization. Here we choose to start by setting the noise variance to be one percent of the data variance.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb12-1" data-line-number="1"><span class="op">%</span>load <span class="op">-</span>s initialize deepgp_tutorial.py</a></code></pre></div>
<p>Secondly, we introduce a staged optimization approach.</p>
<p>Optimization requires moving variational parameters in the hidden layer representing the mean and variance of the expected values in that layer. Since all those values can be scaled up, and this only results in a downscaling in the output of the first GP, and a downscaling of the input length scale to the second GP. It makes sense to first of all fix the scales of the covariance function in each of the GPs.</p>
<p>Sometimes, deep Gaussian processes can find a local minima which involves increasing the noise level of one or more of the GPs. This often occurs because it allows a minimum in the KL divergence term in the lower bound on the likelihood. To avoid this minimum we habitually train with the likelihood variance (the noise on the output of the GP) fixed to some lower value for some iterations.</p>
<p>Next an optimization of the kernel function parameters at each layer is performed, but with the variance of the likelihood fixed. Again, this is to prevent the model minimizing the Kullback-Leibler divergence between the approximate posterior and the prior <em>before</em> achieving a good data-fit.</p>
<p>Finally, all parameters of the model are optimized together.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb13-1" data-line-number="1"><span class="op">%</span>load <span class="op">-</span>s staged_optimize deepgp_tutorial.py</a></code></pre></div>
<p>The next code is for visualizing the intermediate layers of the deep model. This visualization is only appropriate for models with intermediate layers containing a single latent variable.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb14-1" data-line-number="1"><span class="op">%</span>load <span class="op">-</span>s visualize deepgp_tutorial.py</a></code></pre></div>
<p>The pinball visualization is to bring the pinball-analogy to life in the model. It shows how a ball would fall through the model to end up in the right pbosition. This visualization is only appropriate for models with intermediate layers containing a single latent variable.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb15-1" data-line-number="1"><span class="op">%</span>load <span class="op">-</span>s visualize_pinball deepgp_tutorial.py</a></code></pre></div>
<p>The <code>posterior_sample</code> code allows us to see the output sample locations for a given input. This is useful for visualizing the non-Gaussian nature of the output density.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb16-1" data-line-number="1"><span class="op">%</span>load <span class="op">-</span>s posterior_sample deepgp_tutorial.py</a></code></pre></div>
<p>Finally, we bind these methods to the DeepGP object for ease of calling.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb17-1" data-line-number="1">deepgp.DeepGP.initialize<span class="op">=</span>initialize</a>
<a class="sourceLine" id="cb17-2" data-line-number="2">deepgp.DeepGP.staged_optimize<span class="op">=</span>staged_optimize</a>
<a class="sourceLine" id="cb17-3" data-line-number="3">deepgp.DeepGP.posterior_sample <span class="op">=</span> posterior_sample</a>
<a class="sourceLine" id="cb17-4" data-line-number="4">deepgp.DeepGP.visualize<span class="op">=</span>visualize</a>
<a class="sourceLine" id="cb17-5" data-line-number="5">deepgp.DeepGP.visualize_pinball<span class="op">=</span>visualize_pinball</a></code></pre></div>
<div class="sourceCode" id="cb18"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb18-1" data-line-number="1"><span class="im">import</span> deepgp</a></code></pre></div>
<div class="sourceCode" id="cb19"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb19-1" data-line-number="1">layers <span class="op">=</span> [y.shape[<span class="dv">1</span>], <span class="dv">1</span>, x.shape[<span class="dv">1</span>]]</a>
<a class="sourceLine" id="cb19-2" data-line-number="2">inits <span class="op">=</span> [<span class="st">&#39;PCA&#39;</span>]<span class="op">*</span>(<span class="bu">len</span>(layers)<span class="op">-</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb19-3" data-line-number="3">kernels <span class="op">=</span> []</a>
<a class="sourceLine" id="cb19-4" data-line-number="4"><span class="cf">for</span> i <span class="kw">in</span> layers[<span class="dv">1</span>:]:</a>
<a class="sourceLine" id="cb19-5" data-line-number="5">    kernels <span class="op">+=</span> [GPy.kern.RBF(i)]</a>
<a class="sourceLine" id="cb19-6" data-line-number="6">m <span class="op">=</span> deepgp.DeepGP(layers,Y<span class="op">=</span>yhat, X<span class="op">=</span>x, </a>
<a class="sourceLine" id="cb19-7" data-line-number="7">                  inits<span class="op">=</span>inits, </a>
<a class="sourceLine" id="cb19-8" data-line-number="8">                  kernels<span class="op">=</span>kernels, <span class="co"># the kernels for each layer</span></a>
<a class="sourceLine" id="cb19-9" data-line-number="9">                  num_inducing<span class="op">=</span><span class="dv">20</span>, back_constraint<span class="op">=</span><span class="va">False</span>)</a>
<a class="sourceLine" id="cb19-10" data-line-number="10"></a>
<a class="sourceLine" id="cb19-11" data-line-number="11"></a>
<a class="sourceLine" id="cb19-12" data-line-number="12"></a>
<a class="sourceLine" id="cb19-13" data-line-number="13">m.initialize()</a></code></pre></div>
<div class="sourceCode" id="cb20"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb20-1" data-line-number="1">m.staged_optimize(iters<span class="op">=</span>(<span class="dv">1000</span>,<span class="dv">1000</span>,<span class="dv">10000</span>), messages<span class="op">=</span>(<span class="va">True</span>, <span class="va">True</span>, <span class="va">True</span>))</a></code></pre></div>
<div class="sourceCode" id="cb21"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb21-1" data-line-number="1"><span class="im">import</span> teaching_plots <span class="im">as</span> plot</a>
<a class="sourceLine" id="cb21-2" data-line-number="2"><span class="im">import</span> mlai</a></code></pre></div>
<div class="sourceCode" id="cb22"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb22-1" data-line-number="1">fig, ax<span class="op">=</span>plt.subplots(figsize<span class="op">=</span>plot.big_wide_figsize)</a>
<a class="sourceLine" id="cb22-2" data-line-number="2">plot.model_output(m, scale<span class="op">=</span>scale, offset<span class="op">=</span>offset, ax<span class="op">=</span>ax, xlabel<span class="op">=</span><span class="st">&#39;time&#39;</span>, ylabel<span class="op">=</span><span class="st">&#39;acceleration/$g$&#39;</span>, fontsize<span class="op">=</span><span class="dv">20</span>, portion<span class="op">=</span><span class="fl">0.5</span>)</a>
<a class="sourceLine" id="cb22-3" data-line-number="3">ax.set_ylim(ylim)</a>
<a class="sourceLine" id="cb22-4" data-line-number="4">ax.set_xlim(xlim)</a>
<a class="sourceLine" id="cb22-5" data-line-number="5">mlai.write_figure(filename<span class="op">=</span><span class="st">&#39;../slides/diagrams/deepgp/motorcycle-helmet-deep-gp.svg&#39;</span>, </a>
<a class="sourceLine" id="cb22-6" data-line-number="6">            transparent<span class="op">=</span><span class="va">True</span>, frameon<span class="op">=</span><span class="va">True</span>)</a></code></pre></div>
<h2 id="motorcycle-helmet-data-deep-gp-edit">Motorcycle Helmet Data Deep GP <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_deepgp/includes/deep-motorcycle.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_deepgp/includes/deep-motorcycle.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<div class="figure">
<div id="motorcycle-helmet-deep-gp-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/deepgp/motorcycle-helmet-deep-gp.svg" width="80%" style=" ">
</object>
</div>
<div id="motorcycle-helmet-deep-gp-magnify" class="magnify" onclick="magnifyFigure(&#39;motorcycle-helmet-deep-gp&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="motorcycle-helmet-deep-gp-caption" class="caption-frame">
<p>Figure: Deep Gaussian process fit to the motorcycle helmet accelerometer data.</p>
</div>
</div>
<div class="sourceCode" id="cb23"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb23-1" data-line-number="1"><span class="im">import</span> teaching_plots <span class="im">as</span> plot</a>
<a class="sourceLine" id="cb23-2" data-line-number="2"><span class="im">import</span> mlai</a></code></pre></div>
<div class="sourceCode" id="cb24"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb24-1" data-line-number="1">fig, ax<span class="op">=</span>plt.subplots(figsize<span class="op">=</span>plot.big_wide_figsize)</a>
<a class="sourceLine" id="cb24-2" data-line-number="2">plot.model_sample(m, scale<span class="op">=</span>scale, offset<span class="op">=</span>offset, samps<span class="op">=</span><span class="dv">10</span>, ax<span class="op">=</span>ax, xlabel<span class="op">=</span><span class="st">&#39;time&#39;</span>, ylabel<span class="op">=</span><span class="st">&#39;acceleration/$g$&#39;</span>, portion <span class="op">=</span> <span class="fl">0.5</span>)</a>
<a class="sourceLine" id="cb24-3" data-line-number="3">ax.set_ylim(ylim)</a>
<a class="sourceLine" id="cb24-4" data-line-number="4">ax.set_xlim(xlim)</a>
<a class="sourceLine" id="cb24-5" data-line-number="5"></a>
<a class="sourceLine" id="cb24-6" data-line-number="6">mlai.write_figure(figure<span class="op">=</span>fig, filename<span class="op">=</span><span class="st">&#39;../slides/diagrams/deepgp/motorcycle-helmet-deep-gp-samples.svg&#39;</span>, </a>
<a class="sourceLine" id="cb24-7" data-line-number="7">                  transparent<span class="op">=</span><span class="va">True</span>, frameon<span class="op">=</span><span class="va">True</span>)</a></code></pre></div>
<h2 id="motorcycle-helmet-data-deep-gp">Motorcycle Helmet Data Deep GP</h2>
<div class="figure">
<div id="motorcycle-helmet-deep-gp-samples-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/deepgp/motorcycle-helmet-deep-gp-samples.svg" width="80%" style=" ">
</object>
</div>
<div id="motorcycle-helmet-deep-gp-samples-magnify" class="magnify" onclick="magnifyFigure(&#39;motorcycle-helmet-deep-gp-samples&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="motorcycle-helmet-deep-gp-samples-caption" class="caption-frame">
<p>Figure: Samples from the deep Gaussian process as fitted to the motorcycle helmet accelerometer data.</p>
</div>
</div>
<div class="sourceCode" id="cb25"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb25-1" data-line-number="1">m.visualize(xlim<span class="op">=</span>xlim, ylim<span class="op">=</span>ylim, scale<span class="op">=</span>scale,offset<span class="op">=</span>offset, </a>
<a class="sourceLine" id="cb25-2" data-line-number="2">            xlabel<span class="op">=</span><span class="st">&quot;time&quot;</span>, ylabel<span class="op">=</span><span class="st">&quot;acceleration/$g$&quot;</span>, portion<span class="op">=</span><span class="fl">0.5</span>,</a>
<a class="sourceLine" id="cb25-3" data-line-number="3">            dataset<span class="op">=</span><span class="st">&#39;motorcycle-helmet&#39;</span>,</a>
<a class="sourceLine" id="cb25-4" data-line-number="4">            diagrams<span class="op">=</span><span class="st">&#39;../slides/diagrams/deepgp&#39;</span>)</a></code></pre></div>
<h2 id="motorcycle-helmet-data-latent-1">Motorcycle Helmet Data Latent 1</h2>
<div class="figure">
<div id="motorcycle-helmet-deep-gp-layer-0-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/deepgp/motorcycle-helmet-deep-gp-layer-0.svg" width="60%" style=" ">
</object>
</div>
<div id="motorcycle-helmet-deep-gp-layer-0-magnify" class="magnify" onclick="magnifyFigure(&#39;motorcycle-helmet-deep-gp-layer-0&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="motorcycle-helmet-deep-gp-layer-0-caption" class="caption-frame">
<p>Figure: Mappings from the input to the latent layer for the motorcycle helmet accelerometer data.</p>
</div>
</div>
<h2 id="motorcycle-helmet-data-latent-2">Motorcycle Helmet Data Latent 2</h2>
<div class="figure">
<div id="motorcycle-helmet-deep-gp-layer-1-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/deepgp/motorcycle-helmet-deep-gp-layer-1.svg" width="60%" style=" ">
</object>
</div>
<div id="motorcycle-helmet-deep-gp-layer-1-magnify" class="magnify" onclick="magnifyFigure(&#39;motorcycle-helmet-deep-gp-layer-1&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="motorcycle-helmet-deep-gp-layer-1-caption" class="caption-frame">
<p>Figure: Mappings from the latent layer to the output layer for the motorcycle helmet accelerometer data.</p>
</div>
</div>
<div class="sourceCode" id="cb26"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb26-1" data-line-number="1">fig, ax<span class="op">=</span>plt.subplots(figsize<span class="op">=</span>plot.big_wide_figsize)</a>
<a class="sourceLine" id="cb26-2" data-line-number="2">m.visualize_pinball(ax<span class="op">=</span>ax, xlabel<span class="op">=</span><span class="st">&#39;time&#39;</span>, ylabel<span class="op">=</span><span class="st">&#39;acceleration/g&#39;</span>, </a>
<a class="sourceLine" id="cb26-3" data-line-number="3">                    points<span class="op">=</span><span class="dv">50</span>, scale<span class="op">=</span>scale, offset<span class="op">=</span>offset, portion<span class="op">=</span><span class="fl">0.1</span>)</a>
<a class="sourceLine" id="cb26-4" data-line-number="4">mlai.write_figure(figure<span class="op">=</span>fig, filename<span class="op">=</span><span class="st">&#39;../slides/diagrams/deepgp/motorcycle-helmet-deep-gp-pinball.svg&#39;</span>, </a>
<a class="sourceLine" id="cb26-5" data-line-number="5">                  transparent<span class="op">=</span><span class="va">True</span>, frameon<span class="op">=</span><span class="va">True</span>)</a></code></pre></div>
<h2 id="motorcycle-helmet-pinball-plot">Motorcycle Helmet Pinball Plot</h2>
<div class="figure">
<div id="motorcycle-helmet-deep-gp-pinball-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/deepgp/motorcycle-helmet-deep-gp-pinball.svg" width="60%" style=" ">
</object>
</div>
<div id="motorcycle-helmet-deep-gp-pinball-magnify" class="magnify" onclick="magnifyFigure(&#39;motorcycle-helmet-deep-gp-pinball&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="motorcycle-helmet-deep-gp-pinball-caption" class="caption-frame">
<p>Figure: Pinball plot for the mapping from input to output layer for the motorcycle helmet accelerometer data.</p>
</div>
</div>
<h2 id="graphical-models-edit">Graphical Models <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/graphical-models.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ml/includes/graphical-models.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<p>One way of representing a joint distribution is to consider conditional dependencies between data. Conditional dependencies allow us to factorize the distribution. For example, a Markov chain is a factorization of a distribution into components that represent the conditional relationships between points that are neighboring, often in time or space. It can be decomposed in the following form. <br /><span class="math display">$$p(\dataVector) = p(\dataScalar_\numData | \dataScalar_{\numData-1}) p(\dataScalar_{\numData-1}|\dataScalar_{\numData-2}) \dots p(\dataScalar_{2} | \dataScalar_{1})$$</span><br /></p>
<div class="figure">
<div id="markov-chain-figure" class="figure-frame">
<object class="svgplot " data="../slides/diagrams/ml/markov.svg" width="50%" style=" ">
</object>
</div>
<div id="markov-chain-magnify" class="magnify" onclick="magnifyFigure(&#39;markov-chain&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="markov-chain-caption" class="caption-frame">
<p>Figure: A Markov chain is a simple form of probabilistic graphical model providing a particular decomposition of the joint density.</p>
</div>
</div>
<p>By specifying conditional independencies we can reduce the parameterization required for our data, instead of directly specifying the parameters of the joint distribution, we can specify each set of parameters of the conditonal independently. This can also give an advantage in terms of interpretability. Understanding a conditional independence structure gives a structured understanding of data. If developed correctly, according to causal methodology, it can even inform how we should intervene in the system to drive a desired result <span class="citation" data-cites="Pearl:causality95">(Pearl 1995)</span>.</p>
<p>However, a challenge arises when the data becomes more complex. Consider the graphical model shown below, used to predict the perioperative risk of <em>C Difficile</em> infection following colon surgery <span class="citation" data-cites="Steele:predictive12">(Steele et al. 2012)</span>.</p>
<div class="figure">
<div id="c-difficile-bayes-net-diagnosis-figure" class="figure-frame">
<div class="centered" style="">
<img class="negate" src="../slides/diagrams/bayes-net-diagnosis.png" width="60%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="c-difficile-bayes-net-diagnosis-magnify" class="magnify" onclick="magnifyFigure(&#39;c-difficile-bayes-net-diagnosis&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="c-difficile-bayes-net-diagnosis-caption" class="caption-frame">
<p>Figure: A probabilistic directed graph used to predict the perioperative risk of <em>C Difficile</em> infection following colon surgery. When these models have good predictive performance they are often difficult to interpret. This may be due to the limited representation capability of the conditional densities in the model.</p>
</div>
</div>
<p>To capture the complexity in the interelationship between the data, the graph itself becomes more complex, and less interpretable.</p>
<h2 id="conclusion-edit">Conclusion <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_data-science/includes/data-oriented-conclusions.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_data-science/includes/data-oriented-conclusions.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<p>We operate in a technologically evolving environment. Machine learning is becoming a key coponent in our decision-making capabilities, our intelligence and strategic command. However, technology drove changes in battlefield strategy. From the stalemate of the first world war to the tank-dominated Blitzkrieg of the second, to the asymmetric warfare of the present. Our technology, tactics and strategies are also constantly evolving. Machine learning is part of that evolution solution, but the main challenge is not to become so fixated on the tactics of today that we miss the evolution of strategy that the technology is suggesting.</p>
<p>Data oriented programming offers a set of development methodologies which ensure that the system designer considers what decisions are required, how they will be made, and critically, declares this within the system architecture.</p>
<p>This allows for monitoring of <em>data quality</em>, <em>fairness</em>, <em>model accuracy</em> and opens the door to a more sophisticated form of auto ML where full redployments of models are considered while analyzing the information dynamics of a complex automated decision-making system.</p>
<!--



## Example: Prediction of Malaria Incidence in Uganda <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_health/includes/malaria-gp.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_health/includes/malaria-gp.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>

<span style="text-align:right"><img class="" src="../slides/diagrams/people/2013_03_28_180606.JPG" width="1.5cm" style="background:none; border:none; box-shadow:none; position:absolute; clip:rect(2662px,1780px,1110px,600px);vertical-align:middle"></span>

As an example of using Gaussian process models within the full pipeline from data to decsion, we'll consider the prediction of Malaria incidence in Uganda. For the purposes of this study malaria reports come in two forms, HMIS reports from health centres and Sentinel data, which is curated by the WHO. There are limited sentinel sites and many HMIS sites.

The work is from Ricardo Andrade Pacheco's PhD thesis, completed in collaboration with John Quinn and Martin Mubangizi [@Andrade:consistent14;@Mubangizi:malaria14]. John and Martin were initally from the AI-DEV group from the University of Makerere in Kampala and more latterly they were based at UN Global Pulse in Kampala.





Malaria data is spatial data. Uganda is split into districts, and health reports can be found for each district. This suggests that models such as conditional random fields could be used for spatial modelling, but there are two complexities with this. First of all, occasionally districts split into two. Secondly, sentinel sites are a specific location within a district, such as Nagongera which is a sentinel site based in the Tororo district.

<div class="figure">
<div class="figure-frame" id="uganda-districts-2006-figure">
<div class="centered " style=""><img class="" src="../slides/diagrams/health/uganda-districts-2006.png" width="50%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle"></div>
</div>
<div class="magnify" id="uganda-districts-2006-magnify" onclick="magnifyFigure('uganda-districts-2006')">
<img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex">
</div>
<div class="caption-frame" id="uganda-districts-2006-caption">
Figure: Ugandan districs. Data SRTM/NASA from <https://dds.cr.usgs.gov/srtm/version2_1>.
</div>
</div>

<span style="text-align:right">[@Andrade:consistent14;@Mubangizi:malaria14]</span>






The common standard for collecting health data on the African continent is from the Health management information systems (HMIS). However, this data suffers from missing values [@Gething:hmis06] and diagnosis of diseases like typhoid and malaria may be confounded.

<div class="figure">
<div class="figure-frame" id="tororo-district-in-uganda-figure">
<object class="" width="50%" data="../slides/diagrams/health/Tororo_District_in_Uganda.svg"></object>
</div>
<div class="magnify" id="tororo-district-in-uganda-magnify" onclick="magnifyFigure('tororo-district-in-uganda')">
<img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex">
</div>
<div class="caption-frame" id="tororo-district-in-uganda-caption">
Figure: The Tororo district, where the sentinel site, Nagongera, is located.
</div>
</div>

[World Health Organization Sentinel Surveillance systems](https://www.who.int/immunization/monitoring_surveillance/burden/vpd/surveillance_type/sentinel/en/) are set up "when high-quality data are needed about a particular disease that cannot be obtained through a passive system". Several sentinel sites give accurate assessment of malaria disease levels in Uganda, including a site in Nagongera.



<div class="figure">
<div class="figure-frame" id="sentinel-nagongera-figure">
<div class="centered " style=""><img class="negate" src="../slides/diagrams/health/sentinel_nagongera.png" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle"></div>
</div>
<div class="magnify" id="sentinel-nagongera-magnify" onclick="magnifyFigure('sentinel-nagongera')">
<img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex">
</div>
<div class="caption-frame" id="sentinel-nagongera-caption">
Figure: Sentinel and HMIS data along with rainfall and temperature for the Nagongera sentinel station in the Tororo district.
</div>
</div>

In collaboration with the AI Research Group at Makerere we chose to investigate whether Gaussian process models could be used to assimilate information from these two different sources of disease informaton. Further, we were interested in whether local information on rainfall and temperature could be used to improve malaria estimates.

The aim of the project was to use WHO Sentinel sites, alongside rainfall and temperature, to improve predictions from HMIS data of levels of malaria.



<div class="figure">
<div class="figure-frame" id="mubende-district-in-uganda-figure">
<object class="" width="50%" data="../slides/diagrams/health/Mubende_District_in_Uganda.svg"></object>
</div>
<div class="magnify" id="mubende-district-in-uganda-magnify" onclick="magnifyFigure('mubende-district-in-uganda')">
<img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex">
</div>
<div class="caption-frame" id="mubende-district-in-uganda-caption">
Figure: The Mubende District.
</div>
</div>



<div class="figure">
<div class="figure-frame" id="malaria-prediction-mubende-figure">
<div class="centered " style=""><img class="" src="../slides/diagrams/health/mubende.png" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle"></div>
</div>
<div class="magnify" id="malaria-prediction-mubende-magnify" onclick="magnifyFigure('malaria-prediction-mubende')">
<img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex">
</div>
<div class="caption-frame" id="malaria-prediction-mubende-caption">
Figure: Prediction of malaria incidence in Mubende.
</div>
</div>



<div class="figure">
<div class="figure-frame" id="-figure">
<div class="centered centered" style=""><img class="" src="../slides/diagrams/gpss/1157497_513423392066576_1845599035_n.jpg" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle"></div>
</div>
<div class="magnify" id="-magnify" onclick="magnifyFigure('')">
<img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex">
</div>
<div class="caption-frame" id="-caption">
Figure: The project arose out of the Gaussian process summer school held at Makerere in Kampala in 2013. The school led, in turn, to the Data Science Africa initiative.
</div>
</div>

## Early Warning Systems 



<div class="figure">
<div class="figure-frame" id="kabarole-district-in-uganda-figure">
<object class="" width="50%" data="../slides/diagrams/health/Kabarole_District_in_Uganda.svg"></object>
</div>
<div class="magnify" id="kabarole-district-in-uganda-magnify" onclick="magnifyFigure('kabarole-district-in-uganda')">
<img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex">
</div>
<div class="caption-frame" id="kabarole-district-in-uganda-caption">
Figure: The Kabarole district in Uganda.
</div>
</div>



<div class="figure">
<div class="figure-frame" id="kabarole-disease-over-time-figure">
<div class="centered " style=""><img class="" src="../slides/diagrams/health/kabarole.gif" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle"></div>
</div>
<div class="magnify" id="kabarole-disease-over-time-magnify" onclick="magnifyFigure('kabarole-disease-over-time')">
<img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex">
</div>
<div class="caption-frame" id="kabarole-disease-over-time-caption">
Figure: Estimate of the current disease situation in the Kabarole district over time. Estimate is constructed with a Gaussian process with an additive covariance funciton.
</div>
</div>

Health monitoring system for the Kabarole district. Here we have fitted the reports with a Gaussian process with an additive covariance function. It has two components, one is a long time scale component (in red above) the other is a short time scale component (in blue).

Monitoring proceeds by considering two aspects of the curve. Is the blue line (the short term report signal) above the red (which represents the long term trend? If so we have higher than expected reports. If this is the case *and* the gradient is still positive (i.e. reports are going up) we encode this with a *red* color. If it is the case and the gradient of the blue line is negative (i.e. reports are going down) we encode this with an *amber* color. Conversely, if the blue line is below the red *and* decreasing, we color *green*. On the other hand if it is below red but increasing, we color *yellow*.

This gives us an early warning system for disease. Red is a bad situation getting worse, amber is bad, but improving. Green is good and getting better and yellow good but degrading.

Finally, there is a gray region which represents when the scale of the effect is small.



<div class="figure">
<div class="figure-frame" id="early-warning-system-map-figure">
<div class="centered " style=""><img class="" src="../slides/diagrams/health/monitor.gif" width="50%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle"></div>
</div>
<div class="magnify" id="early-warning-system-map-magnify" onclick="magnifyFigure('early-warning-system-map')">
<img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex">
</div>
<div class="caption-frame" id="early-warning-system-map-caption">
Figure: The map of Ugandan districts with an overview of the Malaria situation in each district.
</div>
</div>

These colors can now be observed directly on a spatial map of the districts to give an immediate impression of the current status of the disease across the country.


-->
<h2 id="related-papers">Related Papers</h2>
<ul>
<li><p><em>Deep Gaussian Processes</em> <span class="citation" data-cites="Damianou:deepgp13">Damianou and Lawrence (2013)</span></p></li>
<li><p><em>Latent Force Models</em> <span class="citation" data-cites="Alvarez:llfm13">Álvarez, Luengo, and Lawrence (2013)</span></p></li>
<li><p><em>Gaussian Process Latent Force Models for Learning and Stochastic Control of Physical Systems</em> <span class="citation" data-cites="Sarkka:control18">Särkkä, Álvarez, and Lawrence (2018)</span></p></li>
<li><p><em>The Emergence of Organizing Structure in Conceptual Representation</em> <span class="citation" data-cites="Lake:emergence18">Lake, Lawrence, and Tenenbaum (2018)</span></p></li>
</ul>
<h2 id="others-work">Other’s Work</h2>
<ul>
<li><em>How Deep Are Deep Gaussian Processes?</em> <span class="citation" data-cites="Dunlop:deep2017">Dunlop et al. (n.d.)</span></li>
<li><em>Doubly Stochastic Variational Inference for Deep Gaussian Processes</em> <span class="citation" data-cites="Salimbeni:doubly2017">Salimbeni and Deisenroth (2017)</span></li>
<li><em>Deep Multi-task Gaussian Processes for Survival Analysis with Competing Risks</em> <span class="citation" data-cites="Alaa:deep2017">Alaa and van der Schaar (2017)</span></li>
<li><em>Counterfactual Gaussian Processes for Reliable Decision-making and What-if Reasoning</em> <span class="citation" data-cites="Schulam:counterfactual17">Schulam and Saria (2017)</span></li>
</ul>
<h2 id="directions">Directions</h2>
<h2 id="data-science-africa-edit">Data Science Africa <span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_data-science/includes/data-science-africa.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_data-science/includes/data-science-africa.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span></h2>
<div class="figure">
<div id="data-science-africa-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="../slides/diagrams/data-science-africa-logo.png" width="30%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="data-science-africa-magnify" class="magnify" onclick="magnifyFigure(&#39;data-science-africa&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="data-science-africa-caption" class="caption-frame">
<p>Figure: Data Science Africa <a href="http://datascienceafrica.org" class="uri">http://datascienceafrica.org</a> is a ground up initiative for capacity building around data science, machine learning and artificial intelligence on the African continent.</p>
</div>
</div>
<p>Data Science Africa is a bottom up initiative for capacity building in data science, machine learning and artificial intelligence on the African continent.</p>
<p>As of 2019 there have been five workshops and five schools, located in Nyeri, Kenya (twice); Kampala, Uganda; Arusha, Tanzania; Abuja, Nigeria and Addis Ababa, Ethiopia. The next event is scheduled for October 2019 in Accra, Ghana.</p>
<p>The main notion is <em>end-to-end</em> data science. For example, going from data collection in the farmer’s field to decision making in the Ministry of Agriculture. Or going from malaria disease counts in health centers, to medicine distribution.</p>
<p>The philosophy is laid out in <span class="citation" data-cites="Lawrence:dsa15">(Lawrence 2015)</span>. The key idea is that the modern <em>information infrastructure</em> presents new solutions to old problems. Modes of development change because less capital investment is required to take advantage of this infrastructure. The philosophy is that local capacity building is the right way to leverage these challenges in addressing data science problems in the African context.</p>
<p>Data Science Africa is now a non-govermental organization registered in Kenya. The organising board of the meeting is entirely made up of scientists and academics based on the African continent.</p>
<div class="figure">
<div id="africa-benefit-data-revolution-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="../slides/diagrams/data-science/africa-benefit-data-revolution.png" width="70%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="africa-benefit-data-revolution-magnify" class="magnify" onclick="magnifyFigure(&#39;africa-benefit-data-revolution&#39;)">
<p><img class="img-button" src="/icons/Magnify_Large.svg" style="width:1.5ex"></p>
</div>
<div id="africa-benefit-data-revolution-caption" class="caption-frame">
<p>Figure: The lack of existing physical infrastructure on the African continent makes it a particularly interesting environment for deploying solutions based on the <em>information infrastructure</em>. The idea is explored more in this <a href="https://www.theguardian.com/media-network/2015/aug/25/africa-benefit-data-science-information" target="_blank" >this Guardian Op-ed</a>.</p>
</div>
</div>
<h1 id="references" class="unnumbered">References</h1>
<div id="refs" class="references">
<div id="ref-Alaa:deep2017">
<p>Alaa, Ahmed M., and Mihaela van der Schaar. 2017. “Deep Multi-Task Gaussian Processes for Survival Analysis with Competing Risks.” In <em>Advances in Neural Information Processing Systems 30</em>, edited by I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, 2326–34. Curran Associates, Inc. <a href="http://papers.nips.cc/paper/6827-deep-multi-task-gaussian-processes-for-survival-analysis-with-competing-risks.pdf" class="uri">http://papers.nips.cc/paper/6827-deep-multi-task-gaussian-processes-for-survival-analysis-with-competing-risks.pdf</a>.</p>
</div>
<div id="ref-Alvarez:llfm13">
<p>Álvarez, Mauricio A., David Luengo, and Neil D. Lawrence. 2013. “Linear Latent Force Models Using Gaussian Processes.” <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em> 35 (11): 2693–2705. <a href="https://doi.org/10.1109/TPAMI.2013.86" class="uri">https://doi.org/10.1109/TPAMI.2013.86</a>.</p>
</div>
<div id="ref-Damianou:deepgp13">
<p>Damianou, Andreas, and Neil D. Lawrence. 2013. “Deep Gaussian Processes.” In, 31:207–15.</p>
</div>
<div id="ref-Dunlop:deep2017">
<p>Dunlop, Matthew M., Mark A. Girolami, Andrew M. Stuart, and Aretha L. Teckentrup. n.d. “How Deep Are Deep Gaussian Processes?” <em>Journal of Machine Learning Research</em> 19 (54): 1–46. <a href="http://jmlr.org/papers/v19/18-015.html" class="uri">http://jmlr.org/papers/v19/18-015.html</a>.</p>
</div>
<div id="ref-Lake:emergence18">
<p>Lake, Brenden M., Neil D. Lawrence, and Joshua B. Tenenbaum. 2018. “The Emergence of Organizing Structure in Conceptual Representation.” <em>Cognitive Science</em> 42 Suppl 3: 809–32. <a href="https://doi.org/10.1111/cogs.12580" class="uri">https://doi.org/10.1111/cogs.12580</a>.</p>
</div>
<div id="ref-Lawrence:dsa15">
<p>Lawrence, Neil D. 2015. “How Africa Can Benefit from the Data Revolution.” The Guardian Media &amp; Tech Network. <a href="https://www.theguardian.com/media-network/2015/aug/25/africa-benefit-data-science-information" class="uri">https://www.theguardian.com/media-network/2015/aug/25/africa-benefit-data-science-information</a>.</p>
</div>
<div id="ref-Pearl:causality95">
<p>Pearl, Judea. 1995. “From Bayesian Networks to Causal Networks.” In <em>Probabilistic Reasoning and Bayesian Belief Networks</em>, edited by A. Gammerman, 1–31. Alfred Waller.</p>
</div>
<div id="ref-Salimbeni:doubly2017">
<p>Salimbeni, Hugh, and Marc Deisenroth. 2017. “Doubly Stochastic Variational Inference for Deep Gaussian Processes.” In <em>Advances in Neural Information Processing Systems 30</em>, edited by I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, 4591–4602. Curran Associates, Inc. <a href="http://papers.nips.cc/paper/7045-doubly-stochastic-variational-inference-for-deep-gaussian-processes.pdf" class="uri">http://papers.nips.cc/paper/7045-doubly-stochastic-variational-inference-for-deep-gaussian-processes.pdf</a>.</p>
</div>
<div id="ref-Sarkka:control18">
<p>Särkkä, Simo, Mauricio A. Álvarez, and Neil D. Lawrence. 2018. “Gaussian Process Latent Force Models for Learning and Stochastic Control of Physical Systems.” <em>IEEE Transactions on Automatic Control</em>. <a href="https://doi.org/10.1109/TAC.2018.2874749" class="uri">https://doi.org/10.1109/TAC.2018.2874749</a>.</p>
</div>
<div id="ref-Schulam:counterfactual17">
<p>Schulam, Peter, and Suchi Saria. 2017. “Counterfactual Gaussian Processes for Reliable Decision-Making and What-If Reasoning.” In <em>Advances in Neural Information Processing Systems 30</em>, edited by I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, 1696–1706. Curran Associates, Inc. <a href="http://papers.nips.cc/paper/6767-counterfactual-gaussian-processes-for-reliable-decision-making-and-what-if-reasoning.pdf" class="uri">http://papers.nips.cc/paper/6767-counterfactual-gaussian-processes-for-reliable-decision-making-and-what-if-reasoning.pdf</a>.</p>
</div>
<div id="ref-Steele:predictive12">
<p>Steele, S, A Bilchik, J Eberhardt, P Kalina, A Nissan, E Johnson, I Avital, and A Stojadinovic. 2012. “Using Machine-Learned Bayesian Belief Networks to Predict Perioperative Risk of Clostridium Difficile Infection Following Colon Surgery.” <em>Interact J Med Res</em> 1 (2): e6. <a href="https://doi.org/10.2196/ijmr.2131" class="uri">https://doi.org/10.2196/ijmr.2131</a>.</p>
</div>
<div id="ref-Taigman:deepface14">
<p>Taigman, Yaniv, Ming Yang, Marc’Aurelio Ranzato, and Lior Wolf. 2014. “DeepFace: Closing the Gap to Human-Level Performance in Face Verification.” In <em>Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition</em>. <a href="https://doi.org/10.1109/CVPR.2014.220" class="uri">https://doi.org/10.1109/CVPR.2014.220</a>.</p>
</div>
</div>


